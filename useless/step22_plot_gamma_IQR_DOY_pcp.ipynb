{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read gridinfo mask\n",
      "Read nldas data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_max' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_min' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_range' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_max' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_min' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_range' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 79831\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os,scipy\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from scipy.stats import gamma\n",
    "\n",
    "def read_ens(out_forc_name_base, metric, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.'+metric+'.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]\n",
    "        pcp = f.variables['pcp'][:]\n",
    "        tmean = f.variables['t_mean'][:]\n",
    "        tmin = f.variables['t_min'][:]\n",
    "        tmax = f.variables['t_max'][:]\n",
    "        trange = f.variables['t_range'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            tmean_concat = tmean\n",
    "            tmin_concat = tmin\n",
    "            tmax_concat = tmax\n",
    "            trange_concat = trange\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_concat = np.concatenate((pcp_concat, pcp), axis=0) # (time,y,x)\n",
    "            tmean_concat = np.concatenate((tmean_concat, tmean), axis=0)\n",
    "            tmin_concat = np.concatenate((tmin_concat, tmin), axis=0)\n",
    "            tmax_concat = np.concatenate((tmax_concat, tmax), axis=0)\n",
    "            trange_concat = np.concatenate((trange_concat, trange), axis=0)\n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_concat, tmean_concat, tmin_concat, tmax_concat, trange_concat\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "stn_ens_dir = os.path.join(root_dir,'data/stn_ens_summary')\n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "start_yr = 2015\n",
    "end_yr = 2016\n",
    "\n",
    "gridinfo_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "scenarios_ids = range(0,9) #[0,1,5,8] \n",
    "intervals =  range(10,1,-1) #[10,9,5,2]\n",
    "scenario_num = len(scenarios_ids)\n",
    "\n",
    "subforlder = 'gmet_ens_summary'\n",
    "file_basename = 'ens_forc'\n",
    "\n",
    "ens_num = 100\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "dpi_value = 600\n",
    "plot_date_start = '2015-01-01'\n",
    "plot_date_end = '2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "nldas_iqr_file = os.path.join(root_dir, 'scripts/step21_nldas_gamma_IQR_DOY_pcp/IQR_pcp.txt')\n",
    "\n",
    "output_dir=os.path.join(root_dir, 'scripts/step22_plot_gamma_IQR_DOY')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_filename = 'step22_plot_gamma_IQR_DOY_pcp.png'\n",
    "   \n",
    "#======================================================================================================\n",
    "print('Read gridinfo mask')\n",
    "# get xy mask from gridinfo.nc\n",
    "f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "#data_mask = f_gridinfo['data_mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "#======================================================================================================\n",
    "# read scenario ensemble results and save to dictionary\n",
    "print('Read nldas ens bounds')\n",
    "k=6-1\n",
    "test_folder = test_folders[scenarios_ids[k]]\n",
    "\n",
    "print(test_folder)\n",
    "test_dir = os.path.join(result_dir, test_folder)\n",
    "fig_title= test_folder\n",
    "\n",
    "print(' -- read spatial ensemble')\n",
    "# read ensemble mean    \n",
    "output_namebase = os.path.join(test_dir,subforlder, file_basename)\n",
    "metric = 'enspctl.5'\n",
    "time_enslb, pcp_enslb, tmean_enslb, tmin_enslb, tmax_enslb, trange_enslb = read_ens(output_namebase, metric, start_yr, end_yr)\n",
    "\n",
    "output_namebase = os.path.join(test_dir,subforlder, file_basename)\n",
    "metric = 'enspctl.95'\n",
    "time_ensub, pcp_ensub, tmean_ensub, tmin_ensub, tmax_ensub, trange_ensub = read_ens(output_namebase, metric, start_yr, end_yr)\n",
    "\n",
    "# define plot mask for nldas ensemble\n",
    "mask_ens_t = (time_enslb>=plot_date_start_obj) & (time_enslb<=plot_date_end_obj)\n",
    "\n",
    "print(' -- calculate IQR')\n",
    "# IQR = upper limit - lower limit\n",
    "(nt,ny,nx) = np.shape(pcp_ensub[mask_ens_t,:,:])\n",
    "pcp_ensiqr = pcp_ensub[mask_ens_t,:,:]-pcp_enslb[mask_ens_t,:,:]   \n",
    "tmean_ensiqr = tmean_ensub[mask_ens_t,:,:]-tmean_enslb[mask_ens_t,:,:]\n",
    "tmin_ensiqr = tmin_ensub[mask_ens_t,:,:]-tmin_enslb[mask_ens_t,:,:]\n",
    "tmax_ensiqr = tmax_ensub[mask_ens_t,:,:]-tmax_enslb[mask_ens_t,:,:]\n",
    "trange_ensiqr = trange_ensub[mask_ens_t,:,:]-trange_enslb[mask_ens_t,:,:]\n",
    "\n",
    "del pcp_enslb, tmean_enslb, tmin_enslb, tmax_enslb, trange_enslb  \n",
    "del pcp_ensub, tmean_ensub, tmin_ensub, tmax_ensub, trange_ensub \n",
    "\n",
    "print(' -- extract unmasked values')\n",
    "# extract unmasked values\n",
    "mask_xy_3d = np.repeat(mask_xy[np.newaxis,:,:],nt,axis=0)\n",
    "pcp_ensiqr=pcp_ensiqr[mask_xy_3d!=0]    \n",
    "tmean_ensiqr=tmean_ensiqr[mask_xy_3d!=0] \n",
    "tmin_ensiqr=tmin_ensiqr[mask_xy_3d!=0]  \n",
    "tmax_ensiqr=tmax_ensiqr[mask_xy_3d!=0]   \n",
    "trange_ensiqr=trange_ensiqr[mask_xy_3d!=0] \n",
    "\n",
    "print(' -- reshape')\n",
    "# reshpae (nt,ny,nx) -> (nt,ny*nx)\n",
    "pcp_ensiqr = pcp_ensiqr.reshape((nt,-1))\n",
    "tmean_ensiqr = tmean_ensiqr.reshape((nt,-1))\n",
    "tmin_ensiqr = tmin_ensiqr.reshape((nt,-1))\n",
    "tmax_ensiqr = tmax_ensiqr.reshape((nt,-1))\n",
    "trange_ensiqr = trange_ensiqr.reshape((nt,-1))\n",
    "\n",
    "#======================================================================================================    \n",
    "# create a white-blue linear colormap\n",
    "print('create colormap')\n",
    "\n",
    "# reference: https://stackoverflow.com/questions/25408393/getting-individual-colors-from-a-color-map-in-matplotlib\n",
    "cmap = mpl.cm.get_cmap('jet') # get the blue color of jet \n",
    "c0 = cmap(0.0)\n",
    "top = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",c0])\n",
    "\n",
    "# combine two liner colormaps to create a\n",
    "# reference: https://matplotlib.org/3.1.0/tutorials/colors/colormap-manipulation.html\n",
    "bottom = mpl.cm.get_cmap('jet')\n",
    "newcolors = np.vstack((top(np.linspace(0, 1, int(256*0.1))),bottom(np.linspace(0, 1, int(256*0.9)))))\n",
    "newcmp = mpl.colors.LinearSegmentedColormap.from_list(\"WhiteJet\", newcolors)\n",
    "\n",
    "#======================================================================================================\n",
    "# read historical nldas data\n",
    "print('Read nldas data')\n",
    "for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "    nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "    nldas_path = os.path.join(nldas_dir, nldas_file)\n",
    "    \n",
    "    f_nldas = xr.open_dataset(nldas_path)\n",
    "    if yr == start_yr:\n",
    "        pcp = f_nldas['pcp'].values[:] # (time, y, x). unit: mm/day\n",
    "        time = f_nldas['time'].values[:]\n",
    "    else:\n",
    "        pcp = np.concatenate((pcp, f_nldas['pcp'].values[:]), axis = 0)\n",
    "        time = np.concatenate((time, f_nldas['time'].values[:]), axis = 0)\n",
    "\n",
    "# get time mask from nldas data\n",
    "time_obj = pd.to_datetime(time)\n",
    "mask_t  = (time_obj >= plot_date_start_obj) & (time_obj <= plot_date_end_obj) \n",
    "time = time_obj[mask_t]\n",
    "\n",
    "nt_nldas = len(time)\n",
    "mask_xy_3d_nldas = np.repeat(mask_xy[np.newaxis,:,:],nt_nldas,axis=0)\n",
    "\n",
    "pcp = pcp[mask_xy_3d_nldas!=0]    \n",
    "pcp = pcp.reshape((nt_nldas,-1))\n",
    "\n",
    "# calculate DOY (day of year) mean IQR    \n",
    "df_nlds = pd.DataFrame(pcp)    \n",
    "time_month = [t.month for t in time]\n",
    "time_day = [t.day for t in time]\n",
    "df_nlds['month']=time_month\n",
    "df_nlds['date']=time_day  \n",
    "df_nlds2 = df_nlds.groupby(['month','date']).mean()\n",
    "\n",
    "del pcp\n",
    "\n",
    "##======================================================================================================    \n",
    "# read Gamma distribution IQR\n",
    "gamma_iqr = np.loadtxt(nldas_iqr_file, delimiter=',',skiprows=0)\n",
    "gamma_iqr = np.where(gamma_iqr==-999,np.nan,gamma_iqr)\n",
    "\n",
    "#======================================================================================================    \n",
    "# plot\n",
    "print('Plot')\n",
    "var_list = ['Precp (when NLDAS ≠ 0)']\n",
    "var_units = ['(mm/d)']\n",
    "\n",
    "# plot each varaiable seperately\n",
    "nrow = 1\n",
    "ncol = 1           \n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(3.54,3.54*0.75/2.0))\n",
    "\n",
    "data = pcp_ensiqr \n",
    "c_ens = 'b' #'tab:blue'\n",
    "c_gamma = 'r' #'tab:red'\n",
    "\n",
    "# calculate DOY (day of year) mean IQR for GMET and gamma distribution  \n",
    "df = pd.DataFrame(data)    \n",
    "time_month = [t.month for t in time_ensub]\n",
    "time_day = [t.day for t in time_ensub]\n",
    "df['month']=time_month\n",
    "df['date']=time_day    \n",
    "df2 = df.groupby(['month','date']).mean()\n",
    "df3 = df2[df_nlds2!=0]\n",
    "\n",
    "iqr_doy = np.nanmean(df3,axis=1) #[DOY,1]\n",
    "gamma_doy = np.nanmean(gamma_iqr,axis=1) #[DOY,1]\n",
    "\n",
    "# plot IQR\n",
    "ax[i].plot(np.arange(1,1+nt),iqr_doy, color=c_ens, marker='s', \n",
    "           linewidth=0.5, markersize=1, markeredgecolor='none', alpha=0.7, label = 'NLDAS Ensemble')\n",
    "ax[i].plot(np.arange(1,1+nt),gamma_doy, color=c_gamma, marker='^', \n",
    "           linewidth=0.5, markersize=1, markeredgecolor='none', alpha=0.7, label = 'Gamma Distribution')\n",
    "\n",
    "# limit\n",
    "ax[i].set_xlim(1,nt)\n",
    "\n",
    "# label\n",
    "if i == nrow-1:\n",
    "    xlabel = 'Day of Year (DOY) '\n",
    "    ax[i].set_xlabel(xlabel, fontsize='xx-small')\n",
    "ax[i].set_ylabel('IQR '+var_units[i], fontsize='xx-small') \n",
    "\n",
    "# title\n",
    "ax[i].set_title(var_list[i], fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "# tick\n",
    "ax[i].tick_params(axis='both', direction='out',labelsize = 'xx-small',\n",
    "                  length=1, width=0.5, pad=1.5, labelcolor='k')\n",
    "\n",
    "# legend\n",
    "ax[i].legend(loc='upper right', fontsize='xx-small')\n",
    "\n",
    "# change subplot border width\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax[i].spines[axis].set_linewidth(0.5)\n",
    "\n",
    "# save plot\n",
    "fig.tight_layout(pad=0.1, h_pad=0.5) \n",
    "fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value,\n",
    "            bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close(fig)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 79831\n",
      "(79831,)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def ppf25(a,b):\n",
    "    \n",
    "    q25 = gamma.ppf(0.25, a, loc=0, scale=b)\n",
    "    return q25\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "(ny,nx) = np.shape(nldas_arr)\n",
    "print(ny,nx)\n",
    "q25 = np.zeros((ny,nx))\n",
    "q75 = np.zeros((ny,nx))\n",
    "\n",
    "i=0\n",
    "q25[i,:] = [pool.apply(ppf25, args=(alpha[i,j], beta[i,j])) for j in range(nx)]\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    \n",
    "\n",
    "print(np.shape(q25[i,:]))\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan,        nan, 0.0001644 ,\n",
       "        0.00295921, 0.00690483, 0.01068604, 0.01479606, 0.02318049],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q25[0:2,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 3, 3, 3, 0, 1, 3, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "def howmany_within_range(row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "results = [pool.apply(howmany_within_range, args=(row, 4, 8)) for row in data]\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    \n",
    "\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05332500375000003"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.21330002**2)/0.8532001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
