{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read gridinfo mask\n",
      "Read nldas data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/ipykernel_launcher.py:144: RuntimeWarning: Mean of empty slice\n",
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/ipykernel_launcher.py:145: RuntimeWarning: Mean of empty slice\n",
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read NLDAS time: 0:00:05.367726\n",
      "Plot\n",
      "05016grids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/xarray/core/dataarray.py:1658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  3: pd.Panel}\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3e273c19256d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0moutput_namebase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gmet_ens'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ens_forc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mlats_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcp_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmean_ens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange_ens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_ens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_namebase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_yr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_yr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mens_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mtime_ens1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3e273c19256d>\u001b[0m in \u001b[0;36mread_ens\u001b[0;34m(out_forc_name_base, start_yr, end_yr, ens_num)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mlons_ens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mpcp_ens_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mens_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# create ens array for one member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mtmean_ens_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mens_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtrange_ens_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mens_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare two ensemble outputs (e.g., gauge-based GMET and NLDAS-based GMET)\n",
    "\n",
    "import numpy as np\n",
    "import argparse, os\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import netCDF4 as nc\n",
    "\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "def process_command_line():\n",
    "    '''Parse the commandline'''\n",
    "    parser = argparse.ArgumentParser(description='Script to subset a netcdf file based on a list of IDs.')\n",
    "    parser.add_argument('EnsDir', help='path of GMET ens data.')\n",
    "    parser.add_argument('CaseID',help='Sampling case ID.')\n",
    "    parser.add_argument('yr',help='year.')\n",
    "    parser.add_argument('startEns',help='start ensemble member id.')\n",
    "    parser.add_argument('stopEns',help='end ensemble member id.')\n",
    "    parser.add_argument('lb_perct',help='percentile value for lower bound.')\n",
    "    parser.add_argument('ub_perct',help='percentile value for upper bound.')\n",
    "    args = parser.parse_args()\n",
    "    return(args)\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "# process command line\n",
    "args = process_command_line()\n",
    "EnsDir = args.EnsDir\n",
    "CaseID=args.CaseID\n",
    "\n",
    "yr=args.yr\n",
    "startEns=args.startEns   \n",
    "stopEns=args.stopEns  \n",
    "ens_num = (stopEns-startEns+1)\n",
    "\n",
    "lb_perct=args.lb_perct\n",
    "ub_perct=args.ub_perct\n",
    "\n",
    "outdir = os.path.join(EnsDir, CaseID, 'gmet_ens_summary')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "#=================================================================================\n",
    "# read ensemble data\n",
    "for i in range(startEns,stopEns+1):\n",
    "    ens_file = os.path.join(EnsDir, CaseID, 'gmet_ens', 'ens_forc.'+ str(yr) + '.' + str('%03d' % (i)) +'.nc')\n",
    "\n",
    "    f=xr.open_dataset(ens_file)\n",
    "    time = f['time'][:]\n",
    "    pcp = f.variables['pcp'][:]\n",
    "    tmean = f.variables['t_mean'][:]\n",
    "    trange = f.variables['t_range'][:]\n",
    "\n",
    "    if i == 0:\n",
    "        pcp_ens = np.zeros((np.shape(pcp)[0], np.shape(pcp)[1], np.shape(pcp)[2], ens_num))# create ens array for one member\n",
    "        tmean_ens = np.zeros((np.shape(pcp)[0], np.shape(pcp)[1], np.shape(pcp)[2], ens_num))\n",
    "        trange_ens = np.zeros((np.shape(pcp)[0], np.shape(pcp)[1], np.shape(pcp)[2], ens_num))\n",
    "\n",
    "    pcp_ens[:,:,:,i] = pcp\n",
    "    tmean_ens[:,:,:,i] = tmean\n",
    "    trange_ens[:,:,:,i] = trange\n",
    "\n",
    "#=================================================================================\n",
    "# calculate time-series mean values of mean and std. (time,y,x)\n",
    "pcp_ens_mean = np.nanmean(pcp_ens, axis = 3)\n",
    "pcp_ens_median = np.nanmedian(pcp_ens, axis = 3)\n",
    "pcp_ens_std = np.std(pcp_ens, axis = 3)\n",
    "pcp_ens_lb = np.percentile(pcp_ens, lb_perct, axis = 3)\n",
    "pcp_ens_ub = np.percentile(pcp_ens, ub_perct, axis = 3)\n",
    "del pcp_ens\n",
    "\n",
    "tmean_ens_mean = np.nanmean(tmean_ens, axis = 3)\n",
    "tmean_ens_median = np.nanmedian(tmean_ens, axis = 3)\n",
    "tmean_ens_std = np.std(tmean_ens, axis = 3)\n",
    "tmean_ens_lb = np.percentile(tmean_ens, lb_perct, axis = 3)\n",
    "tmean_ens_ub = np.percentile(tmean_ens, ub_perct, axis = 3)\n",
    "del tmean_ens\n",
    "\n",
    "trange_ens_mean = np.nanmean(trange_ens, axis = 3)\n",
    "trange_ens_median = np.nanmedian(trange_ens, axis = 3)\n",
    "trange_ens_std = np.std(trange_ens, axis = 3)\n",
    "trange_ens_lb = np.percentile(trange_ens, lb_perct, axis = 3)\n",
    "trange_ens_ub = np.percentile(trange_ens, ub_perct, axis = 3)\n",
    "del trange_ens\n",
    "\n",
    "#=================================================================================\n",
    "#save statistics summary\n",
    "SrcFile=os.path.join(EnsDir, CaseID, 'gmet_ens', 'ens_forc.'+ str(yr) + '.001.nc')\n",
    "with nc.Dataset(SrcFile) as src:\n",
    "\n",
    "    for i in range(startEns,stopEns+1):\n",
    "        DstFile = os.path.join(outdir, 'ens_forc.'+ str(yr) + '.' + str('%03d' % (i)) +'.nc')\n",
    "        with nc.Dataset(DstFile, \"w\") as dst:\n",
    "\n",
    "            # copy dimensions\n",
    "            for name, dimension in src.dimensions.items():\n",
    "                 dst.createDimension(\n",
    "                    name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "\n",
    "            # copy variable attributes all at once via dictionary (for the included variables)\n",
    "            include = ['latitude', 'longitude', 'time']\n",
    "            for name, variable in src.variables.items():\n",
    "                x = dst.createVariable(name, variable.datatype, variable.dimensions)               \n",
    "                dst[name].setncatts(src[name].__dict__)\n",
    "                if name in include:\n",
    "                    dst[name][:]=src[name][:]                \n",
    "\n",
    "            # create summary variables \n",
    "            vars_short = ['pcp_mean','pcp_median','pcp_std','pcp_ub','pcp_lb',\n",
    "                         'tmean_mean','tmean_median','tmean_std','tmean_ub','tmean_lb',\n",
    "                         'trange_mean','trange_median','trange_std','trange_ub','trange_lb']\n",
    "            vars_long = ['Mean daily precipitation','Median daily precipitation',\n",
    "                         'Standard deviation of daily precipitation','90th percentile of daily precipitation','5th percentile of daily precipitation',\n",
    "                         'Mean daily temperature', 'Median daily temperature',\n",
    "                         'Standard deviation of daily mean temperature','90th percentile of daily mean temperature','5th percentile of daily mean temperature',\n",
    "                         'Mean daily temperature range', 'Median daily temperature range',\n",
    "                         'Standard deviation of daily temperature range','90th percentile of daily temperature range','5th percentile of daily temperature range']\n",
    "            units = ['mm/day', 'mm/day', 'mm/day', 'mm/day',\n",
    "                     'degC', 'degC', 'degC', 'degC',\n",
    "                     'degC', 'degC', 'degC', 'degC',]\n",
    "\n",
    "            for i, var in enumerate(vars_short):\n",
    "                var_i = dst.createVariable(var,np.float64,('time','y','x')) # note: unlimited dimension is leftmost\n",
    "                var_i.long_name = vars_long[i]\n",
    "                var_i.units = units[i] \n",
    "\n",
    "            dst.variables['pcp_mean'][:] = pcp_ens_mean\n",
    "            dst.variables['pcp_median'][:] = pcp_ens_median\n",
    "            dst.variables['pcp_std'][:] = pcp_ens_std \n",
    "            dst.variables['pcp_ub'][:] = pcp_ens_lb\n",
    "            dst.variables['pcp_lb'][:] = pcp_ens_ub \n",
    "\n",
    "            dst.variables['tmean_mean'][:] = tmean_ens_mean\n",
    "            dst.variables['tmean_median'][:] = tmean_ens_median\n",
    "            dst.variables['tmean_std'][:] = tmean_ens_std \n",
    "            dst.variables['tmean_ub'][:] = tmean_ens_lb\n",
    "            dst.variables['tmean_lb'][:] = tmean_ens_ub \n",
    "            \n",
    "            dst.variables['trange_mean'][:] = trange_ens_mean\n",
    "            dst.variables['trange_median'][:] = trange_ens_median\n",
    "            dst.variables['trange_std'][:] = trange_ens_std \n",
    "            dst.variables['trange_ub'][:] = trange_ens_lb\n",
    "            dst.variables['trange_lb'][:] = trange_ens_ub \n",
    "            \n",
    "print('Done')\n",
    "print(datetime.datetime.now()-startTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(prcp_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENTER]",
   "language": "python",
   "name": "conda-env-ENTER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
