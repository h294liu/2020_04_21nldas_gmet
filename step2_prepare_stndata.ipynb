{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read nldas data\n",
      "Write\n",
      "stndata_00822grids\n",
      "stndata_00986grids\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "\n",
    "root_dir = '/glade/u/home/hongli/work/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc')\n",
    "stnlist_dir = os.path.join(root_dir, 'scripts/step4_sample_stnlist')\n",
    "stnlist_name_base = 'stnlist'\n",
    "\n",
    "time_format='%Y-%m-%d'\n",
    "start_yr = 2015\n",
    "end_yr = 2016\n",
    "\n",
    "time_format='%Y-%m-%d'\n",
    "extract_start_date = '2015-01-01'\n",
    "extract_end_date   = '2016-12-31'\n",
    "\n",
    "outfolder = 'scripts/step2_prepare_stndata'\n",
    "if not os.path.exists(os.path.join(root_dir, outfolder)):\n",
    "    os.makedirs(os.path.join(root_dir, outfolder))\n",
    "outnc_tpl = os.path.join(root_dir, 'scripts/stn_data_tpl.nc')\n",
    "\n",
    "# ============================================================================================================\n",
    "# read historical nldas \n",
    "print('Read nldas data')\n",
    "for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "    nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "    nldas_path = os.path.join(nldas_dir, nldas_file)\n",
    "    \n",
    "    f_nldas = xr.open_dataset(nldas_path)\n",
    "    if yr == start_yr:\n",
    "        prcp_avg = f_nldas['prcp_avg'].values[:] # (time, lat, lon). unit: kg/m^2 = mm\n",
    "        tair_min = f_nldas['tair_min'].values[:] # (time, lat, lon). unit: K\n",
    "        tair_max = f_nldas['tair_max'].values[:]\n",
    "        time = pd.to_datetime(f_nldas['time'].values[:]).strftime(time_format)\n",
    "    else:\n",
    "        prcp_avg = np.concatenate((prcp_avg, f_nldas['prcp_avg'].values[:]), axis = 0)\n",
    "        tair_min = np.concatenate((tair_min, f_nldas['tair_min'].values[:]), axis = 0)\n",
    "        tair_max = np.concatenate((tair_max, f_nldas['tair_max'].values[:]), axis = 0)\n",
    "        time = np.concatenate((time, pd.to_datetime(f_nldas['time'].values[:]).strftime(time_format)), axis = 0)\n",
    "    f_nldas.close()\n",
    "    \n",
    "prcp_sum = np.multiply(prcp_avg, 24.0) #mm/hr to mm/day\n",
    "tair_min = np.subtract(tair_min, 273.15)\n",
    "tair_max = np.subtract(tair_max, 273.15)\n",
    "\n",
    "# nldas mask on the time dimension\n",
    "time_obj = np.asarray([datetime.datetime.strptime(t, time_format) for t in time])\n",
    "start_date_obj = datetime.datetime.strptime(extract_start_date, time_format)\n",
    "end_date_obj = datetime.datetime.strptime(extract_end_date, time_format)\n",
    "nldas_mask  = (time_obj >= start_date_obj) & (time_obj <= end_date_obj) \n",
    "\n",
    "# ============================================================================================================\n",
    "# write point output one-by-one\n",
    "print('Write')\n",
    "stnlist_files = [f for f in os.listdir(stnlist_dir) if stnlist_name_base in f]\n",
    "stnlist_files = sorted(stnlist_files)\n",
    "\n",
    "include = ['GHCND_id', 'elevation', 'latitude', 'longitude', 'prcp', 'time', 'tmax', 'tmin']\n",
    "\n",
    "with nc.Dataset(outnc_tpl) as src:\n",
    "    for stnlist_file in stnlist_files:\n",
    "#     for stnlist_file in stnlist_files[0:1]:\n",
    "        \n",
    "        # create sub-outfolder\n",
    "        sub_folder = 'stndata_'+(stnlist_file.split('.')[0].split('_')[1])\n",
    "        if not os.path.exists(os.path.join(root_dir, outfolder, sub_folder)):\n",
    "            os.makedirs(os.path.join(root_dir, outfolder, sub_folder)) \n",
    "        print(sub_folder)\n",
    "\n",
    "        # read selected stn list \n",
    "        stn_ids = np.loadtxt(os.path.join(stnlist_dir,stnlist_file), skiprows=2, usecols=[0], delimiter=',', dtype='str') # STA_ID[0], LAT[1], LON[2] ELEV[3], SLP_N[4], SLP_E[5], STA_NAME[6]\n",
    "        stnlist = np.loadtxt(os.path.join(stnlist_dir,stnlist_file), skiprows=2, usecols=[1,2,3,4,5], delimiter=',') \n",
    "        stn_num = len(stn_ids)\n",
    "\n",
    "        for i in range(stn_num):\n",
    "            stn_id = stn_ids[i]    \n",
    "            stn_lat_id = int(stn_id[3:3+3]) #start from zero\n",
    "            stn_lon_id = int(stn_id[9:9+3]) #start from zero\n",
    "#             print(stn_id)\n",
    "\n",
    "            with nc.Dataset(os.path.join(root_dir, outfolder, sub_folder, stn_id+'.nc'), \"w\") as dst:\n",
    "\n",
    "                # copy dimensions\n",
    "                for name, dimension in src.dimensions.items():\n",
    "                     dst.createDimension(\n",
    "                        name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "\n",
    "                # copy variable attributes all at once via dictionary (for the included variables)\n",
    "                for name, variable in src.variables.items():\n",
    "                    if name in include:\n",
    "                        x = dst.createVariable(name, variable.datatype, variable.dimensions)               \n",
    "                        dst[name].setncatts(src[name].__dict__)\n",
    "\n",
    "                # assign values for variables ([:] is necessary)\n",
    "                dst.variables['GHCND_id'][:] = nc.stringtochar(np.array([stn_id], dtype='S'))\n",
    "                dst.variables['latitude'][:] = stnlist[i,0]\n",
    "                dst.variables['longitude'][:] = stnlist[i,1]\n",
    "                dst.variables['elevation'][:] = stnlist[i,2]\n",
    "\n",
    "                dst.variables['time'][:] = nc.date2num(time_obj[nldas_mask], dst.variables['time'].units)\n",
    "                dst.variables['tmax'][:] = tair_max[nldas_mask,stn_lat_id, stn_lon_id]\n",
    "                dst.variables['tmin'][:] = tair_min[nldas_mask,stn_lat_id, stn_lon_id]\n",
    "                dst.variables['prcp'][:] = prcp_sum[nldas_mask,stn_lat_id, stn_lon_id]          \n",
    "# del prcp_sum, tair_min, tair_max\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Row0Col110'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stn_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENTER]",
   "language": "python",
   "name": "conda-env-ENTER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
