{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create colormap\n",
      "Plot\n",
      "Precp'\n",
      "Tmean_2\n",
      "Trange_2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert_summary')\n",
    "start_yr = 2007 #1979 #2013\n",
    "end_yr = 2016 #2019 #2016\n",
    "\n",
    "nldas_grid_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "scenarios_ids = range(0,9) #[0,1,5,8] \n",
    "intervals =  range(10,1,-1) #[10,9,5,2]\n",
    "scenario_num = len(scenarios_ids)\n",
    "\n",
    "subforlder = 'gmet_regr_summary'\n",
    "file_basename = 'regress_ts_'\n",
    "transfm_power = 1/4.0\n",
    "\n",
    "ens_num = 100\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "dpi_value = 150\n",
    "plot_date_start = '2007-01-01' #'1979-01-01' #'2013-01-01'\n",
    "plot_date_end = '2016-12-31' #'2019-12-31' #'2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "output_dir=os.path.join(root_dir, 'scripts/step23_plot_regr_nldas_scatter')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_filename_base = 'step23_plot_regr_nldas_scatter_'\n",
    "    \n",
    "# #======================================================================================================\n",
    "# print('Read gridinfo mask')\n",
    "# # get xy mask from gridinfo.nc\n",
    "# f_gridinfo = xr.open_dataset(nldas_grid_file)\n",
    "# nldas_mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "# mask_xy = (nldas_mask_xy!=0) \n",
    "\n",
    "# #======================================================================================================\n",
    "# # read scenario ensemble results and save to dictionary\n",
    "# print('Read regression result')\n",
    "# for k in range(scenario_num):\n",
    "\n",
    "#     test_folder = test_folders[scenarios_ids[k]]\n",
    "    \n",
    "#     print(test_folder)\n",
    "#     test_dir = os.path.join(result_dir, test_folder)\n",
    "#     fig_title= test_folder\n",
    "\n",
    "#     print(' -- read spatial ensemble mean')\n",
    "#     # read ensemble mean \n",
    "#     print('pcp')\n",
    "#     output_basename = os.path.join(test_dir,subforlder,file_basename)\n",
    "#     f=xr.open_dataset(os.path.join(output_basename+'pcp.nc'))\n",
    "#     pcp_regr = f.variables['pcp'].values[:]\n",
    "#     pcp_regr_transfm = (np.power(pcp_regr*transfm_power+1, 1/transfm_power))  #Cox-Box back-transform P  \n",
    "#     time = f['time'].values[:]\n",
    "#     time_regr = pd.DatetimeIndex(time)\n",
    "    \n",
    "#     print('pcp_2')\n",
    "#     f=xr.open_dataset(os.path.join(output_basename+'pcp_2.nc'))\n",
    "#     pcp_2_regr = f.variables['pcp_2'].values[:]\n",
    "#     pcp_2_regr_transfm = (np.power(pcp_2_regr*transfm_power+1, 1/transfm_power))  #Cox-Box back-transform P  \n",
    "    \n",
    "#     print('tmean_2')\n",
    "#     f=xr.open_dataset(os.path.join(output_basename+'tmean_2.nc'))\n",
    "#     tmean_2_regr = f.variables['tmean_2'].values[:]\n",
    "\n",
    "#     print('trange_2')\n",
    "#     f=xr.open_dataset(os.path.join(output_basename+'trange_2.nc'))\n",
    "#     trange_2_regr = f.variables['trange_2'].values[:]           \n",
    "\n",
    "#     # define plot mask for nldas ensemble\n",
    "#     mask_ens_t = (time_regr>=plot_date_start_obj) & (time_regr<=plot_date_end_obj)\n",
    "    \n",
    "#     print(' -- calculate temporal mean')\n",
    "#     # caluclate time series mean(ny,nx)\n",
    "#     pcp_regr = np.nanmean(pcp_regr_transfm[mask_ens_t,:,:],axis=0)     \n",
    "#     pcp_2_regr = np.nanmean(pcp_2_regr_transfm[mask_ens_t,:,:],axis=0)     \n",
    "#     tmean_2_regr = np.nanmean(tmean_2_regr[mask_ens_t,:,:],axis=0)\n",
    "#     trange_2_regr = np.nanmean(trange_2_regr[mask_ens_t,:,:],axis=0)\n",
    "\n",
    "#     print(' -- extract unmasked values')\n",
    "#     # extract unmasked values\n",
    "#     pcp_regr=pcp_regr[mask_xy]    \n",
    "#     pcp_2_regr=pcp_2_regr[mask_xy]    \n",
    "#     tmean_2_regr=tmean_2_regr[mask_xy] \n",
    "#     trange_2_regr=trange_2_regr[mask_xy] \n",
    "    \n",
    "#     # save to array\n",
    "#     if k == 0:\n",
    "#         grid_num = len(pcp_regr)\n",
    "#         pcp_regr_arr = np.zeros((grid_num,scenario_num+1)) #one more column for raw nldas\n",
    "#         pcp_2_regr_arr = np.zeros((grid_num,scenario_num+1)) \n",
    "#         tmean_2_regr_arr = np.zeros((grid_num,scenario_num+1)) \n",
    "#         trange_2_regr_arr = np.zeros((grid_num,scenario_num+1)) \n",
    "\n",
    "#     pcp_regr_arr[:,k] = pcp_regr \n",
    "#     pcp_2_regr_arr[:,k] = pcp_2_regr\n",
    "#     tmean_2_regr_arr[:,k] = tmean_2_regr  \n",
    "#     trange_2_regr_arr[:,k] = trange_2_regr    \n",
    "\n",
    "#     del time_regr, pcp_regr, pcp_2_regr, tmean_2_regr, trange_2_regr, pcp_regr_transfm, pcp_2_regr_transfm\n",
    "\n",
    "# #======================================================================================================\n",
    "# # read historical nldas data\n",
    "# print('Read nldas data')\n",
    "# print(' -- read spatial data')\n",
    "# print('pcp')\n",
    "# f_nldas = xr.open_dataset(os.path.join(nldas_dir, 'NLDAS_pcp.nc'))\n",
    "# time = f_nldas['time'].values[:]\n",
    "# pcp = f_nldas['pcp'].values[:] # (time, y, x). unit: mm/day\n",
    "\n",
    "# print('t_mean')\n",
    "# f_nldas = xr.open_dataset(os.path.join(nldas_dir, 'NLDAS_t_mean.nc'))                     \n",
    "# t_mean = f_nldas['t_mean'].values[:] # (time, y, x). unit: degC\n",
    "\n",
    "# print('t_range')\n",
    "# f_nldas = xr.open_dataset(os.path.join(nldas_dir, 'NLDAS_t_range.nc'))\n",
    "# t_range = f_nldas['t_range'].values[:]\n",
    "\n",
    "# # get time mask from nldas data\n",
    "# time_obj = pd.to_datetime(time)\n",
    "# mask_t  = (time_obj >= plot_date_start_obj) & (time_obj <= plot_date_end_obj) \n",
    "# time = time_obj[mask_t]\n",
    "\n",
    "# # # time series mean\n",
    "# # # pcp_transfm = np.power(pcp[mask_t,:,:],transfm_power) #power-law transform P  \n",
    "# # pcp_transfm = (np.power(pcp[mask_t,:,:],transfm_power) - 1)/transfm_power #Cox-Box transform P  \n",
    "\n",
    "# print(' -- calculate temporal mean')\n",
    "# prcp_mean = np.nanmean(pcp, axis=0) #(y, x))\n",
    "# tmean_mean = np.nanmean(t_mean[mask_t,:,:], axis=0) \n",
    "# trange_mean = np.nanmean(t_range[mask_t,:,:], axis=0)\n",
    "\n",
    "# print(' -- extract unmasked values')\n",
    "# # extract unmasked values\n",
    "# prcp_mean=prcp_mean[mask_xy]\n",
    "# tmean_mean=tmean_mean[mask_xy]\n",
    "# trange_mean=trange_mean[mask_xy]\n",
    "\n",
    "# # save to array\n",
    "# pcp_regr_arr[:,-1] = prcp_mean \n",
    "# pcp_2_regr_arr[:,-1] = prcp_mean\n",
    "# tmean_2_regr_arr[:,-1] = tmean_mean \n",
    "# trange_2_regr_arr[:,-1] = trange_mean \n",
    "\n",
    "# del pcp,t_mean,t_range\n",
    "\n",
    "# #======================================================================================================    \n",
    "# # SAVE\n",
    "# print('Save')\n",
    "# var_list = [\"Precp'\", \"Precp_2'\", 'Tmean_2', 'Trange_2']\n",
    "    \n",
    "# # save mean value for re-use\n",
    "# for i in range(4):\n",
    "\n",
    "#     if i == 0:\n",
    "#         data=pcp_regr_arr\n",
    "#     elif i == 1:\n",
    "#         data=pcp_2_regr_arr\n",
    "#     elif i == 2:\n",
    "#         data=tmean_2_regr_arr\n",
    "#     elif i == 3:\n",
    "#         data=trange_2_regr_arr\n",
    "        \n",
    "#     output_filename_txt = var_list[i]+'_regr.txt'\n",
    "#     np.savetxt(os.path.join(output_dir, output_filename_txt), data, delimiter=',',\n",
    "#                fmt='%f',header='Col is sample scenario. Row is the time-series mean of regr in flatten valid grids. The last col is for raw NLDAS.')\n",
    "\n",
    "#======================================================================================================    \n",
    "# create a white-blue linear colormap\n",
    "print('create colormap')\n",
    "\n",
    "# reference: https://stackoverflow.com/questions/25408393/getting-individual-colors-from-a-color-map-in-matplotlib\n",
    "cmap = mpl.cm.get_cmap('jet') # get the blue color of jet \n",
    "c0 = cmap(0.0)\n",
    "top = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",c0])\n",
    "\n",
    "# combine two liner colormaps to create a\n",
    "# reference: https://matplotlib.org/3.1.0/tutorials/colors/colormap-manipulation.html\n",
    "bottom = mpl.cm.get_cmap('jet')\n",
    "newcolors = np.vstack((top(np.linspace(0, 1, int(256*0.15))),bottom(np.linspace(0, 1, int(256*0.85)))))\n",
    "newcmp = mpl.colors.LinearSegmentedColormap.from_list(\"WhiteJet\", newcolors)\n",
    "\n",
    "#======================================================================================================    \n",
    "# plot \n",
    "print('Plot')\n",
    "var_list = [\"Precp'\", 'Tmean_2', 'Trange_2'] #\"Precp_2'\",\n",
    "title_list = [\"Precipitation\", 'Tmean', 'Trange']\n",
    "var_units = ['(mm/day)','($^\\circ$C)','($^\\circ$C)']\n",
    "for m in range(len(var_list)): # loop all variables\n",
    "    var = var_list[m]\n",
    "    output_filename = output_filename_base+var+'.png'\n",
    "    print(var)\n",
    "    \n",
    "    # data load    \n",
    "    output_filename_txt = var_list[m]+'_regr.txt'\n",
    "    data = np.loadtxt(os.path.join(output_dir, output_filename_txt), delimiter=',', skiprows=1)\n",
    "    mean = data[:,-1]\n",
    "    ensmean_arr = data[:,0:-1]\n",
    "    \n",
    "    # xy aixs range\n",
    "    vmin_regr=np.nanmin([np.nanmin(ensmean_arr[:,k]) for k in range(scenario_num)])\n",
    "    vmax_regr=np.nanmax([np.nanmax(ensmean_arr[:,k]) for k in range(scenario_num)])\n",
    "\n",
    "#     vmin = np.nanmin([vmin_regr,np.nanmin(mean)])\n",
    "#     vmax = np.nanmax([vmax_regr,np.nanmax(mean)])\n",
    "    vmin = np.nanmin(mean)\n",
    "    vmax = np.nanmax(mean)\n",
    "    \n",
    "    # MAE\n",
    "    mae=[np.nanmean(np.absolute(ensmean_arr[:,k]-mean)) for k in range(scenario_num)]    \n",
    "    \n",
    "    # plot each varaiable seperately\n",
    "    nrow = 3 # totally 9 sampling scenarios\n",
    "    ncol = 3\n",
    "            \n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(4.5,4.5*1.0))\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            k = i*ncol+j\n",
    "            \n",
    "#             print('sample scenario '+str(k+1))\n",
    "\n",
    "            # 2D histograms\n",
    "            # https://python-graph-gallery.com/83-basic-2d-histograms-with-matplotlib/\n",
    "            x = mean\n",
    "            y = ensmean_arr[:,k]\n",
    "            hist = ax[i,j].hist2d(x, y, bins=(200, 200),cmap=newcmp, \n",
    "                                  range=[[vmin, vmax], [vmin, vmax]]) # return (counts, xedges, yedges, Image)\n",
    "    \n",
    "            # diagonal\n",
    "            ax[i,j].plot([vmin, vmax],[vmin, vmax],color='grey',linewidth=0.5, alpha=0.6)\n",
    "            \n",
    "            # MAE text\n",
    "            ax[i,j].annotate((r'$\\overline{MAE}$=%.2f') %(mae[k]), xy=(0.05, 0.87), \n",
    "                             xycoords='axes fraction',fontsize='xx-small',fontstyle='italic')\n",
    "\n",
    "            # limit\n",
    "            ax[i,j].set_xlim(vmin, vmax)\n",
    "            ax[i,j].set_ylim(vmin, vmax)\n",
    "\n",
    "            # label\n",
    "            if i == nrow-1:\n",
    "                xlabel = 'NLDAS ' + var_units[m]\n",
    "                ax[i,j].set_xlabel(xlabel, fontsize='xx-small')\n",
    "            if j == 0:\n",
    "                ylabel = 'Estimation ' + var_units[m]\n",
    "                ax[i,j].set_ylabel(ylabel, fontsize='xx-small')\n",
    "             \n",
    "            # tick\n",
    "            ax[i,j].tick_params(axis='both', direction='out',labelsize = 'xx-small', \n",
    "                                length=2, width=0.5, pad=1.2) #\n",
    "            if j == 0:\n",
    "                ax[i,j].tick_params(axis='both',labelleft = True)\n",
    "            else:\n",
    "                ax[i,j].tick_params(axis='both',labelleft = False)\n",
    "            if i == nrow-1:\n",
    "                ax[i,j].tick_params(axis='both',labelbottom = True)\n",
    "            else:\n",
    "                ax[i,j].tick_params(axis='both',labelbottom = False)\n",
    "                \n",
    "            # title\n",
    "            title_str = 'Scenario '+str(k+1) +' (interval = '+str(intervals[k])+')'\n",
    "            ax[i,j].set_title(title_str, fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "           # change subplot border width\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax[i,j].spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    # colorbar    \n",
    "    fig.subplots_adjust(bottom=0.15, top=1, left = 0, right=1, wspace = 0.07, hspace = 0.25)\n",
    "    cax = fig.add_axes([0.25, 0.05, 0.5, 0.02]) #[left, bottom, width, height]\n",
    "    cbar = fig.colorbar(hist[3], cax=cax, orientation='horizontal')\n",
    "\n",
    "    tick1 = hist[0].max()*0.5\n",
    "    tick2 = hist[0].max()\n",
    "    cbar.set_ticks([0, tick1, tick2]) \n",
    "    cbar.set_ticklabels(['Low', 'Medium', 'High'])  \n",
    "    cbar.ax.tick_params(labelsize='xx-small', length=2, width=1)\n",
    "\n",
    "    # set the colorbar ticks and tick labels\n",
    "#     cbar.set_label(label='Number of grids per pixel',size='xx-small')    \n",
    "    cbar.set_label(label='Number of grids',size='xx-small')    \n",
    "\n",
    "    # save plot\n",
    "    fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value, \n",
    "                bbox_inches = 'tight', pad_inches = 0.05)\n",
    "    plt.close(fig)\n",
    "\n",
    "print('Done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "output_filename_txt = var_list[m]+'_regr.txt'\n",
    "data = np.loadtxt(os.path.join(output_dir, output_filename_txt), delimiter=',', skiprows=1)\n",
    "mean = data[:,-1]\n",
    "ensmean_arr = data[:,0:-1]\n",
    "\n",
    "# xy aixs range\n",
    "vmin_regr=np.nanmin([np.nanmin(ensmean_arr[:,k]) for k in range(scenario_num)])\n",
    "vmax_regr=np.nanmax([np.nanmax(ensmean_arr[:,k]) for k in range(scenario_num)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7626.542207"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ensmean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(trange_mean<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'density' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-b8b33d7223ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'density' is not defined"
     ]
    }
   ],
   "source": [
    "np.nanmax(density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
