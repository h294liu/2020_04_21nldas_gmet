{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load library, function, and other inputs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = '/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/share/proj'\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pyproj import Proj\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_nldas(file_dir, date_start_obj, date_end_obj, mask_xy):\n",
    "    start_yr = int(datetime.datetime.strftime(date_start_obj,'%Y'))\n",
    "    end_yr = int(datetime.datetime.strftime(date_end_obj,'%Y'))\n",
    "    \n",
    "    for yr in range(start_yr, end_yr+1):\n",
    "        nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "        nldas_path = os.path.join(file_dir, nldas_file)\n",
    "        f_nldas = xr.open_dataset(nldas_path)\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            pcp_concat = f_nldas['pcp'].values[:] # (time, y, x). unit: mm/day\n",
    "            tmean_concat = f_nldas['t_mean'].values[:] # (time, y, x). unit: degC\n",
    "#             t_range_concat = f_nldas['t_range'].values[:]\n",
    "            time_concat = f_nldas['time'].values[:]\n",
    "        else:\n",
    "            pcp_concat = np.concatenate((pcp_concat, f_nldas['pcp'].values[:]), axis = 0)\n",
    "            tmean_concat = np.concatenate((tmean_concat, f_nldas['t_mean'].values[:]), axis = 0)\n",
    "#             trange_concat = np.concatenate((trange_concat, f_nldas['t_range'].values[:]), axis = 0)\n",
    "            time_concat = np.concatenate((time_concat, f_nldas['time'].values[:]), axis = 0)\n",
    "\n",
    "    # get time mask from nldas data\n",
    "    time_obj = pd.to_datetime(time_concat)    \n",
    "    \n",
    "    mask_t  = (time_obj >= date_start_obj) & (time_obj <= date_end_obj) \n",
    "    time_obj = time_obj[mask_t]\n",
    "    pcp_concat=np.where(mask_xy==0,np.nan,pcp_concat[mask_t,:,:])  # convert masked values to nan  \n",
    "    tmean_concat=np.where(mask_xy==0,np.nan,tmean_concat[mask_t,:,:])  \n",
    "    return time_obj, pcp_concat, tmean_concat#, t_range_concat\n",
    "\n",
    "def read_ens_mb(file_dir, mb, date_start_obj, date_end_obj, mask_xy):\n",
    "    start_yr = int(datetime.datetime.strftime(date_start_obj,'%Y'))\n",
    "    end_yr = int(datetime.datetime.strftime(date_end_obj,'%Y'))\n",
    "    \n",
    "    for yr in range(start_yr, end_yr+1):                \n",
    "        filename='ens_forc.%d.%03d.nc'%(yr,mb)\n",
    "        file = os.path.join(file_dir, filename)\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'].values[:]\n",
    "        pcp = f['pcp'].values[:]\n",
    "        tmean = f['t_mean'].values[:]\n",
    "#        trange = f['t_range'].values[:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            tmean_concat = tmean\n",
    "#             trange_concat = trange\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_concat = np.concatenate((pcp_concat, pcp), axis=0) # (time,y,x)\n",
    "            tmean_concat = np.concatenate((tmean_concat, tmean), axis=0)\n",
    "#             trange_concat = np.concatenate((trange_concat, trange), axis=0)            \n",
    "    \n",
    "    time_obj = pd.to_datetime(time_concat)   \n",
    "    \n",
    "    mask_t  = (time_obj >= date_start_obj) & (time_obj <= date_end_obj) \n",
    "    time_obj = time_obj[mask_t]\n",
    "    pcp_concat=np.where(mask_xy==0,np.nan,pcp_concat[mask_t,:,:])  # convert masked values to nan  \n",
    "    tmean_concat=np.where(mask_xy==0,np.nan,tmean_concat[mask_t,:,:])  \n",
    "    return time_obj, pcp_concat, tmean_concat#, trange_concat\n",
    "\n",
    "def read_ens_std(file_dir, date_start_obj, date_end_obj, mask_xy):\n",
    "    start_yr = int(datetime.datetime.strftime(date_start_obj,'%Y'))\n",
    "    end_yr = int(datetime.datetime.strftime(date_end_obj,'%Y'))\n",
    "    \n",
    "    for yr in range(start_yr, end_yr+1):                \n",
    "        \n",
    "        filename='ens_forc.%d.ensstd.nc'%(yr)\n",
    "        file = os.path.join(file_dir, filename)\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'].values[:]\n",
    "        pcp_error = f['pcp'].values[:] # std\n",
    "        tmean_error = f['t_mean'].values[:]\n",
    "#         trange_error = f['t_range'].values[:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_error_concat = pcp_error\n",
    "            tmean_error_concat = tmean_error\n",
    "#             trange_error_concat = trange_error\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_error_concat = np.concatenate((pcp_error_concat, pcp_error), axis=0) # (time,y,x)\n",
    "            tmean_error_concat = np.concatenate((tmean_error_concat, tmean_error), axis=0)\n",
    "#             trange_error_concat = np.concatenate((trange_error_concat, trange_error), axis=0)\n",
    "            \n",
    "    time_obj = pd.to_datetime(time_concat)        \n",
    "    mask_t  = (time_obj >= date_start_obj) & (time_obj <= date_end_obj) \n",
    "    time_obj = time_obj[mask_t]\n",
    "    pcp_error_concat=np.where(mask_xy==0,np.nan,pcp_error_concat[mask_t,:,:])  # convert masked values to nan  \n",
    "    tmean_error_concat=np.where(mask_xy==0,np.nan,tmean_error_concat[mask_t,:,:])  \n",
    "    return time_obj, pcp_error_concat, tmean_error_concat#, trange_error_concat\n",
    "\n",
    "def plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx):\n",
    "\n",
    "    m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='cyl', ax=ax)   \n",
    "#     m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='tmerc', ax=ax,lat_0=lat_0,lon_0=lon_0)\n",
    "\n",
    "    m.drawstates(linewidth=0.5, linestyle='solid', color='grey')\n",
    "    m.drawcountries(linewidth=0.5, linestyle='solid', color='k')\n",
    "    m.drawcoastlines(linewidth=.25, linestyle='solid', color='k')\n",
    "    return m\n",
    "\n",
    "def set_box_color(bp, color):\n",
    "    plt.setp(bp['boxes'], color=color)\n",
    "    plt.setp(bp['whiskers'], color=color)\n",
    "    plt.setp(bp['caps'], color=color)\n",
    "    plt.setp(bp['medians'], color=color)\n",
    "    return\n",
    "\n",
    "# set the colormap and centre the colorbar\n",
    "class MidpointNormalize(mpl.colors.Normalize):\n",
    "    \"\"\"Normalise the colorbar.\n",
    "    source: http://chris35wills.github.io/matplotlib_diverging_colorbar/\n",
    "    e.g. im=ax1.imshow(array, norm=MidpointNormalize(midpoint=0.,vmin=-300, vmax=1000))    \n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mpl.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y), np.isnan(value))\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "gridinfo_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "test_folder =test_folders[-2]\n",
    "\n",
    "regress_subforlder = 'gmet_regr'\n",
    "ens_subforlder = 'gmet_ens_bc'\n",
    "ens_stat_subforlder='gmet_ens_bc_summary'\n",
    "\n",
    "ens_num = 100 #100\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "dpi_value = 150\n",
    "date_starts = ['2016-02-01','2016-08-01'] # list of start dates of plot time periods\n",
    "date_ends = ['2016-02-29','2016-08-31']   # list of end dates of plot time periods\n",
    "grids = [[40,265],[40,265]]               # xid and yid of the spatial distribution\n",
    "# date_starts = ['2016-08-09']\n",
    "# date_ends = ['2016-08-20']\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "output_dir=os.path.join(root_dir, 'scripts/step35_statistical_perturb_NLDAS_v2')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read gridinfo mask\n",
      "---- 2016-02-01 - 2016-02-29 ----\n",
      "Read nldas data\n",
      "Read ensemble std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read ensemble data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb NLADS Precip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb NLADS Tmean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 2016-08-01 - 2016-08-31 ----\n",
      "Read nldas data\n",
      "Read ensemble std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read ensemble data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:01<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb NLADS Precip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturb NLADS Tmean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#======================================================================================================\n",
    "# PART 1. Read gridinfo mask\n",
    "print('Read gridinfo mask')\n",
    "# get xy mask from gridinfo.nc\n",
    "f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "latitude = f_gridinfo['latitude'].values[:]\n",
    "longitude = f_gridinfo['longitude'].values[:]\n",
    "\n",
    "# prepare for basemap plot\n",
    "llcrnrlon = longitude[0,0]\n",
    "urcrnrlon = longitude[-1,-1]\n",
    "llcrnrlat = latitude[0,0]\n",
    "urcrnrlat = latitude[-1,-1]\n",
    "lat_0=0.5*(llcrnrlat+urcrnrlat)\n",
    "lon_0=0.5*(llcrnrlon+urcrnrlon)\n",
    "(ny,nx)=np.shape(longitude)\n",
    "\n",
    "# PART 2. read and save data for different time periods (pt)\n",
    "data_dic={}\n",
    "for pt in range(len(date_starts)):\n",
    "# for pt in range(1):\n",
    "    key=str(pt)\n",
    "    data_dic[key]={}\n",
    "    \n",
    "    #======================================================================================================\n",
    "    # PART 2.1 determine useful time period\n",
    "    date_start_obj = datetime.datetime.strptime(date_starts[pt], time_format)\n",
    "    date_end_obj = datetime.datetime.strptime(date_ends[pt], time_format)\n",
    "    [xid,yid]=grids[pt]\n",
    "    lons = longitude[xid,yid]\n",
    "    lats = latitude[xid,yid]   \n",
    "    print('---- %s - %s ----'%(date_starts[pt],date_ends[pt]))\n",
    "    \n",
    "    #======================================================================================================\n",
    "    # PART 2.2 read \n",
    "    print('Read nldas data')\n",
    "    time_nldas, pcp_nldas, tmean_nldas = read_nldas(nldas_dir,date_start_obj, date_end_obj, mask_xy)\n",
    "\n",
    "    print('Read ensemble std')\n",
    "    file_dir = os.path.join(result_dir,test_folder,ens_stat_subforlder)\n",
    "    time_std, pcp_gmet_std, tmean_gmet_std = read_ens_std(file_dir, date_start_obj, date_end_obj, mask_xy)   \n",
    "\n",
    "    print('Read ensemble data')\n",
    "    file_dir = os.path.join(result_dir,test_folder,ens_subforlder)\n",
    "\n",
    "    pbar = tqdm(total=ens_num)\n",
    "    for mb in range(ens_num):\n",
    "        time_mb, pcp_mb, tmean_mb = read_ens_mb(file_dir, mb+1, date_start_obj, date_end_obj, mask_xy)\n",
    "        (nt,nx,ny) = np.shape(pcp_mb) \n",
    "        pcp_mb,tmean_mb = np.reshape(pcp_mb,(nt,nx,ny,1)),np.reshape(tmean_mb,(nt,nx,ny,1))\n",
    "\n",
    "        if mb == 0:\n",
    "            time_gmet_ens,pcp_gmet_ens,tmean_gmet_ens = time_mb,pcp_mb,tmean_mb\n",
    "        else:\n",
    "            pcp_gmet_ens = np.concatenate((pcp_gmet_ens,pcp_mb), axis=-1)\n",
    "            tmean_gmet_ens = np.concatenate((tmean_gmet_ens,tmean_mb), axis=-1)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    del time_mb, pcp_mb, tmean_mb\n",
    "    \n",
    "    #=====================================================\n",
    "    # PART 2.3 perturb NLADS precipitation \n",
    "    print('perturb NLADS Precip')\n",
    "    # --- assume Precip ~ Gamma ---\n",
    "    (nt,nx,ny)=np.shape(pcp_nldas)\n",
    "    pcp_stat_ens = np.empty((nt,nx,ny,ens_num))\n",
    "    pcp_stat_ens[:] = np.NaN\n",
    "\n",
    "    cp2 = 0.3**2 #0.25**2\n",
    "    shape = 1/cp2 * np.ones_like(pcp_nldas)\n",
    "    scale = cp2 * pcp_nldas\n",
    "\n",
    "    pbar = tqdm(total=ens_num)\n",
    "    for mb in range(ens_num):\n",
    "        pcp_stat_ens[...,mb]=np.random.gamma(shape, scale)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    #======================================================================================================\n",
    "    # PART 2.4  perturb NLADS Tmean\n",
    "    print('perturb NLADS Tmean')\n",
    "    # ---assume mean Temp ~ Normal ---\n",
    "    (nt,nx,ny)=np.shape(tmean_nldas)\n",
    "    tmean_stat_ens = np.empty((nt,nx,ny,ens_num))\n",
    "    tmean_stat_ens[:] = np.NaN\n",
    "\n",
    "    mean = tmean_nldas\n",
    "    std = 0.29 # degree\n",
    "\n",
    "    pbar = tqdm(total=ens_num)\n",
    "    for mb in range(ens_num):\n",
    "        tmean_stat_ens[...,mb]=np.random.normal(mean, std)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    \n",
    "    #======================================================================================================\n",
    "    # PART 2.3.6 save data to dic\n",
    "    data_dic[key] = {'time_nldas':time_nldas, \n",
    "                     'pcp_nldas':pcp_nldas, 'tmean_nldas':tmean_nldas,\n",
    "                     'pcp_stat_ens':pcp_stat_ens, 'tmean_stat_ens':tmean_stat_ens,\n",
    "                     'pcp_gmet_ens':pcp_gmet_ens, 'tmean_gmet_ens':tmean_gmet_ens, \n",
    "                     'pcp_gmet_std':pcp_gmet_std, 'tmean_gmet_std':tmean_gmet_std}\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Plot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create colormap\n",
      "---- 2016-02-01 - 2016-02-29 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-05c92fb3bc2a>:80: RuntimeWarning: Mean of empty slice\n",
      "  pcp_nldas_mean = np.nanmean(pcp_nldas, axis=0) #(y,x)\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1666: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "<ipython-input-3-05c92fb3bc2a>:81: RuntimeWarning: Mean of empty slice\n",
      "  pcp_stat_std_mean = np.nanmean(np.nanstd(pcp_stat_ens, axis=-1), axis=0)\n",
      "<ipython-input-3-05c92fb3bc2a>:83: RuntimeWarning: Mean of empty slice\n",
      "  pcp_gmet_std_mean = np.nanmean(pcp_gmet_std, axis=0)\n",
      "<ipython-input-3-05c92fb3bc2a>:94: RuntimeWarning: Mean of empty slice\n",
      "  tmean_nldas_mean = np.nanmean(tmean_nldas, axis=0) #(y,x)\n",
      "<ipython-input-3-05c92fb3bc2a>:95: RuntimeWarning: Mean of empty slice\n",
      "  tmean_stat_std_mean = np.nanmean(np.nanstd(tmean_stat_ens, axis=-1), axis=0)\n",
      "<ipython-input-3-05c92fb3bc2a>:97: RuntimeWarning: Mean of empty slice\n",
      "  tmean_gmet_std_mean = np.nanmean(tmean_gmet_std, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot Precip in space\n",
      "plot Precip in time\n",
      "plot Tmean in space\n",
      "plot Tmean in time\n",
      "---- 2016-08-01 - 2016-08-31 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-05c92fb3bc2a>:80: RuntimeWarning: Mean of empty slice\n",
      "  pcp_nldas_mean = np.nanmean(pcp_nldas, axis=0) #(y,x)\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1666: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "<ipython-input-3-05c92fb3bc2a>:81: RuntimeWarning: Mean of empty slice\n",
      "  pcp_stat_std_mean = np.nanmean(np.nanstd(pcp_stat_ens, axis=-1), axis=0)\n",
      "<ipython-input-3-05c92fb3bc2a>:83: RuntimeWarning: Mean of empty slice\n",
      "  pcp_gmet_std_mean = np.nanmean(pcp_gmet_std, axis=0)\n",
      "<ipython-input-3-05c92fb3bc2a>:94: RuntimeWarning: Mean of empty slice\n",
      "  tmean_nldas_mean = np.nanmean(tmean_nldas, axis=0) #(y,x)\n",
      "<ipython-input-3-05c92fb3bc2a>:95: RuntimeWarning: Mean of empty slice\n",
      "  tmean_stat_std_mean = np.nanmean(np.nanstd(tmean_stat_ens, axis=-1), axis=0)\n",
      "<ipython-input-3-05c92fb3bc2a>:97: RuntimeWarning: Mean of empty slice\n",
      "  tmean_gmet_std_mean = np.nanmean(tmean_gmet_std, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot Precip in space\n",
      "plot Precip in time\n",
      "plot Tmean in space\n",
      "plot Tmean in time\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def create_colormap(cmap):\n",
    "    # create a white-cmap linear colormap\n",
    "    # reference: https://stackoverflow.com/questions/25408393/getting-individual-colors-from-a-color-map-in-matplotlib\n",
    "    cmap = mpl.cm.get_cmap(cmap) #‘viridis’，'jet' # get the blue color of jet \n",
    "    c0 = cmap(0.0)\n",
    "    top = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",c0])\n",
    "\n",
    "    # combine two liner colormaps to create a\n",
    "    # reference: https://matplotlib.org/3.1.0/tutorials/colors/colormap-manipulation.html\n",
    "    bottom = mpl.cm.get_cmap(cmap) #'jet','viridis'\n",
    "#     newcolors = np.vstack((top(np.linspace(0, 1, int(256*0.01))),bottom(np.linspace(0, 1, int(256*0.99)))))\n",
    "    newcolors = bottom(np.linspace(0.3, 1, int(256)))\n",
    "    newcmp = mpl.colors.LinearSegmentedColormap.from_list(\"NewCmap\", newcolors)\n",
    "    return newcmp\n",
    "\n",
    "#======================================================================================================    \n",
    "# create a white-jet linear colormap\n",
    "print('Create colormap')\n",
    "# reference: https://stackoverflow.com/questions/25408393/getting-individual-colors-from-a-color-map-in-matplotlib\n",
    "cmap = mpl.cm.get_cmap('jet') # get the blue color of jet \n",
    "c0 = cmap(0.1)\n",
    "# top = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",c0])\n",
    "top = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"white\"])\n",
    "\n",
    "# combine two liner colormaps to create a\n",
    "# reference: https://matplotlib.org/3.1.0/tutorials/colors/colormap-manipulation.html\n",
    "bottom = plt.cm.bwr\n",
    "newcolors = bottom(np.linspace(0.1, 1, 256))\n",
    "NewBwr = mpl.colors.LinearSegmentedColormap.from_list(\"NewBwr\", newcolors)\n",
    "\n",
    "#======================================================================================================    \n",
    "# PART 3. plot\n",
    "# --- plot precipitation in space\n",
    "nrow = len(date_starts) # Wet, dry events\n",
    "ncol_pcp_space = 3 # NLDAS, GMET std, statistical std    \n",
    "fig_pcp_space = plt.figure(figsize=(7.08,7.08*0.4), constrained_layout=True)\n",
    "gs_pcp_space = fig_pcp_space.add_gridspec(nrow, ncol_pcp_space,height_ratios=[1, 1.05])   \n",
    "\n",
    "# --- plot precipitation in time\n",
    "nrow = len(date_starts) # Wet, dry events\n",
    "ncol_pcp_time = 1 # time series    \n",
    "fig_pcp_time = plt.figure(figsize=(7.08,7.08*0.4), constrained_layout=True)\n",
    "gs_pcp_time = fig_pcp_time.add_gridspec(nrow, ncol_pcp_time)   \n",
    "\n",
    "# --- plot Tmean in space\n",
    "nrow = len(date_starts) # Wet, dry events\n",
    "ncol_tmean_space = 2 # NLDAS, GMET std    \n",
    "fig_tmean_space = plt.figure(figsize=(7.08*2/3.0,7.08*0.4), constrained_layout=True)\n",
    "gs_tmean_space = fig_tmean_space.add_gridspec(nrow, ncol_tmean_space,height_ratios=[1, 1.05])   \n",
    "\n",
    "# --- plot Tmean in time\n",
    "nrow = len(date_starts) # Wet, dry events\n",
    "ncol_tmean_time = 1 # time series    \n",
    "fig_tmean_time = plt.figure(figsize=(7.08,7.08*0.4), constrained_layout=True)\n",
    "gs_tmean_time = fig_tmean_time.add_gridspec(nrow, ncol_tmean_time)   \n",
    "\n",
    "for pt in range(nrow):\n",
    "# for pt in range(1):\n",
    "    key=str(pt)    \n",
    "\n",
    "    # PART 3.1 extract data\n",
    "    date_start_obj = datetime.datetime.strptime(date_starts[pt], time_format)\n",
    "    date_end_obj = datetime.datetime.strptime(date_ends[pt], time_format)\n",
    "    print('---- %s - %s ----'%(date_starts[pt],date_ends[pt]))\n",
    "\n",
    "    time_nldas = data_dic[key]['time_nldas']\n",
    "    \n",
    "    pcp_nldas = data_dic[key]['pcp_nldas']       #(t,y,x)\n",
    "    pcp_stat_ens = data_dic[key]['pcp_stat_ens'] #(t,y,x,mb)\n",
    "    pcp_gmet_ens = data_dic[key]['pcp_gmet_ens'] #(t,y,x,mb)\n",
    "    pcp_gmet_std = data_dic[key]['pcp_gmet_std'] #(t,y,x)\n",
    "    \n",
    "    tmean_nldas = data_dic[key]['tmean_nldas']\n",
    "    tmean_stat_ens = data_dic[key]['tmean_stat_ens']\n",
    "    tmean_gmet_ens = data_dic[key]['tmean_gmet_ens']\n",
    "    tmean_gmet_std = data_dic[key]['tmean_gmet_std']\n",
    "    \n",
    "    #=====================================================\n",
    "    # PART 3.2 calculate Precip mean, std, vmin and vmax for plot\n",
    "    pcp_nldas_mean = np.nanmean(pcp_nldas, axis=0) #(y,x)\n",
    "    pcp_stat_std_mean = np.nanmean(np.nanstd(pcp_stat_ens, axis=-1), axis=0) \n",
    "#     pcp_gmet_std_mean = np.nanmean(np.nanstd(pcp_gmet_ens, axis=-1), axis=0)\n",
    "    pcp_gmet_std_mean = np.nanmean(pcp_gmet_std, axis=0)\n",
    "                      \n",
    "#     vmin_pcp = np.nanmin(pcp_nldas_mean)\n",
    "#     vmax_pcp = np.nanpercentile(pcp_nldas_mean,99)    \n",
    "#     vmin_pcp_std = np.nanmin([np.nanmin(pcp_stat_std_mean),np.nanmin(pcp_gmet_std_mean)])\n",
    "#     vmax_pcp_std = np.nanmax([np.nanpercentile(pcp_stat_std_mean,99.5), np.nanpercentile(pcp_gmet_std_mean,99.5)])\n",
    "    vmin_pcp,vmax_pcp = 0,9.5   \n",
    "    vmin_pcp_std,vmax_pcp_std = 0,4.8\n",
    "\n",
    "    #=====================================================\n",
    "    # PART 3.3 calculate Tmean mean, std, vmin and vmax for plot\n",
    "    tmean_nldas_mean = np.nanmean(tmean_nldas, axis=0) #(y,x)\n",
    "    tmean_stat_std_mean = np.nanmean(np.nanstd(tmean_stat_ens, axis=-1), axis=0)                      \n",
    "#     tmean_gmet_std_mean = np.nanmean(np.nanstd(tmean_gmet_ens, axis=-1), axis=0)\n",
    "    tmean_gmet_std_mean = np.nanmean(tmean_gmet_std, axis=0)\n",
    "\n",
    "#     vmin_tmean = np.nanmin(tmean_nldas_mean)\n",
    "#     vmax_tmean = np.nanmax(tmean_nldas_mean)    \n",
    "#     vmin_tmean_std = np.nanmin([np.nanmin(tmean_stat_std_mean),np.nanmin(tmean_gmet_std_mean)])\n",
    "#     vmax_tmean_std = np.nanmax([np.nanpercentile(tmean_stat_std_mean,99.5),np.nanpercentile(tmean_gmet_std_mean,99.5)])    \n",
    "    vmin_tmean,vmax_tmean = 0,38    \n",
    "    vmin_tmean_std, vmax_tmean_std = 0, 1.7\n",
    "\n",
    "    #=====================================================\n",
    "    # PART 3.4 plot Precip in space\n",
    "    # reference: https://stackoverflow.com/questions/16592222/matplotlib-group-boxplots    \n",
    "    print('plot Precip in space')\n",
    "    for j in range(ncol_pcp_space):\n",
    "        if j==0:\n",
    "            newcmp=create_colormap(plt.cm.terrain_r)\n",
    "            cmap,vmin,vmax=newcmp, vmin_pcp, vmax_pcp #plt.cm.Blues #plt.cm.terrain_r\n",
    "            data,title_str=pcp_nldas_mean,'(a) NLDAS Precip'               \n",
    "        else:\n",
    "            cmap,vmin,vmax=plt.cm.Blues, vmin_pcp_std, vmax_pcp_std #plt.cm.jet_r\n",
    "            if j == 1:\n",
    "                data,title_str=pcp_gmet_std_mean,'(b) Spatial regression Std Dev'\n",
    "            elif j==2:\n",
    "                data,title_str=pcp_stat_std_mean,'(c) Parametric Std Dev'\n",
    "\n",
    "        # plot Basemap\n",
    "        ax = fig_pcp_space.add_subplot(gs_pcp_space[pt,j])\n",
    "        m = plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx) # plot Basemap \n",
    "\n",
    "        # plot data\n",
    "        im = m.pcolormesh(longitude,latitude,data,shading='flat',latlon=True,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "\n",
    "        # set colorbar\n",
    "        if pt!=0:\n",
    "            cbar = fig_pcp_space.colorbar(im,ax=ax,pad=0.002,orientation=\"horizontal\")  \n",
    "            cbar.ax.tick_params(labelsize='xx-small',pad=0.01, length=2)             \n",
    "            cbar.set_label(label='(mm/day)', size='xx-small', rotation='horizontal', labelpad=-0.5)\n",
    "\n",
    "        # set title\n",
    "        if pt == 0:\n",
    "            ax.set_title(title_str, fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "        # set ylabel\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(datetime.datetime.strftime(time_nldas[0],'%B %Y'), fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "        # plot grids location\n",
    "        if j == 0:\n",
    "            m.scatter(lons, lats, marker = 'o', color='none', \n",
    "                      edgecolors='red', zorder=5, alpha=0.8)#magenta\n",
    "                \n",
    "    #=====================================================\n",
    "    # PART 3.5 plot Precip in time\n",
    "    print('plot Precip in time')\n",
    "    ax = fig_pcp_time.add_subplot(gs_pcp_time[pt,:])\n",
    "\n",
    "    # extract point data\n",
    "    nldas_point = pcp_nldas[:,xid,yid]            \n",
    "    data_left = pcp_gmet_ens[:,xid,yid,:]\n",
    "    data_right = pcp_stat_ens[:,xid,yid,:]  \n",
    "\n",
    "    data_left = data_left.tolist()\n",
    "    data_right = data_right.tolist()\n",
    "\n",
    "    # boxplot left data\n",
    "    positions=np.array(range(len(data_left)))*2.0-0.4\n",
    "    color='blue'\n",
    "    flierprops = dict(marker='+', markerfacecolor='none', markersize=2,\n",
    "                  linestyle='none', markeredgecolor=color)\n",
    "    bpl = ax.boxplot(data_left, positions=positions, widths=0.6, \n",
    "                     flierprops=flierprops, medianprops=dict(alpha=.8))\n",
    "    set_box_color(bpl, color) # colors are from http://colorbrewer2.org/\n",
    "    sc = ax.scatter(positions,nldas_point,s=4, c='k',alpha=1,zorder=2)\n",
    "\n",
    "    # boxplot right data\n",
    "    positions=np.array(range(len(data_left)))*2.0+0.4\n",
    "    color='red'\n",
    "    flierprops = dict(marker='+', markerfacecolor='none', markersize=2,\n",
    "                  linestyle='none', markeredgecolor=color)\n",
    "    bpr = ax.boxplot(data_right, positions=positions, widths=0.6, \n",
    "                     flierprops=flierprops, medianprops=dict(alpha=.8))\n",
    "    set_box_color(bpr, color)\n",
    "    sc = ax.scatter(positions,nldas_point,s=4, c='k',alpha=1,zorder=2)\n",
    "\n",
    "    # Add a horizontal grid to the plot, but make it very light in color\n",
    "    # so we can use it for reading data values but not be distracting\n",
    "    ax.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # xticks\n",
    "    ticks = [datetime.datetime.strftime(t,'%d') for t in time_nldas]\n",
    "    ax.set_xticklabels(ticks)\n",
    "    ax.set_xticks(np.array(range(len(data_left)))*2.0)\n",
    "    ax.tick_params(axis='both',labelsize='xx-small')\n",
    "\n",
    "    # draw temporary red and blue lines and use them to create a legend\n",
    "    ax.legend([sc, bpl[\"boxes\"][0], bpr[\"boxes\"][0]], ['NLADS', 'Spatial regression', 'Parametric'], \n",
    "              loc='upper right',fontsize='xx-small')\n",
    "\n",
    "    ax.set_xlabel('Date', fontsize='xx-small') \n",
    "    ax.set_ylabel('Precip (mm/day)', fontsize='xx-small') \n",
    "\n",
    "    # set title\n",
    "    title_str= '(%s) Precip in %s'%(chr(ord('a')+pt), datetime.datetime.strftime(time_nldas[0],'%B %Y'))                         \n",
    "    ax.set_title(title_str, fontsize='xx-small', fontweight='semibold')    \n",
    "        \n",
    "    #=====================================================\n",
    "    # PART 3.6 plot Tmean in space\n",
    "    # reference: https://stackoverflow.com/questions/16592222/matplotlib-group-boxplots\n",
    "    print('plot Tmean in space')\n",
    "    for j in range(ncol_tmean_space):\n",
    "        if j==0:\n",
    "            cmap,vmin,vmax=plt.cm.jet, vmin_tmean, vmax_tmean #plt.cm.Blues\n",
    "            data,title_str=tmean_nldas_mean,'(a) NLDAS Tmean'               \n",
    "        else:\n",
    "            cmap,vmin,vmax=NewBwr, vmin_tmean_std, vmax_tmean_std #plt.cm.bwr\n",
    "            if j == 1:\n",
    "                data,title_str=tmean_gmet_std_mean,'(b) Spatial regression Std Dev'\n",
    "            elif j==2:\n",
    "                data,title_str=tmean_stat_std_mean,'(c) Parametric Std Dev'\n",
    "\n",
    "        # plot Basemap\n",
    "        ax = fig_tmean_space.add_subplot(gs_tmean_space[pt,j])\n",
    "        m = plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx) # plot Basemap \n",
    "\n",
    "        # plot data\n",
    "        im = m.pcolormesh(longitude,latitude,data,shading='flat',latlon=True,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        \n",
    "        if j == 0:\n",
    "            im = m.pcolormesh(longitude,latitude,data,shading='flat',latlon=True,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        elif j>=1:\n",
    "            im = m.pcolormesh(longitude,latitude,data,shading='flat',latlon=True,cmap=cmap,vmin=vmin,vmax=vmax,\n",
    "                             norm=MidpointNormalize(midpoint=std,vmin=vmin, vmax=vmax))            \n",
    "\n",
    "        # set colorbar\n",
    "        if pt!=0:\n",
    "            cbar = fig_tmean_space.colorbar(im,ax=ax,pad=0.002,orientation=\"horizontal\")  \n",
    "            cbar.ax.tick_params(labelsize='xx-small',pad=0.01, length=2)             \n",
    "            cbar.set_label(label='($^\\circ$C)', size='xx-small', rotation='horizontal', labelpad=-0.5)\n",
    "\n",
    "        # set title\n",
    "        if pt == 0:\n",
    "            ax.set_title(title_str, fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "        # set ylabel\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(datetime.datetime.strftime(time_nldas[0],'%B %Y'), fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "        # plot grids location\n",
    "        if j == 0:\n",
    "            m.scatter(lons, lats, marker = 'o', color='none', \n",
    "                      edgecolors='red', zorder=5, alpha=0.8)#magenta\n",
    "                    \n",
    "    #=====================================================\n",
    "    # PART 3.7 plot Tmean in time\n",
    "    print('plot Tmean in time')\n",
    "    ax = fig_tmean_time.add_subplot(gs_tmean_time[pt,:])\n",
    "\n",
    "    # extract point data\n",
    "    nldas_point = tmean_nldas[:,xid,yid]            \n",
    "    data_left = tmean_gmet_ens[:,xid,yid,:]\n",
    "    data_right = tmean_stat_ens[:,xid,yid,:]  \n",
    "\n",
    "    data_left = data_left.tolist()\n",
    "    data_right = data_right.tolist()\n",
    "\n",
    "    # boxplot left data\n",
    "    positions=np.array(range(len(data_left)))*2.0-0.4\n",
    "    color='blue'\n",
    "    flierprops = dict(marker='+', markerfacecolor='none', markersize=2,\n",
    "                  linestyle='none', markeredgecolor=color)\n",
    "    bpl = ax.boxplot(data_left, positions=positions, widths=0.6, \n",
    "                     flierprops=flierprops, medianprops=dict(alpha=.8))\n",
    "    set_box_color(bpl, color) # colors are from http://colorbrewer2.org/\n",
    "    sc = ax.scatter(positions,nldas_point,s=4, c='k',alpha=1)\n",
    "\n",
    "    # boxplot right data\n",
    "    positions=np.array(range(len(data_left)))*2.0+0.4\n",
    "    color='red'\n",
    "    flierprops = dict(marker='+', markerfacecolor='none', markersize=2,\n",
    "                  linestyle='none', markeredgecolor=color)\n",
    "    bpr = ax.boxplot(data_right, positions=positions, widths=0.6, \n",
    "                     flierprops=flierprops, medianprops=dict(alpha=.8))\n",
    "    set_box_color(bpr, color)\n",
    "    sc = ax.scatter(positions,nldas_point,s=4, c='k',alpha=1)\n",
    "\n",
    "    # Add a horizontal grid to the plot, but make it very light in color\n",
    "    # so we can use it for reading data values but not be distracting\n",
    "    ax.yaxis.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    # xticks\n",
    "    ticks = [datetime.datetime.strftime(t,'%d') for t in time_nldas]\n",
    "    ax.set_xticklabels(ticks)\n",
    "    ax.set_xticks(np.array(range(len(data_left)))*2.0)\n",
    "    ax.tick_params(axis='both',labelsize='xx-small')\n",
    "\n",
    "    # draw temporary red and blue lines and use them to create a legend\n",
    "    ax.legend([sc, bpl[\"boxes\"][0], bpr[\"boxes\"][0]], ['NLADS', 'Spatial regression', 'Parametric'], \n",
    "              loc='upper right',fontsize='xx-small')\n",
    "\n",
    "    ax.set_xlabel('Date', fontsize='xx-small') \n",
    "    ax.set_ylabel('Tmean ($^\\circ$C)', fontsize='xx-small') \n",
    "\n",
    "    # set title\n",
    "    title_str= '(%s) Tmean in %s'%(chr(ord('a')+pt), datetime.datetime.strftime(time_nldas[0],'%B %Y'))                         \n",
    "    ax.set_title(title_str, fontsize='xx-small', fontweight='semibold')\n",
    "    \n",
    "#=====================================================           \n",
    "# save\n",
    "# --- save precip in space\n",
    "output_filename = '%s_Precip_%s_xid%d_yid%d_spatial.png'%(test_folder, datetime.datetime.strftime(time_nldas[0],'%B_%Y'),xid, yid)\n",
    "fig_pcp_space.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value)\n",
    "plt.close(fig_pcp_space)\n",
    "\n",
    "# --- save precip in time\n",
    "output_filename = '%s_Precip_%s_xid%d_yid%d_time.png'%(test_folder, datetime.datetime.strftime(time_nldas[0],'%B_%Y'),xid, yid)\n",
    "fig_pcp_time.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value)\n",
    "plt.close(fig_pcp_time)\n",
    "\n",
    "# --- save Tmean in space\n",
    "output_filename = '%s_Tmean_%s_xid%d_yid%d_spatial.png'%(test_folder, datetime.datetime.strftime(time_nldas[0],'%B_%Y'),xid, yid)\n",
    "fig_tmean_space.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value)\n",
    "plt.close(fig_tmean_space)\n",
    "\n",
    "# --- save Tmean in time\n",
    "output_filename = '%s_Tmean_%s_xid%d_yid%d_time.png'%(test_folder, datetime.datetime.strftime(time_nldas[0],'%B_%Y'),xid, yid)\n",
    "fig_tmean_time.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value)\n",
    "plt.close(fig_tmean_time)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [0.30824798, 0.31744072, 0.31908718, ..., 0.15204985, 0.15317374,\n",
       "        0.15459178],\n",
       "       [0.322115  , 0.3239294 , 0.3264998 , ..., 0.14395365, 0.1490669 ,\n",
       "        0.15212606],\n",
       "       [0.32646263, 0.3263203 , 0.32391474, ..., 0.13311036, 0.13631953,\n",
       "        0.14140235]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
