{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read gridinfo mask\n",
      "Read nldas data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_max' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_min' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_range' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "<ipython-input-1-b59e81c4809b>:161: RuntimeWarning: Mean of empty slice\n",
      "  pcp_mean = np.nanmean(pcp[mask_t,:,:], axis=0) #(y, x))\n",
      "<ipython-input-1-b59e81c4809b>:162: RuntimeWarning: Mean of empty slice\n",
      "  tmean_mean = np.nanmean(tmean[mask_t,:,:], axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:163: RuntimeWarning: Mean of empty slice\n",
      "  trange_mean = np.nanmean(trange[mask_t,:,:], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot\n",
      "18212grids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-b59e81c4809b>:202: RuntimeWarning: Mean of empty slice\n",
      "  pcp_mb1_mean = np.nanmean(pcp_mb1[mb1_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:203: RuntimeWarning: Mean of empty slice\n",
      "  pcp_mb2_mean = np.nanmean(pcp_mb2[mb2_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:204: RuntimeWarning: Mean of empty slice\n",
      "  pcp_std_mean = np.nanmean(pcp_std[std_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:206: RuntimeWarning: Mean of empty slice\n",
      "  tmean_mb1_mean = np.nanmean(tmean_mb1[mb1_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:207: RuntimeWarning: Mean of empty slice\n",
      "  tmean_mb2_mean = np.nanmean(tmean_mb2[mb2_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:208: RuntimeWarning: Mean of empty slice\n",
      "  tmean_std_mean = np.nanmean(tmean_std[std_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:210: RuntimeWarning: Mean of empty slice\n",
      "  trange_mb1_mean = np.nanmean(trange_mb1[mb1_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:211: RuntimeWarning: Mean of empty slice\n",
      "  trange_mb2_mean = np.nanmean(trange_mb2[mb2_mask_t,:,:],axis=0)\n",
      "<ipython-input-1-b59e81c4809b>:212: RuntimeWarning: Mean of empty slice\n",
      "  trange_std_mean = np.nanmean(trange_std[std_mask_t,:,:],axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = '/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/share/proj'\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pyproj import Proj\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "def read_nldas(file_dir, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):\n",
    "        nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "        nldas_path = os.path.join(file_dir, nldas_file)\n",
    "\n",
    "        f_nldas = xr.open_dataset(nldas_path)\n",
    "        if yr == start_yr:\n",
    "            pcp_concat = f_nldas['pcp'].values[:] # (time, y, x). unit: mm/day\n",
    "            t_mean_concat = f_nldas['t_mean'].values[:] # (time, y, x). unit: degC\n",
    "            t_range_concat = f_nldas['t_range'].values[:]\n",
    "            time_concat = f_nldas['time'].values[:]\n",
    "        else:\n",
    "            pcp_concat = np.concatenate((pcp_concat, f_nldas['pcp'].values[:]), axis = 0)\n",
    "            t_mean_concat = np.concatenate((t_mean_concat, f_nldas['t_mean'].values[:]), axis = 0)\n",
    "            t_range_concat = np.concatenate((t_range_concat, f_nldas['t_range'].values[:]), axis = 0)\n",
    "            time_concat = np.concatenate((time_concat, f_nldas['time'].values[:]), axis = 0)\n",
    "\n",
    "    # get time mask from nldas data\n",
    "    time_obj = pd.to_datetime(time_concat)\n",
    "    return time_obj, pcp_concat, t_mean_concat, t_range_concat\n",
    "\n",
    "def read_ens_mb(file_dir, mb, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        filename='ens_forc.%d.%03d.nc'%(yr,mb)\n",
    "        file = os.path.join(file_dir, filename)\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'].values[:]\n",
    "        pcp = f['pcp'].values[:]\n",
    "        tmean = f['t_mean'].values[:]\n",
    "        trange = f['t_range'].values[:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            tmean_concat = tmean\n",
    "            trange_concat = trange\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_concat = np.concatenate((pcp_concat, pcp), axis=0) # (time,y,x)\n",
    "            tmean_concat = np.concatenate((tmean_concat, tmean), axis=0)\n",
    "            trange_concat = np.concatenate((trange_concat, trange), axis=0)            \n",
    "    time_concat = pd.to_datetime(time_concat)        \n",
    "    return time_concat, pcp_concat, tmean_concat, trange_concat\n",
    "\n",
    "def read_regress_std(file_dir, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        filename='regress_ts.%d.nc'%(yr)\n",
    "        file = os.path.join(file_dir, filename)\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'].values[:]\n",
    "        pcp_error = f['pcp_error'].values[:] # std\n",
    "        tmean_error_2 = f['tmean_error_2'].values[:]\n",
    "        trange_error_2 = f['trange_error_2'].values[:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_error_concat = pcp_error\n",
    "            tmean_error_2_concat = tmean_error_2\n",
    "            trange_error_2_concat = trange_error_2\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_error_concat = np.concatenate((pcp_error_concat, pcp_error), axis=0) # (time,y,x)\n",
    "            tmean_error_2_concat = np.concatenate((tmean_error_2_concat, tmean_error_2), axis=0)\n",
    "            trange_error_2_concat = np.concatenate((trange_error_2_concat, trange_error_2), axis=0)\n",
    "            \n",
    "    time_concat = pd.to_datetime(time_concat)        \n",
    "    return time_concat, pcp_error_concat, tmean_error_2_concat, trange_error_2_concat\n",
    "\n",
    "def read_ens_std(file_dir, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        filename='ens_forc.%d.ensstd.nc'%(yr)\n",
    "        file = os.path.join(file_dir, filename)\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'].values[:]\n",
    "        pcp_error = f['pcp'].values[:] # std\n",
    "        tmean_error = f['t_mean'].values[:]\n",
    "        trange_error = f['t_range'].values[:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_error_concat = pcp_error\n",
    "            tmean_error_concat = tmean_error\n",
    "            trange_error_concat = trange_error\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_error_concat = np.concatenate((pcp_error_concat, pcp_error), axis=0) # (time,y,x)\n",
    "            tmean_error_concat = np.concatenate((tmean_error_concat, tmean_error), axis=0)\n",
    "            trange_error_concat = np.concatenate((trange_error_concat, trange_error), axis=0)\n",
    "            \n",
    "    time_concat = pd.to_datetime(time_concat)        \n",
    "    return time_concat, pcp_error_concat, tmean_error_concat, trange_error_concat\n",
    "\n",
    "def plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx):\n",
    "\n",
    "    m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='cyl', ax=ax)   \n",
    "#     m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='tmerc', ax=ax,lat_0=lat_0,lon_0=lon_0)\n",
    "\n",
    "    m.drawstates(linewidth=0.5, linestyle='solid', color='grey')\n",
    "    m.drawcountries(linewidth=0.5, linestyle='solid', color='k')\n",
    "    m.drawcoastlines(linewidth=.25, linestyle='solid', color='k')\n",
    "    return m\n",
    "\n",
    "# set the colormap and centre the colorbar\n",
    "class MidpointNormalize(mpl.colors.Normalize):\n",
    "    \"\"\"Normalise the colorbar.\n",
    "    source: http://chris35wills.github.io/matplotlib_diverging_colorbar/\n",
    "    e.g. im=ax1.imshow(array, norm=MidpointNormalize(midpoint=0.,vmin=-300, vmax=1000))    \n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mpl.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y), np.isnan(value))\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "start_yr = 2016\n",
    "end_yr = 2016\n",
    "\n",
    "gridinfo_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "\n",
    "regress_subforlder = 'gmet_regr'\n",
    "ens_subforlder = 'gmet_ens_bc'\n",
    "\n",
    "ens_num = 100\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "dpi_value = 150\n",
    "plot_date_start = '2016-06-01'\n",
    "plot_date_end = '2016-06-30'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "output_dir=os.path.join(root_dir, 'scripts/step33_plot_spatial_mbm_std')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "#======================================================================================================\n",
    "print('Read gridinfo mask')\n",
    "# get xy mask from gridinfo.nc\n",
    "f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "#data_mask = f_gridinfo['data_mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "latitude = f_gridinfo['latitude'].values[:]\n",
    "longitude = f_gridinfo['longitude'].values[:]\n",
    "\n",
    "#======================================================================================================\n",
    "# read historical nldas data\n",
    "print('Read nldas data')\n",
    "time_obj, pcp, tmean, trange=read_nldas(nldas_dir,start_yr, end_yr)\n",
    "mask_t  = (time_obj >= plot_date_start_obj) & (time_obj <= plot_date_end_obj) \n",
    "time = time_obj[mask_t]\n",
    "\n",
    "# time series mean\n",
    "pcp_mean = np.nanmean(pcp[mask_t,:,:], axis=0) #(y, x))\n",
    "tmean_mean = np.nanmean(tmean[mask_t,:,:], axis=0) \n",
    "trange_mean = np.nanmean(trange[mask_t,:,:], axis=0)\n",
    "\n",
    "# convert masked values to nan\n",
    "pcp_mean=np.where(mask_xy==0,np.nan,pcp_mean)\n",
    "tmean_mean=np.where(mask_xy==0,np.nan,tmean_mean)\n",
    "trange_mean=np.where(mask_xy==0,np.nan,trange_mean)\n",
    "\n",
    "del pcp,tmean,trange\n",
    "\n",
    "#======================================================================================================\n",
    "print('Plot')\n",
    "# loop through all uniform tests\n",
    "for test_folder in test_folders[-1:]:\n",
    "    \n",
    "    print(test_folder)\n",
    "    test_dir = os.path.join(result_dir, test_folder)\n",
    "\n",
    "    ## part 1. read data\n",
    "    # read ensemble member 011  \n",
    "    file_dir = os.path.join(test_dir,ens_subforlder)\n",
    "    mb1 = 11\n",
    "    time_mb1, pcp_mb1, tmean_mb1, trange_mb1 = read_ens_mb(file_dir, mb1, start_yr, end_yr)\n",
    "\n",
    "    # read ensemble member 075 \n",
    "    file_dir = os.path.join(test_dir,ens_subforlder)\n",
    "    mb2 = 75\n",
    "    time_mb2, pcp_mb2, tmean_mb2, trange_mb2 = read_ens_mb(file_dir, mb2, start_yr, end_yr)\n",
    "    \n",
    "#     # read std from regression results (method 1)    \n",
    "#     file_dir = os.path.join(test_dir,regress_subforlder)\n",
    "#     time_std, pcp_std, tmean_std, trange_std = read_regress_std(file_dir, start_yr, end_yr)   \n",
    "    # read std from ensemble results (method 2)    \n",
    "    file_dir = os.path.join(test_dir,regress_subforlder)\n",
    "    time_std, pcp_std, tmean_std, trange_std = read_ens_std(file_dir, start_yr, end_yr)   \n",
    "\n",
    "    ## part 2. calcualte time-series mean for extract period\n",
    "    # define plot mask for nldas ensemble\n",
    "    mb1_mask_t = (time_mb1>=plot_date_start_obj) & (time_mb1<=plot_date_end_obj)\n",
    "    mb2_mask_t = (time_mb2>=plot_date_start_obj) & (time_mb2<=plot_date_end_obj)\n",
    "    std_mask_t = (time_std>=plot_date_start_obj) & (time_std<=plot_date_end_obj)\n",
    "    \n",
    "    # caluclate time series mean(ny,nx)\n",
    "    pcp_mb1_mean = np.nanmean(pcp_mb1[mb1_mask_t,:,:],axis=0) \n",
    "    pcp_mb2_mean = np.nanmean(pcp_mb2[mb2_mask_t,:,:],axis=0) \n",
    "    pcp_std_mean = np.nanmean(pcp_std[std_mask_t,:,:],axis=0) \n",
    "    \n",
    "    tmean_mb1_mean = np.nanmean(tmean_mb1[mb1_mask_t,:,:],axis=0) \n",
    "    tmean_mb2_mean = np.nanmean(tmean_mb2[mb2_mask_t,:,:],axis=0) \n",
    "    tmean_std_mean = np.nanmean(tmean_std[std_mask_t,:,:],axis=0) \n",
    "    \n",
    "    trange_mb1_mean = np.nanmean(trange_mb1[mb1_mask_t,:,:],axis=0) \n",
    "    trange_mb2_mean = np.nanmean(trange_mb2[mb2_mask_t,:,:],axis=0) \n",
    "    trange_std_mean = np.nanmean(trange_std[std_mask_t,:,:],axis=0) \n",
    "\n",
    "    # convert masked values to nan\n",
    "    pcp_mb1_mean=np.where(mask_xy==0,np.nan,pcp_mb1_mean)\n",
    "    pcp_mb2_mean=np.where(mask_xy==0,np.nan,pcp_mb2_mean)\n",
    "    pcp_std_mean=np.where(mask_xy==0,np.nan,pcp_std_mean)\n",
    "    \n",
    "    tmean_mb1_mean=np.where(mask_xy==0,np.nan,tmean_mb1_mean)\n",
    "    tmean_mb2_mean=np.where(mask_xy==0,np.nan,tmean_mb2_mean)\n",
    "    tmean_std_mean=np.where(mask_xy==0,np.nan,tmean_std_mean)\n",
    "    \n",
    "    trange_mb1_mean=np.where(mask_xy==0,np.nan,trange_mb1_mean)\n",
    "    trange_mb2_mean=np.where(mask_xy==0,np.nan,trange_mb2_mean)\n",
    "    trange_std_mean=np.where(mask_xy==0,np.nan,trange_std_mean)\n",
    "    \n",
    "    ## part 3. setup plot colorbar range for the plot_date\n",
    "    vmin_pcp=np.nanmin([np.nanmin(pcp_mean), np.nanmin(pcp_mb1_mean), np.nanmin(pcp_mb2_mean)])\n",
    "    vmax_pcp=np.nanmax([np.nanmax(pcp_mean), np.nanpercentile(pcp_mb1_mean,99.5), np.nanpercentile(pcp_mb2_mean,99.5)])\n",
    "    vmin_pcp_std=np.nanmin(pcp_std_mean)\n",
    "    vmax_pcp_std=np.nanmax(pcp_std_mean)\n",
    "    \n",
    "    vmin_tmean=np.nanmin([np.nanmin(tmean_mb1_mean), np.nanmin(tmean_mb2_mean)])\n",
    "    vmax_tmean=np.nanmax([np.nanmax(tmean_mb1_mean), np.nanmax(tmean_mb2_mean)])\n",
    "    vmin_tmean_std=np.nanmin(tmean_std_mean)\n",
    "    vmax_tmean_std=np.nanpercentile(tmean_std_mean,99.5) #np.nanmax(tmean_std_mean)\n",
    "    \n",
    "    vmin_trange=np.nanmin([np.nanmin(trange_mb1_mean), np.nanmin(trange_mb2_mean)])\n",
    "    vmax_trange=np.nanmax([np.nanmax(trange_mb1_mean), np.nanmax(trange_mb2_mean)])\n",
    "    vmin_trange_std=np.nanmin(trange_std_mean)\n",
    "    vmax_trange_std=np.nanpercentile(trange_std_mean,99.5) #np.nanmax(trange_std_mean)\n",
    "\n",
    "    # plot\n",
    "    nrow = 4+2 # NLDAS, ensmb1, ensmb2, std + 2 colorbars\n",
    "    ncol = 3 # Prcip, Tmean, Trange    \n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(7.08,7.08*0.85),\n",
    "                          gridspec_kw={\"height_ratios\":[1, 1, 1, 0.05, 1, 0.05]}) #7.08*0.9\n",
    "    # figure size (width, height) \n",
    "    #constrained_layout=True\n",
    "#     fig.subplots_adjust(top=0.9) # adjust the subplots, i.e. leave more space at the top to accomodate the additional titles\n",
    "    fig.subplots_adjust(left=0.1, bottom=0.1, right=1, top=0.85)#, wspace=None, hspace=None)\n",
    "    \n",
    "    llcrnrlon = longitude[0,0]\n",
    "    urcrnrlon = longitude[-1,-1]\n",
    "    llcrnrlat = latitude[0,0]\n",
    "    urcrnrlat = latitude[-1,-1]\n",
    "    lat_0=0.5*(llcrnrlat+urcrnrlat)\n",
    "    lon_0=0.5*(llcrnrlon+urcrnrlon)\n",
    "    (ny,nx)=np.shape(longitude)\n",
    "\n",
    "    ylabels=['NLDAS','Member '+str(mb1),'Member '+str(mb2),'','Std. dev.','']\n",
    "    \n",
    "    for j in range(ncol):\n",
    "        for i in range(nrow):\n",
    "    \n",
    "            # select data for each subplot\n",
    "            # PCP (1st column, 1st-3st row)\n",
    "            if j==0:\n",
    "                if i <3:\n",
    "                    cmap=plt.cm.jet #newcmp #plt.cm.winter\n",
    "                    vmin=vmin_pcp\n",
    "                    vmax=vmax_pcp\n",
    "                    if i == 0:\n",
    "                        data,title_str=pcp_mean,'Precip'\n",
    "                    elif i==1:\n",
    "                        data=pcp_mb1_mean\n",
    "                    elif i==2:\n",
    "                        data=pcp_mb2_mean\n",
    "                elif i==3+1:\n",
    "                    cmap=plt.cm.Blues\n",
    "                    vmin=vmin_pcp_std\n",
    "                    vmax=vmax_pcp_std\n",
    "                    data=pcp_std_mean                \n",
    "\n",
    "            # Tmean (2st column, 1st-3st row)\n",
    "            if j==1:\n",
    "                if i <3:\n",
    "                    cmap=plt.cm.jet #newcmp #plt.cm.winter\n",
    "                    vmin=vmin_tmean\n",
    "                    vmax=vmax_tmean\n",
    "                    if i == 0:\n",
    "                        data=tmean_mean\n",
    "                        title_str = 'Tmean'\n",
    "                    elif i==1:\n",
    "                        data=tmean_mb1_mean\n",
    "                    elif i==2:\n",
    "                        data=tmean_mb2_mean\n",
    "                elif i==3+1:\n",
    "                    cmap=plt.cm.Blues\n",
    "                    vmin=vmin_tmean_std\n",
    "                    vmax=vmax_tmean_std\n",
    "                    data=tmean_std_mean \n",
    "\n",
    "            # Trange (2st column, 1st-3st row)\n",
    "            if j==2:\n",
    "                if i <3:\n",
    "                    cmap=plt.cm.jet #newcmp #plt.cm.winter\n",
    "                    vmin=vmin_trange\n",
    "                    vmax=vmax_trange\n",
    "                    if i == 0:\n",
    "                        data=trange_mean\n",
    "                        title_str = 'Trange'\n",
    "                    elif i==1:\n",
    "                        data=trange_mb1_mean\n",
    "                    elif i==2:\n",
    "                        data=trange_mb2_mean\n",
    "                elif i==3+1:\n",
    "                    cmap=plt.cm.Blues\n",
    "                    vmin=vmin_trange_std\n",
    "                    vmax=vmax_trange_std\n",
    "                    data=trange_std_mean \n",
    "\n",
    "            # plot Basemap\n",
    "            if i <3 or i == 3+1:\n",
    "                m = plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax[i,j],lat_0,lon_0,ny,nx) # plot Basemap \n",
    "            \n",
    "                # plot data\n",
    "                im = m.pcolormesh(longitude,latitude,data,shading='flat',latlon=True,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "\n",
    "                # set ylabel\n",
    "                if j == 0:\n",
    "                    ax[i,j].set_ylabel(ylabels[i], fontsize='xx-small', fontweight='semibold')\n",
    "            \n",
    "            # set colorbar\n",
    "            if i == 3 or i == 5:\n",
    "                if i == 3 and j == 0:\n",
    "                    cbar_ax, cbar_label = ax[0:3,j], '(mm/day)'\n",
    "                elif i ==3 and j >=1:\n",
    "                    cbar_ax, cbar_label = ax[0:3,j], '($^\\circ$C)'\n",
    "                elif i ==5 and j ==0:\n",
    "                    cbar_ax, cbar_label = ax[4,j], '(mm/day)'\n",
    "                elif i ==5 and j >=1:\n",
    "                    cbar_ax, cbar_label = ax[4,j], '($^\\circ$C)'\n",
    "\n",
    "                cbar = fig.colorbar(im,cax=ax[i,j],ax=cbar_ax,pad=0.01,orientation=\"horizontal\")  \n",
    "                cbar.ax.tick_params(labelsize='xx-small',pad=0.05, length=2)             \n",
    "                cbar.set_label(label=cbar_label, size='xx-small', rotation='horizontal', labelpad=-0.5)\n",
    "\n",
    "            # set title\n",
    "            if i == 0:\n",
    "                ax[i,j].set_title(title_str, fontsize='xx-small', fontweight='semibold')\n",
    "    \n",
    "    # save plot\n",
    "    fig.tight_layout(pad=0.2)\n",
    "    output_filename = test_folder+'.png'\n",
    "    fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value)\n",
    "    plt.close(fig)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4724542611898504, 0.28149183886988743, 0.5590283402038245)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(pcp_std_mean),np.nanmean(tmean_std_mean),np.nanmean(trange_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
