{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot\n",
      "Precp\n",
      "Tmean\n",
      "Tmin\n",
      "Tmax\n",
      "Trange\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "def read_stn_ens_metric(out_forc_name_base, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):\n",
    "\n",
    "        file = os.path.join(out_forc_name_base, 'ens_forc.sumamry.'+str(yr)+'.nc')\n",
    "        f_stn = xr.open_dataset(file)\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            pcp_std = f_stn['pcp_std'].values[:]\n",
    "            tmean_std = f_stn['tmean_std'].values[:]\n",
    "            tmin_std = f_stn['tmin_std'].values[:]\n",
    "            tmax_std = f_stn['tmax_std'].values[:]\n",
    "            trange_std = f_stn['trange_std'].values[:]\n",
    "            time = f_stn['time'].values[:]\n",
    "        else:\n",
    "            pcp_std = np.concatenate((pcp_std, f_stn['pcp_std'].values[:]), axis = 0)\n",
    "            tmean_std = np.concatenate((tmean_std, f_stn['tmean_std'].values[:]), axis = 0)\n",
    "            tmin_std = np.concatenate((tmin_std, f_stn['tmin_std'].values[:]), axis = 0)\n",
    "            tmax_std = np.concatenate((tmax_std, f_stn['tmax_std'].values[:]), axis = 0)\n",
    "            trange_std = np.concatenate((trange_std, f_stn['trange_std'].values[:]), axis = 0)\n",
    "            time = np.concatenate((time, f_stn['time'].values[:]), axis = 0)\n",
    "        \n",
    "        time_obj = pd.to_datetime(time)\n",
    "        \n",
    "    return time_obj,pcp_std,tmean_std,tmin_std,tmax_std,trange_std\n",
    "\n",
    "def read_nldas_ens_metric(out_forc_name_base, metric, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.'+metric+'.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            pcp = f['pcp'].values[:]\n",
    "            tmean = f['t_mean'].values[:]\n",
    "            tmin = f['t_min'].values[:]\n",
    "            tmax = f['t_max'].values[:]\n",
    "            trange = f['t_range'].values[:]\n",
    "            time = f['time'].values[:]\n",
    "        else:\n",
    "            pcp = np.concatenate((pcp, f['pcp'].values[:]), axis=0) # (time,y,x)\n",
    "            tmean = np.concatenate((tmean, f['t_mean'].values[:]), axis=0)\n",
    "            tmin = np.concatenate((tmin, f['t_min'].values[:]), axis=0)\n",
    "            tmax = np.concatenate((tmax, f['t_max'].values[:]), axis=0)\n",
    "            trange = np.concatenate((trange, f['t_range'].values[:]), axis=0)\n",
    "            time = np.concatenate((time,f['time'].values[:]), axis=0) # (time)\n",
    "            \n",
    "        time_obj = pd.to_datetime(time)\n",
    "        \n",
    "    return time_obj, pcp, tmean, tmin, tmax, trange\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "stn_ens_dir = os.path.join(root_dir,'data/stn_ens_summary')\n",
    "start_yr = 2016\n",
    "end_yr = 2016\n",
    "\n",
    "stn_grid_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "nldas_grid_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth_deg_v1p1.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "scenarios_ids = range(0,9)  \n",
    "intervals =  range(10,1,-1)\n",
    "scenario_num = len(scenarios_ids)\n",
    "\n",
    "subforlder = 'gmet_ens_summary'\n",
    "file_basename = 'ens_forc'\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "plot_date_start = '2016-01-01'\n",
    "plot_date_end = '2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "dpi_value = 600 #150\n",
    "output_dir=os.path.join(root_dir, 'scripts/step28_plot_ens_unc_box')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_filename = 'step28_plot_ens_unc_box_bias.png'\n",
    "    \n",
    "# #======================================================================================================\n",
    "# print('Read gridinfo mask')\n",
    "# # get xy mask from gridinfo.nc\n",
    "# f_stn_grid = xr.open_dataset(stn_grid_file)\n",
    "# stn_mask_xy = f_stn_grid['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# f_nldas_grid = xr.open_dataset(nldas_grid_file)\n",
    "# nldas_mask_xy = f_nldas_grid['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# # commonly available area\n",
    "# mask_xy = (stn_mask_xy!=0) & (nldas_mask_xy!=0) \n",
    "\n",
    "# #======================================================================================================\n",
    "# # Read nldas ens summary\n",
    "# print('Read nldas ens summary')\n",
    "\n",
    "# for k in range(scenario_num):\n",
    "\n",
    "#     test_folder = test_folders[scenarios_ids[k]]\n",
    "    \n",
    "#     print(test_folder)\n",
    "#     test_dir = os.path.join(result_dir, test_folder)\n",
    "#     fig_title= test_folder\n",
    "\n",
    "#     print(' -- read spatial ensemble metric')\n",
    "#     # read ensemble mean    \n",
    "#     output_namebase = os.path.join(test_dir,subforlder, file_basename)\n",
    "#     metric = 'ensstd'\n",
    "#     time, pcp_std, tmean_std, tmin_std, tmax_std, trange_std = read_nldas_ens_metric(output_namebase, metric, start_yr, end_yr)\n",
    "\n",
    "#     # define plot mask for nldas ensemble\n",
    "#     mask_ens_t = (time>=plot_date_start_obj) & (time<=plot_date_end_obj)\n",
    "    \n",
    "#     print(' -- calculate temporal mean')\n",
    "#     # caluclate time series mean(ny,nx)\n",
    "#     pcp_std_nldas = np.nanmean(pcp_std[mask_ens_t,:,:],axis=0)     \n",
    "#     tmean_std_nldas = np.nanmean(tmean_std[mask_ens_t,:,:],axis=0)\n",
    "#     tmin_std_nldas = np.nanmean(tmin_std[mask_ens_t,:,:],axis=0)\n",
    "#     tmax_std_nldas = np.nanmean(tmax_std[mask_ens_t,:,:],axis=0)\n",
    "#     trange_std_nldas = np.nanmean(trange_std[mask_ens_t,:,:],axis=0)\n",
    "    \n",
    "#     print(' -- extract unmasked values')\n",
    "#     # extract unmasked values\n",
    "#     pcp_std_nldas=pcp_std_nldas[mask_xy]    \n",
    "#     tmean_std_nldas=tmean_std_nldas[mask_xy] \n",
    "#     tmin_std_nldas=tmin_std_nldas[mask_xy]  \n",
    "#     tmax_std_nldas=tmax_std_nldas[mask_xy]   \n",
    "#     trange_std_nldas=trange_std_nldas[mask_xy] \n",
    "    \n",
    "#     # save to array\n",
    "#     if k == 0:\n",
    "#         grid_num = len(pcp_std_nldas)\n",
    "#         pcp_std_arr = np.zeros((grid_num,scenario_num+1))\n",
    "#         tmean_std_arr = np.zeros((grid_num,scenario_num+1)) \n",
    "#         tmin_std_arr = np.zeros((grid_num,scenario_num+1)) \n",
    "#         tmax_std_arr = np.zeros((grid_num,scenario_num+1))\n",
    "#         trange_std_arr = np.zeros((grid_num,scenario_num+1))\n",
    "    \n",
    "#     pcp_std_arr[:,k] = pcp_std_nldas\n",
    "#     tmean_std_arr[:,k] = tmean_std_nldas \n",
    "#     tmin_std_arr[:,k] = tmin_std_nldas\n",
    "#     tmax_std_arr[:,k] = tmax_std_nldas\n",
    "#     trange_std_arr[:,k] = trange_std_nldas\n",
    "    \n",
    "#     del pcp_std_nldas, tmean_std_nldas, tmin_std_nldas, tmax_std_nldas, trange_std_nldas\n",
    "#     del pcp_std, tmean_std, tmin_std, tmax_std, trange_std  \n",
    "\n",
    "# #======================================================================================================\n",
    "# # read stn ens summary\n",
    "# print('Read stn ens summary')\n",
    "\n",
    "# time,pcp_std,tmean_std,tmin_std,tmax_std,trange_std = read_stn_ens_metric(stn_ens_dir, start_yr, end_yr)\n",
    "\n",
    "# # get time mask from nldas data\n",
    "# mask_t  = (time >= plot_date_start_obj) & (time <= plot_date_end_obj) \n",
    "# time = time[mask_t]\n",
    "\n",
    "# # caluclate time-series mean \n",
    "# pcp_std_stn = np.nanmean(pcp_std[mask_t,:,:], axis=0) \n",
    "# tmean_std_stn = np.nanmean(tmean_std[mask_t,:,:], axis=0)\n",
    "# tmin_std_stn = np.nanmean(tmin_std[mask_t,:,:], axis=0)\n",
    "# tmax_std_stn = np.nanmean(tmax_std[mask_t,:,:], axis=0)\n",
    "# trange_std_stn = np.nanmean(trange_std[mask_t,:,:], axis=0)\n",
    "\n",
    "# # extract unmasked values\n",
    "# pcp_std_stn=pcp_std_stn[mask_xy]\n",
    "# tmean_std_stn=tmean_std_stn[mask_xy]\n",
    "# tmin_std_stn=tmin_std_stn[mask_xy]\n",
    "# tmax_std_stn=tmax_std_stn[mask_xy]\n",
    "# trange_std_stn=trange_std_stn[mask_xy]\n",
    "\n",
    "# # save to array\n",
    "# pcp_std_arr[:,-1] = pcp_std_stn\n",
    "# tmean_std_arr[:,-1] = tmean_std_stn \n",
    "# tmin_std_arr[:,-1] = tmin_std_stn\n",
    "# tmax_std_arr[:,-1] = tmax_std_stn\n",
    "# trange_std_arr[:,-1] = trange_std_stn\n",
    "\n",
    "# del pcp_std_stn, tmean_std_stn, tmin_std_stn, tmax_std_stn, trange_std_stn\n",
    "# del pcp_std,tmean_std,tmin_std,tmax_std,trange_std\n",
    "\n",
    "#======================================================================================================    \n",
    "# plot\n",
    "print('Plot')\n",
    "var_list = [\"Precp\", 'Tmean', 'Tmin', 'Tmax', 'Trange']\n",
    "unit_list = ['(mm/day)', '($^\\circ$C)', '($^\\circ$C)', '($^\\circ$C)', '($^\\circ$C)']\n",
    "\n",
    "nrow = len(var_list) # prcp, tmean, tmin, tmax, trange\n",
    "ncol = 1 \n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(6.5,5.5*1.2))#, constrained_layout=True)\n",
    "\n",
    "for i in range(nrow):\n",
    "        print(var_list[i])\n",
    "        \n",
    "        # select data for each subplot\n",
    "        if i == 0:\n",
    "            data=pcp_std_arr\n",
    "            top=20\n",
    "        elif i == 1:\n",
    "            data=tmean_std_arr\n",
    "            top=6\n",
    "        elif i == 2:\n",
    "            data=tmin_std_arr\n",
    "            top=6\n",
    "        elif i == 3:\n",
    "            data=tmax_std_arr\n",
    "            top=6\n",
    "        elif i == 4:\n",
    "            data=trange_std_arr\n",
    "            top=4.5     \n",
    "            \n",
    "#         # save time-series mean uncertainty of all valid grids and all scenarios (once for all)\n",
    "#         output_filename_txt = 'ens_std_mean_'+var_list[i]+'.txt'\n",
    "#         np.savetxt(os.path.join(output_dir, output_filename_txt), data, delimiter=',',\n",
    "#                     fmt='%f',header='Col is sample scenario. Row is the time-series mean std of flatten valid grids. The last col is for stn_regr.')\n",
    "\n",
    "#         # read \n",
    "#         data = np.loadtxt(os.path.join(output_dir, output_filename_txt), delimiter=',')\n",
    "        \n",
    "        # boxplot\n",
    "        # reference: https://matplotlib.org/3.1.1/gallery/statistics/boxplot_demo.html\n",
    "        bp = ax[i].boxplot(data, sym='o')#, labels=labels)\n",
    "        plt.setp(bp['boxes'], color='black')\n",
    "        plt.setp(bp['whiskers'], color='black')\n",
    "        plt.setp(bp['fliers'], color='red', marker='o',markersize=0.8)\n",
    "        \n",
    "        # Add a horizontal grid to the plot, but make it very light in color\n",
    "        # so we can use it for reading data values but not be distracting\n",
    "        ax[i].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
    "        ax[i].set_axisbelow(True)\n",
    "        \n",
    "        # y_lim\n",
    "#         bottom=np.nanmin(data)-0.05*(np.nanmax(data)-np.nanmin(data))\n",
    "#         top=np.nanmax(data)*1.05\n",
    "        ax[i].set_ylim(bottom=0, top=top)\n",
    "\n",
    "        # Due to the Y-axis scale being different across samples, it can be\n",
    "        # hard to compare differences in medians across the samples. Add upper\n",
    "        # X-axis tick labels with the sample medians to aid in comparison\n",
    "        # (just use two decimal places of precision)\n",
    "        pos = np.arange(scenario_num+1) \n",
    "        medians = [(bp['medians'][k]).get_ydata()[0] for k in range(scenario_num+1)]\n",
    "        upper_labels = [str(np.round(s, 2)) for s in medians]\n",
    "        for tick, label in zip(range(scenario_num+1), ax[i].get_xticklabels()):\n",
    "            k = tick % 2\n",
    "            ax[i].text(pos[tick]+1.2, 0.9, upper_labels[tick],\n",
    "                     transform=ax[i].get_xaxis_transform(),\n",
    "                     horizontalalignment='center', size='xx-small',\n",
    "                     fontstyle='italic', color='b') #pos[tick], 1.02\n",
    "\n",
    "        # set y-axis label\n",
    "        y_lable = 'Ens Std.dev ' + unit_list[i]\n",
    "        ax[i].set_ylabel(y_lable, fontsize='xx-small')\n",
    "        if i == nrow-1:\n",
    "            ax[i].set_xlabel('Sampling Scenario', fontsize='xx-small')\n",
    "        \n",
    "        x_ticks = [str(x) for x in range(1,10)]\n",
    "        x_ticks.append('stn_ens')\n",
    "        ax[i].set_xticklabels(x_ticks)\n",
    "        ax[i].tick_params(axis='both', direction='out',labelsize = 'xx-small',\n",
    "                          length=1.5, width=0.5, pad=1.5)       \n",
    "        # title\n",
    "        alpha = chr(ord('a') + i)\n",
    "        ax[i].set_title('('+alpha+') '+var_list[i], pad=4, \n",
    "                        fontsize='xx-small', fontweight='semibold') #pad=9\n",
    "        \n",
    "# save plot\n",
    "fig.tight_layout(pad=0.1, h_pad=0.5) #h_pad=0.7\n",
    "fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value, bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close(fig)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pcp_std_stn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c03bf2171d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcp_std_stn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pcp_std_stn' is not defined"
     ]
    }
   ],
   "source": [
    "np.shape(pcp_std_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
