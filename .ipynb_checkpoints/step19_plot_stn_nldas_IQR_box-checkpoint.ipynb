{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot\n",
      "Precp\n",
      "Tmean\n",
      "Tmin\n",
      "Tmax\n",
      "Trange\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "def read_ens(out_forc_name_base, metric, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.'+metric+'.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]\n",
    "        pcp = f.variables['pcp'][:]\n",
    "        tmean = f.variables['t_mean'][:]\n",
    "        tmin = f.variables['t_min'][:]\n",
    "        tmax = f.variables['t_max'][:]\n",
    "        trange = f.variables['t_range'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            tmean_concat = tmean\n",
    "            tmin_concat = tmin\n",
    "            tmax_concat = tmax\n",
    "            trange_concat = trange\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_concat = np.concatenate((pcp_concat, pcp), axis=0) # (time,y,x)\n",
    "            tmean_concat = np.concatenate((tmean_concat, tmean), axis=0)\n",
    "            tmin_concat = np.concatenate((tmin_concat, tmin), axis=0)\n",
    "            tmax_concat = np.concatenate((tmax_concat, tmax), axis=0)\n",
    "            trange_concat = np.concatenate((trange_concat, trange), axis=0)\n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_concat, tmean_concat, tmin_concat, tmax_concat, trange_concat\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "stn_ens_dir = os.path.join(root_dir,'data/stn_ens_summary')\n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "start_yr = 2015\n",
    "end_yr = 2016\n",
    "\n",
    "gridinfo_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "scenarios_ids = range(0,9) #[0,1,5,8] \n",
    "intervals =  range(10,1,-1) #[10,9,5,2]\n",
    "scenario_num = len(scenarios_ids)\n",
    "\n",
    "subforlder = 'gmet_ens_summary'\n",
    "file_basename = 'ens_forc'\n",
    "\n",
    "ens_num = 100\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "dpi_value = 600\n",
    "plot_date_start = '2015-01-01'\n",
    "plot_date_end = '2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "output_dir=os.path.join(root_dir, 'scripts/step19_plot_stn_nldas_IQR_box')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_filename_base = 'step19_plot_stn_nldas_IQR_box_'\n",
    "   \n",
    "# #======================================================================================================\n",
    "# print('Read gridinfo mask')\n",
    "# # get xy mask from gridinfo.nc\n",
    "# f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "# mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "# #data_mask = f_gridinfo['data_mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# #======================================================================================================\n",
    "# # read historical nldas data summary\n",
    "# print('Read stn ens summary')\n",
    "\n",
    "# print(' -- read spatial ensemble')\n",
    "# for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "#     nldas_file = 'ens_forc.sumamry.'+str(yr)+'.nc'\n",
    "#     nldas_path = os.path.join(stn_ens_dir, nldas_file)\n",
    "    \n",
    "#     f_stn = xr.open_dataset(nldas_path)\n",
    "#     if yr == start_yr:\n",
    "#         pcp_lb = f_stn['pcp_lb'].values[:]\n",
    "#         pcp_ub = f_stn['pcp_ub'].values[:]\n",
    "\n",
    "#         tmean_lb = f_stn['tmean_lb'].values[:]\n",
    "#         tmean_ub = f_stn['tmean_ub'].values[:]\n",
    "\n",
    "#         tmin_lb = f_stn['tmin_lb'].values[:]\n",
    "#         tmin_ub = f_stn['tmin_ub'].values[:]\n",
    "\n",
    "#         tmax_lb = f_stn['tmax_lb'].values[:]\n",
    "#         tmax_ub = f_stn['tmax_ub'].values[:]\n",
    "\n",
    "#         trange_lb = f_stn['trange_lb'].values[:]\n",
    "#         trange_ub = f_stn['trange_ub'].values[:]\n",
    "#         time = f_stn['time'].values[:]\n",
    "#     else:\n",
    "#         pcp_lb = np.concatenate((pcp_lb, f_stn['pcp_lb'].values[:]), axis = 0)\n",
    "#         pcp_ub = np.concatenate((pcp_ub, f_stn['pcp_ub'].values[:]), axis = 0)\n",
    "\n",
    "#         tmean_lb = np.concatenate((tmean_lb, f_stn['tmean_lb'].values[:]), axis = 0)\n",
    "#         tmean_ub = np.concatenate((tmean_ub, f_stn['tmean_ub'].values[:]), axis = 0)\n",
    "\n",
    "#         tmin_lb = np.concatenate((tmin_lb, f_stn['tmin_lb'].values[:]), axis = 0)\n",
    "#         tmin_ub = np.concatenate((tmin_ub, f_stn['tmin_ub'].values[:]), axis = 0)\n",
    "\n",
    "#         tmax_lb = np.concatenate((tmax_lb, f_stn['tmax_lb'].values[:]), axis = 0)\n",
    "#         tmax_ub = np.concatenate((tmax_ub, f_stn['tmax_ub'].values[:]), axis = 0)\n",
    "\n",
    "#         trange_lb = np.concatenate((trange_lb, f_stn['trange_lb'].values[:]), axis = 0)\n",
    "#         trange_ub = np.concatenate((trange_ub, f_stn['trange_ub'].values[:]), axis = 0)\n",
    "#         time = np.concatenate((time, f_stn['time'].values[:]), axis = 0)\n",
    "\n",
    "# # get time mask from nldas data\n",
    "# # time_obj = np.asarray([datetime.datetime.strptime(t, time_format) for t in time])\n",
    "# time_obj = pd.to_datetime(time)\n",
    "# mask_t  = (time_obj >= plot_date_start_obj) & (time_obj <= plot_date_end_obj) \n",
    "# time_ens_stn = time_obj[mask_t]\n",
    "\n",
    "# print(' -- calculate temporal mean')\n",
    "# # caluclate time series mean(ny,nx)\n",
    "# pcp_iqr = np.nanmean(pcp_ub[mask_t,:,:]-pcp_lb[mask_t,:,:],axis=0)     \n",
    "# tmean_iqr = np.nanmean(tmean_ub[mask_t,:,:]-tmean_lb[mask_t,:,:],axis=0)\n",
    "# tmin_iqr = np.nanmean(tmin_ub[mask_t,:,:]-tmin_lb[mask_t,:,:],axis=0)\n",
    "# tmax_iqr = np.nanmean(tmax_ub[mask_t,:,:]-tmax_lb[mask_t,:,:],axis=0)\n",
    "# trange_iqr = np.nanmean(trange_ub[mask_t,:,:]-trange_lb[mask_t,:,:],axis=0)\n",
    "\n",
    "# print(' -- extract unmasked values')\n",
    "# # extract unmasked values\n",
    "# pcp_iqr=pcp_iqr[mask_xy!=0]    \n",
    "# tmean_iqr=tmean_iqr[mask_xy!=0] \n",
    "# tmin_iqr=tmin_iqr[mask_xy!=0]  \n",
    "# tmax_iqr=tmax_iqr[mask_xy!=0]   \n",
    "# trange_iqr=trange_iqr[mask_xy!=0] \n",
    "\n",
    "# del pcp_lb,pcp_ub,tmean_lb,tmean_ub,tmin_lb,tmin_ub\n",
    "# del tmax_lb,tmax_ub,trange_lb,trange_ub\n",
    "\n",
    "# #======================================================================================================\n",
    "# # read scenario ensemble results and save to dictionary\n",
    "# print('Read nldas ens bounds')\n",
    "\n",
    "# for k in range(scenario_num):\n",
    "\n",
    "#     test_folder = test_folders[scenarios_ids[k]]\n",
    "    \n",
    "#     print(test_folder)\n",
    "#     test_dir = os.path.join(result_dir, test_folder)\n",
    "#     fig_title= test_folder\n",
    "\n",
    "#     print(' -- read spatial ensemble')\n",
    "#     # read ensemble mean    \n",
    "#     output_namebase = os.path.join(test_dir,subforlder, file_basename)\n",
    "#     metric = 'enspctl.5'\n",
    "#     time_enslb, pcp_enslb, tmean_enslb, tmin_enslb, tmax_enslb, trange_enslb = read_ens(output_namebase, metric, start_yr, end_yr)\n",
    "\n",
    "#     output_namebase = os.path.join(test_dir,subforlder, file_basename)\n",
    "#     metric = 'enspctl.95'\n",
    "#     time_ensub, pcp_ensub, tmean_ensub, tmin_ensub, tmax_ensub, trange_ensub = read_ens(output_namebase, metric, start_yr, end_yr)\n",
    "\n",
    "#     # define plot mask for nldas ensemble\n",
    "#     mask_ens_t = (time_enslb>=plot_date_start_obj) & (time_enslb<=plot_date_end_obj)\n",
    "    \n",
    "#     print(' -- calculate temporal mean')\n",
    "#     # caluclate time series mean(ny,nx)\n",
    "#     pcp_ensiqr = np.nanmean(pcp_ensub[mask_ens_t,:,:]-pcp_enslb[mask_ens_t,:,:],axis=0)     \n",
    "#     tmean_ensiqr = np.nanmean(tmean_ensub[mask_ens_t,:,:]-tmean_enslb[mask_ens_t,:,:],axis=0)\n",
    "#     tmin_ensiqr = np.nanmean(tmin_ensub[mask_ens_t,:,:]-tmin_enslb[mask_ens_t,:,:],axis=0)\n",
    "#     tmax_ensiqr = np.nanmean(tmax_ensub[mask_ens_t,:,:]-tmax_enslb[mask_ens_t,:,:],axis=0)\n",
    "#     trange_ensiqr = np.nanmean(trange_ensub[mask_ens_t,:,:]-trange_enslb[mask_ens_t,:,:],axis=0)\n",
    "    \n",
    "#     print(' -- extract unmasked values')\n",
    "#     # extract unmasked values\n",
    "#     pcp_ensiqr=pcp_ensiqr[mask_xy!=0]    \n",
    "#     tmean_ensiqr=tmean_ensiqr[mask_xy!=0] \n",
    "#     tmin_ensiqr=tmin_ensiqr[mask_xy!=0]  \n",
    "#     tmax_ensiqr=tmax_ensiqr[mask_xy!=0]   \n",
    "#     trange_ensiqr=trange_ensiqr[mask_xy!=0] \n",
    "    \n",
    "#     # save to array\n",
    "#     if k == 0:\n",
    "#         grid_num = len(pcp_ensiqr)\n",
    "#         pcp_iqr_arr = np.zeros((grid_num,scenario_num))\n",
    "#         tmean_iqr_arr = np.zeros((grid_num,scenario_num)) \n",
    "#         tmin_iqr_arr = np.zeros((grid_num,scenario_num)) \n",
    "#         tmax_iqr_arr = np.zeros((grid_num,scenario_num))\n",
    "#         trange_iqr_arr = np.zeros((grid_num,scenario_num))\n",
    "    \n",
    "#     pcp_iqr_arr[:,k] = pcp_ensiqr\n",
    "#     tmean_iqr_arr[:,k] = tmean_ensiqr \n",
    "#     tmin_iqr_arr[:,k] = tmin_ensiqr\n",
    "#     tmax_iqr_arr[:,k] = tmax_ensiqr\n",
    "#     trange_iqr_arr[:,k] = trange_ensiqr\n",
    "    \n",
    "#     del pcp_ensiqr, tmean_ensiqr, tmin_ensiqr, tmax_ensiqr, trange_ensiqr\n",
    "#     del pcp_enslb, tmean_enslb, tmin_enslb, tmax_enslb, trange_enslb  \n",
    "#     del pcp_ensub, tmean_ensub, tmin_ensub, tmax_ensub, trange_ensub \n",
    "\n",
    "# #======================================================================================================    \n",
    "# # create a white-blue linear colormap\n",
    "# print('create colormap')\n",
    "\n",
    "# # reference: https://stackoverflow.com/questions/25408393/getting-individual-colors-from-a-color-map-in-matplotlib\n",
    "# cmap = mpl.cm.get_cmap('jet') # get the blue color of jet \n",
    "# c0 = cmap(0.0)\n",
    "# top = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",c0])\n",
    "\n",
    "# # combine two liner colormaps to create a\n",
    "# # reference: https://matplotlib.org/3.1.0/tutorials/colors/colormap-manipulation.html\n",
    "# bottom = mpl.cm.get_cmap('jet')\n",
    "# newcolors = np.vstack((top(np.linspace(0, 1, int(256*0.1))),bottom(np.linspace(0, 1, int(256*0.9)))))\n",
    "# newcmp = mpl.colors.LinearSegmentedColormap.from_list(\"WhiteJet\", newcolors)\n",
    "\n",
    "##======================================================================================================    \n",
    "# plot\n",
    "print('Plot')\n",
    "var_list = ['Precp', 'Tmean', 'Tmin', 'Tmax', 'Trange']\n",
    "var_units = ['(mm/d)','($^\\circ$C)','($^\\circ$C)','($^\\circ$C)','($^\\circ$C)']\n",
    "# var_list = ['Precp']\n",
    "for m in range(len(var_list)): # loop all five variables\n",
    "    var = var_list[m]\n",
    "    output_filename = output_filename_base+var+'.png'\n",
    "    print(var)\n",
    "    \n",
    "    # data selection\n",
    "    if m == 0:\n",
    "        iqr = (-1)*pcp_iqr # NOTE: need to remove (-1) when fixing the stn_summary issue\n",
    "        ens_iqr_arr = pcp_iqr_arr\n",
    "    elif m == 1:\n",
    "        iqr = (-1)*tmean_iqr\n",
    "        ens_iqr_arr = tmean_iqr_arr\n",
    "    elif m == 2:\n",
    "        iqr = (-1)*tmin_iqr\n",
    "        ens_iqr_arr = tmin_iqr_arr\n",
    "    elif m == 3:\n",
    "        iqr = (-1)*tmax_iqr\n",
    "        ens_iqr_arr = tmax_iqr_arr\n",
    "    elif m == 4:\n",
    "        iqr = (-1)*trange_iqr\n",
    "        ens_iqr_arr = trange_iqr_arr\n",
    "    \n",
    "    # xy aixs range\n",
    "#     vmin_ensiqr=np.nanmin(ens_iqr_arr)\n",
    "#     vmax_ensiqr=np.nanmax(ens_iqr_arr) \n",
    "    \n",
    "#     vmin = np.nanmin([vmin_ensiqr,np.nanmin(iqr)])\n",
    "#     vmax = np.nanmax([vmax_ensiqr,np.nanmax(iqr)])\n",
    "    \n",
    "    vmin = np.nanmin(iqr)\n",
    "    vmax = np.nanmax(iqr)\n",
    "    \n",
    "    # MAE\n",
    "    mae=[np.nanmean(np.absolute(ens_iqr_arr[:,j]-iqr)) for j in range(scenario_num)]    \n",
    "    \n",
    "    # plot each varaiable seperately\n",
    "    nrow = 3 # totally 9 sampling scenarios\n",
    "    ncol = 3\n",
    "            \n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(4,4.5))\n",
    "\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            k = i*ncol+j\n",
    "            \n",
    "#             print('sample scenario '+str(k+1))\n",
    "\n",
    "            # 2D histograms\n",
    "            # https://python-graph-gallery.com/83-basic-2d-histograms-with-matplotlib/\n",
    "            x = iqr\n",
    "            y = ens_iqr_arr[:,k]\n",
    "            hist = ax[i,j].hist2d(x, y, bins=(200, 200),cmap=newcmp, \n",
    "                                  range=[[vmin, vmax], [vmin, vmax]]) # return (counts, xedges, yedges, Image)\n",
    "    \n",
    "            # diagonal\n",
    "            ax[i,j].plot([vmin, vmax],[vmin, vmax],color='grey',linewidth=0.5, alpha=0.6)\n",
    "            \n",
    "            # MAE text\n",
    "            mae_str = 'MAE = '+str(round(mae[k],2))\n",
    "            ax[i,j].text(0.5, 0.92,s=mae_str,fontsize='xx-small',fontstyle='italic',\n",
    "                         horizontalalignment='center', verticalalignment='center', transform=ax[i,j].transAxes)\n",
    "            \n",
    "            # limit\n",
    "            ax[i,j].set_xlim(vmin, vmax)\n",
    "            ax[i,j].set_ylim(vmin, vmax)\n",
    "\n",
    "            # label\n",
    "            if i == nrow-1:\n",
    "                xlabel = 'Station Ensemble IQR\\nof '+var_list[m]+' '+var_units[m]\n",
    "                ax[i,j].set_xlabel(xlabel, fontsize='xx-small')\n",
    "            if j == 0:\n",
    "                ylabel = 'NLDAS Ensemble IQR\\nof '+var_list[m]+' '+var_units[m]\n",
    "                ax[i,j].set_ylabel(ylabel, fontsize='xx-small')\n",
    "             \n",
    "            # tick\n",
    "            ax[i,j].tick_params(axis='both', direction='out',labelsize = 'xx-small', \n",
    "                                length=2, width=0.5, pad=1.5)\n",
    "            if j == 0:\n",
    "                ax[i,j].tick_params(axis='both',labelleft = True)\n",
    "            else:\n",
    "                ax[i,j].tick_params(axis='both',labelleft = False)\n",
    "            if i == nrow-1:\n",
    "                ax[i,j].tick_params(axis='both',labelbottom = True)\n",
    "            else:\n",
    "                ax[i,j].tick_params(axis='both',labelbottom = False)\n",
    "                \n",
    "            # title\n",
    "            title_str = 'Scenario '+str(k+1) +' (interval = '+str(intervals[k])+')'\n",
    "            ax[i,j].set_title(title_str, fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "           # change subplot border width\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax[i,j].spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    # colorbar    \n",
    "    fig.subplots_adjust(bottom=0.17, top=1, left = 0, right=1, wspace = 0.07, hspace = 0.25)\n",
    "    cax = fig.add_axes([0.25, 0.05, 0.5, 0.02]) #[left, bottom, width, height]\n",
    "    cbar = fig.colorbar(hist[3], cax=cax, orientation='horizontal')\n",
    "\n",
    "    tick1 = hist[0].max()*0.5\n",
    "    tick2 = hist[0].max()\n",
    "    cbar.set_ticks([0, tick1, tick2]) \n",
    "    cbar.set_ticklabels(['Low', 'Medium', 'High'])  \n",
    "    cbar.ax.tick_params(labelsize='xx-small', length=2, width=1)\n",
    "\n",
    "    # set the colorbar ticks and tick labels\n",
    "    cbar.set_label(label='Number of grids per pixel',size='xx-small')    \n",
    "\n",
    "    # save plot\n",
    "    fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value, \n",
    "                bbox_inches = 'tight', pad_inches = 0.05)\n",
    "    plt.close(fig)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4068713620305062, 18.381982365250586)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_left, common_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
