{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/xarray/core/merge.py:17: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n",
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/xarray/core/dataarray.py:1658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  3: pd.Panel}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00822grids\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def read_ens(out_forc_name_base, ens_num):\n",
    "    for i in range(ens_num):\n",
    "        ens_file = os.path.join(out_forc_name_base + '.' + str('%03d' % (i+1)) +'.nc')\n",
    "        \n",
    "        f=xr.open_dataset(ens_file)\n",
    "        pcp = f.variables['pcp'][:]\n",
    "        t_mean = f.variables['t_mean'][:]\n",
    "        t_range = f.variables['t_range'][:]\n",
    "\n",
    "        if i == 0:\n",
    "            lats = f['latitude'].values[:] #shape (y,x)\n",
    "            lons = f['longitude'].values[:]\n",
    "            time = pd.DatetimeIndex(f['time'][:].dt.floor('D').to_pandas())\n",
    "                 \n",
    "            pcp_ens = np.zeros((np.shape(pcp)[0], np.shape(pcp)[1], np.shape(pcp)[2], ens_num))# create ens array \n",
    "            t_mean_ens = np.zeros((np.shape(pcp)[0], np.shape(pcp)[1], np.shape(pcp)[2], ens_num))\n",
    "            t_range_ens = np.zeros((np.shape(pcp)[0], np.shape(pcp)[1], np.shape(pcp)[2], ens_num))\n",
    "\n",
    "        pcp_ens[:,:,:,i] = pcp\n",
    "        t_mean_ens[:,:,:,i] = t_mean\n",
    "        t_range_ens[:,:,:,i] = t_range\n",
    "       \n",
    "    return lats, lons, time, pcp_ens, t_mean_ens, t_range_ens\n",
    "\n",
    "root_dir = '/glade/u/home/hongli/work/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc')\n",
    "start_yr = 2015\n",
    "end_yr = 2016\n",
    "\n",
    "gridinfo_file = os.path.join(root_dir,'scripts/conus_ens_grid_eighth_deg_v1p1.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "# ens_date_start = '2015-01-01'\n",
    "# ens_date_end = '2016-12-31'\n",
    "# ens_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "# ens_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "ens_num = 100\n",
    "ens_ofolder = 'gmet_ens_combine'\n",
    "ens_ofile_basename = 'ens_forc.2015-2016'\n",
    "ens_ofolder_bc = 'gmet_ens_combine_bc' # bias correction\n",
    "\n",
    "output_dir=os.path.join(root_dir,'scripts/step9_bias_correct_ens')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# #======================================================================================================\n",
    "# print('Read gridinfo mask')\n",
    "# # get xy mask from gridinfo.nc\n",
    "# f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "# mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# #======================================================================================================\n",
    "# # read historical nldas data\n",
    "# print('Read nldas data')\n",
    "# for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "#     nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "#     nldas_path = os.path.join(nldas_dir, nldas_file)\n",
    "    \n",
    "#     f_nldas = xr.open_dataset(nldas_path)\n",
    "#     if yr == start_yr:\n",
    "#         prcp_avg = f_nldas['prcp_avg'].values[:] # (time, y, x). unit: kg/m^2 = mm\n",
    "#         tair_min = f_nldas['tair_min'].values[:] # (time, y, x). unit: K\n",
    "#         tair_max = f_nldas['tair_max'].values[:]\n",
    "#         time = pd.to_datetime(f_nldas['time'].values[:]).strftime(time_format)\n",
    "#     else:\n",
    "#         prcp_avg = np.concatenate((prcp_avg, f_nldas['prcp_avg'].values[:]), axis = 0)\n",
    "#         tair_min = np.concatenate((tair_min, f_nldas['tair_min'].values[:]), axis = 0)\n",
    "#         tair_max = np.concatenate((tair_max, f_nldas['tair_max'].values[:]), axis = 0)\n",
    "#         time = np.concatenate((time, pd.to_datetime(f_nldas['time'].values[:]).strftime(time_format)), axis = 0)\n",
    "#     f_nldas.close()\n",
    " \n",
    "# # convert unit and calculate mean values\n",
    "# time_obj = np.asarray([datetime.datetime.strptime(t, time_format) for t in time])\n",
    "# prcp_sum = np.multiply(prcp_avg[mask_t,:,:], 24.0) # mm/hr to mm/day. (time,y,x)\n",
    "# tair_min = np.subtract(tair_min[mask_t,:,:], 273.15) # K to degC.\n",
    "# tair_max = np.subtract(tair_max[mask_t,:,:], 273.15)\n",
    "# tair_mean = 0.5*(tair_max-tair_min)\n",
    "\n",
    "for test_folder in test_folders[0:1]:    \n",
    "    print(test_folder)\n",
    "    \n",
    "    # read ensemble output\n",
    "    output_namebase = os.path.join(result_dir,test_folder,ens_ofolder,ens_ofile_basename)\n",
    "    ens_lats, ens_lons, ens_time, pcp_ens, tmean_ens, trange_ens = read_ens(output_namebase, ens_num)\n",
    "        \n",
    "    # calculate ensemble mean over 100 members\n",
    "    pcp_ens_mean  = np.nanmean(pcp_ens, axis=3) # (time,y,x)\n",
    "    tmean_ens_mean = np.nanmean(tmean_ens, axis=3)\n",
    "        \n",
    "    # get time mask for nldas data\n",
    "    nldas_mask_t  = (time_obj >= ens_time[0]) & (time_obj <= ens_time[-1]) \n",
    "\n",
    "    # calcualte delta for pcp, tmin, and tmax\n",
    "    pcp_delta = prcp_sum[nldas_mask_t,:,:] - pcp_ens_mean # (time,y,x)\n",
    "    tmean_delta = tair_mean[nldas_mask_t,:,:] - tmean_ens_mean\n",
    "    \n",
    "    # bias correct ensemble\n",
    "    pcp_ens_correct = pcp_ens + pcp_delta\n",
    "    tmean_ens_correct = trange_ens + tmean_delta\n",
    "\n",
    "#     # save bias-crrected ensemble\n",
    "#     if not os.path.exists(os.path.join(result_dir,test_folder,ens_ofolder_bc)):\n",
    "#         os.path.makedirs(os.path.join(result_dir,test_folder,ens_ofolder_bc))\n",
    "        \n",
    "#     for m in range(ens_num):\n",
    "#         NUM = str('%03d' % (i+1))\n",
    "#         SrcFile = os.path.join(result_dir,test_folder,ens_ofolder,ens_ofile_basename+ '.' + NUM +'.nc')\n",
    "#         DstFile = os.path.join(result_dir,test_folder,ens_ofolder_bc,ens_ofile_basename+ '.' + NUM +'.nc')\n",
    "        \n",
    "#         with nc.Dataset(SrcFile) as src:\n",
    "#             with nc.Dataset(DstFile, \"w\") as dst:\n",
    "\n",
    "#                 # copy dimensions\n",
    "#                 for name, dimension in src.dimensions.items():\n",
    "#                      dst.createDimension(\n",
    "#                         name, (len(dimension) if not dimension.isunlimited() else None))\n",
    "\n",
    "#                 # copy variable attributes all at once via dictionary (for the included variables)\n",
    "#                 include = ['pcp', 't_mean']\n",
    "#                 for name, variable in src.variables.items():\n",
    "#                     x = dst.createVariable(name, variable.datatype, variable.dimensions)               \n",
    "#                     dst[name].setncatts(src[name].__dict__)\n",
    "#                     if not name in include:\n",
    "#                         dst[name][:]=src[name][:]                \n",
    "\n",
    "#                 # assign values for variables ([:] is necessary)\n",
    "#                 dst.variables['time'][:] = nc.date2num(datetime_unique, dst.variables['time'].units)\n",
    "\n",
    "#                 # create Prcp, Tmin, and Tmax variables \n",
    "#                 vars_short = ['tmin','tmax','prcp']\n",
    "#                 vars_long = ['Minimum daily air temperature', 'Maximum daily air temperature', 'Total daily precipitation']\n",
    "#                 units = ['degC', 'degC', 'mm/day']\n",
    "\n",
    "#                 for i, var in enumerate(vars_short):\n",
    "#                     print(var)\n",
    "\n",
    "#                     # create\n",
    "#                     var_i = dst.createVariable(var,np.float64,('time','y','x')) # note: unlimited dimension is leftmost\n",
    "#                     var_i.long_name = vars_long[i]\n",
    "#                     var_i.units = units[i] \n",
    "\n",
    "#                 dst.variables['tmax'][:] = tmax_daily\n",
    "#                 dst.variables['tmin'][:] = tmin_daily\n",
    "#                 dst.variables['prcp'][:] = prcp_daily \n",
    "        \n",
    "# del prcp_avg,tair_min,tair_max\n",
    "print('Done')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcp_ens_mean[0,100:103,100:103],tmean_ens_mean[0,100:103,100:103]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENTER]",
   "language": "python",
   "name": "conda-env-ENTER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
