{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot\n",
      "Precp'\n",
      "Precp_2'\n",
      "Tmean_2\n",
      "Trange_2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "def read_stn_regr(out_forc_name_base, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + str(yr)+'0101_' + str(yr)+'1231' + '.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]        \n",
    "        pcp_error = f.variables['pcp_error'][:]\n",
    "        pcp_error_2 = f.variables['pcp_error_2'][:]\n",
    "        tmean_error_2 = f.variables['tmean_error_2'][:]\n",
    "        trange_error_2 = f.variables['trange_error_2'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_error_concat = pcp_error\n",
    "            pcp_error_2_concat = pcp_error_2\n",
    "            tmean_error_2_concat = tmean_error_2\n",
    "            trange_error_2_concat = trange_error_2\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_error_concat = np.concatenate((pcp_error_concat, pcp_error), axis=0) # (time,y,x)\n",
    "            pcp_error_2_concat = np.concatenate((pcp_error_2_concat, pcp_error_2), axis=0) \n",
    "            tmean_error_2_concat = np.concatenate((tmean_error_2_concat, tmean_error_2), axis=0)\n",
    "            trange_error_2_concat = np.concatenate((trange_error_2_concat, trange_error_2), axis=0)\n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_error_concat, pcp_error_2_concat, tmean_error_2_concat, trange_error_2_concat\n",
    "\n",
    "def read_nldas_regr(out_forc_name_base, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]\n",
    "        pcp_error = f.variables['pcp_error_update'][:]\n",
    "        pcp_error_2 = f.variables['pcp_error_2_update'][:]\n",
    "        tmean_error_2 = f.variables['tmean_error_2'][:]\n",
    "        trange_error_2 = f.variables['trange_error_2'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_error_concat = pcp_error\n",
    "            pcp_error_2_concat = pcp_error_2\n",
    "            tmean_error_2_concat = tmean_error_2\n",
    "            trange_error_2_concat = trange_error_2\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_error_concat = np.concatenate((pcp_error_concat, pcp_error), axis=0) # (time,y,x)\n",
    "            pcp_error_2_concat = np.concatenate((pcp_error_2_concat, pcp_error_2), axis=0) \n",
    "            tmean_error_2_concat = np.concatenate((tmean_error_2_concat, tmean_error_2), axis=0)\n",
    "            trange_error_2_concat = np.concatenate((trange_error_2_concat, trange_error_2), axis=0)\n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_error_concat, pcp_error_2_concat, tmean_error_2_concat, trange_error_2_concat\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "start_yr = 2013\n",
    "end_yr = 2016\n",
    "\n",
    "stn_grid_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "nldas_grid_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth_deg_v1p1.nc')\n",
    "stn_regr_dir = os.path.join(root_dir,'data/stn_regr')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "\n",
    "scenarios_ids = range(0,1)  \n",
    "intervals =  range(10,9,-1) \n",
    "scenario_num = len(scenarios_ids)\n",
    "\n",
    "subforlder = 'gmet_regr'\n",
    "file_basename = 'regress_ts'\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "plot_date_start = '2013-01-01'\n",
    "plot_date_end = '2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "dpi_value = 150\n",
    "output_dir=os.path.join(root_dir, 'scripts/step24_plot_regr_error_box_wSTN')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_filename = 'step24_plot_regr_error_box_wSTN2.png'\n",
    "    \n",
    "# #======================================================================================================\n",
    "# print('Read gridinfo mask')\n",
    "# # get xy mask from gridinfo.nc\n",
    "# f_stn_grid = xr.open_dataset(stn_grid_file)\n",
    "# stn_mask_xy = f_stn_grid['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# f_nldas_grid = xr.open_dataset(nldas_grid_file)\n",
    "# nldas_mask_xy = f_nldas_grid['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# # commonly available area\n",
    "# mask_xy = (stn_mask_xy!=0) & (nldas_mask_xy!=0) \n",
    "\n",
    "# #======================================================================================================\n",
    "# # read scenario regression results and save to dictionary\n",
    "# print('Read nldas regression uncertainty')\n",
    "\n",
    "# for k in range(scenario_num):\n",
    "# # for k in range(1):\n",
    "\n",
    "#     test_folder = test_folders[scenarios_ids[k]]\n",
    "    \n",
    "#     print(test_folder)\n",
    "#     test_dir = os.path.join(result_dir, test_folder)\n",
    "#     fig_title= test_folder\n",
    "\n",
    "#     print(' -- read spatial uncertainty')\n",
    "#     # read regression uncertainty    \n",
    "#     output_namebase = os.path.join(test_dir,subforlder, file_basename)\n",
    "#     time_regr, pcp_error,  pcp_error_2, tmean_error_2, trange_error_2 = read_nldas_regr(output_namebase, start_yr, end_yr)\n",
    "    \n",
    "#     # define plot mask for nldas ensemble\n",
    "#     mask_ens_t = (time_regr>=plot_date_start_obj) & (time_regr<=plot_date_end_obj)\n",
    "    \n",
    "#     print(' -- calculate temporal mean')\n",
    "#     # caluclate time series mean(ny,nx)\n",
    "#     pcp_error_mean = np.nanmean(pcp_error[mask_ens_t,:,:],axis=0)     \n",
    "#     pcp_error_2_mean = np.nanmean(pcp_error_2[mask_ens_t,:,:],axis=0)     \n",
    "#     tmean_error_2_mean = np.nanmean(tmean_error_2[mask_ens_t,:,:],axis=0)\n",
    "#     trange_error_2_mean = np.nanmean(trange_error_2[mask_ens_t,:,:],axis=0)\n",
    "    \n",
    "#     print(' -- extract unmasked values')\n",
    "#     # extract unmasked values\n",
    "#     pcp_error_mean=pcp_error_mean[mask_xy]    \n",
    "#     pcp_error_2_mean=pcp_error_2_mean[mask_xy]    \n",
    "#     tmean_error_2_mean=tmean_error_2_mean[mask_xy] \n",
    "#     trange_error_2_mean=trange_error_2_mean[mask_xy] \n",
    "    \n",
    "#     # save to array\n",
    "#     if k == 0:\n",
    "#         grid_num = len(pcp_error_mean)\n",
    "#         pcp_error_mean_arr = np.zeros((grid_num,scenario_num+1)) #one more column for station regr\n",
    "#         pcp_error_2_mean_arr = np.zeros((grid_num,scenario_num+1))\n",
    "#         tmean_error_2_mean_arr = np.zeros((grid_num,scenario_num+1)) \n",
    "#         trange_error_2_mean_arr = np.zeros((grid_num,scenario_num+1))\n",
    "    \n",
    "#     pcp_error_mean_arr[:,k] = pcp_error_mean\n",
    "#     pcp_error_2_mean_arr[:,k] = pcp_error_2_mean\n",
    "#     tmean_error_2_mean_arr[:,k] = tmean_error_2_mean \n",
    "#     trange_error_2_mean_arr[:,k] = trange_error_2_mean\n",
    "    \n",
    "#     del pcp_error_mean, pcp_error_2_mean, tmean_error_2_mean, trange_error_2_mean\n",
    "#     del pcp_error, pcp_error_2, tmean_error_2, trange_error_2  \n",
    "\n",
    "# #======================================================================================================\n",
    "# # read station regression results\n",
    "# print('Read station regression uncertainty')\n",
    "# print(' -- read spatial errors')\n",
    "# output_namebase = os.path.join(stn_regr_dir, 'conus_regress_eighth_')\n",
    "# stn_time_regr, stn_pcp_error,  stn_pcp_error_2, stn_tmean_error_2, stn_trange_error_2 = read_stn_regr(output_namebase, start_yr, end_yr)\n",
    "\n",
    "# # define plot mask for stn regr\n",
    "# mask_stn_t = (stn_time_regr>=plot_date_start_obj) & (stn_time_regr<=plot_date_end_obj)\n",
    "\n",
    "# print(' -- calculate temporal mean')\n",
    "# # caluclate time series mean(ny,nx)\n",
    "# stn_pcp_error_mean = np.nanmean(stn_pcp_error[mask_stn_t,:,:],axis=0)     \n",
    "# stn_pcp_error_2_mean = np.nanmean(stn_pcp_error_2[mask_stn_t,:,:],axis=0)     \n",
    "# stn_tmean_error_2_mean = np.nanmean(stn_tmean_error_2[mask_stn_t,:,:],axis=0)\n",
    "# stn_trange_error_2_mean = np.nanmean(stn_trange_error_2[mask_stn_t,:,:],axis=0)\n",
    "\n",
    "# print(' -- extract unmasked values')\n",
    "# # extract unmasked values\n",
    "# stn_pcp_error_mean=stn_pcp_error_mean[mask_xy]    \n",
    "# stn_pcp_error_2_mean=stn_pcp_error_2_mean[mask_xy]    \n",
    "# stn_tmean_error_2_mean=stn_tmean_error_2_mean[mask_xy] \n",
    "# stn_trange_error_2_mean=stn_trange_error_2_mean[mask_xy] \n",
    "\n",
    "# pcp_error_mean_arr[:,-1] = stn_pcp_error_mean\n",
    "# pcp_error_2_mean_arr[:,-1] = stn_pcp_error_2_mean\n",
    "# tmean_error_2_mean_arr[:,-1] = stn_tmean_error_2_mean \n",
    "# trange_error_2_mean_arr[:,-1] = stn_trange_error_2_mean\n",
    "\n",
    "# del stn_pcp_error_mean, stn_pcp_error_2_mean, stn_tmean_error_2_mean, stn_trange_error_2_mean\n",
    "# del stn_pcp_error, stn_pcp_error_2, stn_tmean_error_2, stn_trange_error_2  \n",
    " \n",
    "#======================================================================================================    \n",
    "# plot\n",
    "print('Plot')\n",
    "var_list = [\"Precp'\", \"Precp_2'\", 'Tmean_2', 'Trange_2']\n",
    "\n",
    "nrow = len(var_list) # prcp, tmean, tmin, tmax, trange\n",
    "ncol = 1 \n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(5.5/9*5,5.5*1.2))#, constrained_layout=True)\n",
    "\n",
    "for i in range(nrow):\n",
    "        print(var_list[i])\n",
    "        \n",
    "        # select data for each subplot\n",
    "        if i == 0:\n",
    "            data=pcp_error_mean_arr\n",
    "            top=2\n",
    "        elif i == 1:\n",
    "            data=pcp_error_2_mean_arr\n",
    "            top=0.7\n",
    "        elif i == 2:\n",
    "            data=tmean_error_2_mean_arr\n",
    "            top=18\n",
    "        elif i == 3:\n",
    "            data=trange_error_2_mean_arr\n",
    "            top=15\n",
    "        \n",
    "        # boxplot\n",
    "        # reference: https://matplotlib.org/3.1.1/gallery/statistics/boxplot_demo.html\n",
    "        bp = ax[i].boxplot(data, sym='o')#, labels=labels)\n",
    "        plt.setp(bp['boxes'], color='black')\n",
    "        plt.setp(bp['whiskers'], color='black')\n",
    "        plt.setp(bp['fliers'], color='red', marker='o',markersize=1.5)\n",
    "        \n",
    "        # Add a horizontal grid to the plot, but make it very light in color\n",
    "        # so we can use it for reading data values but not be distracting\n",
    "        ax[i].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
    "        ax[i].set_axisbelow(True)\n",
    "        \n",
    "        # y_lim\n",
    "#         bottom=np.nanmin(data)-0.05*(np.nanmax(data)-np.nanmin(data))\n",
    "#         top=np.nanmax(data)*1.05\n",
    "#         ax[i].set_ylim(bottom=0, top=top)\n",
    "\n",
    "#         # Due to the Y-axis scale being different across samples, it can be\n",
    "#         # hard to compare differences in medians across the samples. Add upper\n",
    "#         # X-axis tick labels with the sample medians to aid in comparison\n",
    "#         # (just use two decimal places of precision)\n",
    "#         pos = np.arange(scenario_num+1) \n",
    "#         medians = [(bp['medians'][k]).get_ydata()[0] for k in range(scenario_num+1)]\n",
    "#         upper_labels = [str(np.round(s, 2)) for s in medians]\n",
    "#         for tick, label in zip(range(scenario_num+1), ax[i].get_xticklabels()):\n",
    "#             k = tick % 2\n",
    "#             ax[i].text(pos[tick]+0.2, 0.9, upper_labels[tick],\n",
    "#                      transform=ax[i].get_xaxis_transform(),\n",
    "#                      horizontalalignment='center', size='xx-small',\n",
    "#                      fontstyle='italic', color='b') #pos[tick], 1.02\n",
    "\n",
    "        # set y-axis label\n",
    "        y_lable = 'Regression uncertainty'\n",
    "        ax[i].set_ylabel(y_lable, fontsize='xx-small')\n",
    "        if i == nrow-1:\n",
    "            ax[i].set_xlabel('Sampling Scenario', fontsize='xx-small')\n",
    "        \n",
    "        x_ticks = [str(x) for x in range(1,scenario_num+1)]\n",
    "        x_ticks.append('stn_regr')\n",
    "        ax[i].set_xticklabels(x_ticks)\n",
    "        ax[i].tick_params(axis='both', direction='out',labelsize = 'xx-small',\n",
    "                          length=1.5, width=0.5, pad=1.5)       \n",
    "        # title\n",
    "        alpha = chr(ord('a') + i)\n",
    "        ax[i].set_title('('+alpha+') '+var_list[i], pad=4, \n",
    "                        fontsize='xx-small', fontweight='semibold') #pad=9\n",
    "        \n",
    "# save plot\n",
    "fig.tight_layout(pad=0.1, h_pad=0.5) #h_pad=0.7\n",
    "fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value, bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close(fig)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 8, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_ids = range(0,9) #[0,1,5,8] \n",
    "intervals =  range(10,2,-1) #[10,9,5,2]\n",
    "scenario_num = len(scenarios_ids)\n",
    "scenario_num,scenarios_ids[-1],intervals[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.23']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 464), (80220,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.nanmean(stn_pcp_error[mask_stn_t,:,:],axis=0)\n",
    "b=a[mask_xy]\n",
    "np.shape(a), np.shape(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
