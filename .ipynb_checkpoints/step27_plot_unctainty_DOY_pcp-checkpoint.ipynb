{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot\n",
      "pcp\n",
      "Precp (when NLDAS = 0)\n",
      "Precp (when NLDAS ≠ 0)\n",
      "pcp_2\n",
      "Precp (when NLDAS = 0)\n",
      "Precp (when NLDAS ≠ 0)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os,scipy\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "def read_nldas_regr(out_forc_name_base, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]\n",
    "        pcp_error_update = f.variables['pcp_error_update'][:]\n",
    "        pcp_error_2_update = f.variables['pcp_error_2_update'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_error_concat = pcp_error_update\n",
    "            pcp_error_2_concat = pcp_error_2_update\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_error_concat = np.concatenate((pcp_error_concat, pcp_error_update), axis=0) # (time,y,x)\n",
    "            pcp_error_2_concat = np.concatenate((pcp_error_2_concat, pcp_error_2_update), axis=0) \n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_error_concat, pcp_error_2_concat\n",
    "\n",
    "def read_ens(out_forc_name_base, metric, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.'+metric+'.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]\n",
    "        pcp = f.variables['pcp'][:]\n",
    "        tmean = f.variables['t_mean'][:]\n",
    "        tmin = f.variables['t_min'][:]\n",
    "        tmax = f.variables['t_max'][:]\n",
    "        trange = f.variables['t_range'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            tmean_concat = tmean\n",
    "            tmin_concat = tmin\n",
    "            tmax_concat = tmax\n",
    "            trange_concat = trange\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_concat = np.concatenate((pcp_concat, pcp), axis=0) # (time,y,x)\n",
    "            tmean_concat = np.concatenate((tmean_concat, tmean), axis=0)\n",
    "            tmin_concat = np.concatenate((tmin_concat, tmin), axis=0)\n",
    "            tmax_concat = np.concatenate((tmax_concat, tmax), axis=0)\n",
    "            trange_concat = np.concatenate((trange_concat, trange), axis=0)\n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_concat, tmean_concat, tmin_concat, tmax_concat, trange_concat\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "stn_ens_dir = os.path.join(root_dir,'data/stn_ens_summary')\n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "start_yr = 2013\n",
    "end_yr = 2016\n",
    "\n",
    "gridinfo_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "result_dir = os.path.join(root_dir,'test_uniform_perturb')\n",
    "test_folders = [d for d in os.listdir(result_dir)]\n",
    "test_folders = sorted(test_folders)\n",
    "scenarios_ids = range(0,9) \n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "plot_date_start = '2013-01-01'\n",
    "plot_date_end = '2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "dpi_value = 150\n",
    "output_dir=os.path.join(root_dir, 'scripts/step27_plot_unctainty_DOY_pcp')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "# #======================================================================================================\n",
    "# print('Read gridinfo mask')\n",
    "# # get xy mask from gridinfo.nc\n",
    "# f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "# mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "# #======================================================================================================\n",
    "# # read historical nldas data\n",
    "# print('Read nldas data')\n",
    "# for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "#     nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "#     nldas_path = os.path.join(nldas_dir, nldas_file)\n",
    "    \n",
    "#     f_nldas = xr.open_dataset(nldas_path)\n",
    "#     if yr == start_yr:\n",
    "#         pcp = f_nldas['pcp'].values[:] # (time, y, x). unit: mm/day\n",
    "#         time = f_nldas['time'].values[:]\n",
    "#     else:\n",
    "#         pcp = np.concatenate((pcp, f_nldas['pcp'].values[:]), axis = 0)\n",
    "#         time = np.concatenate((time, f_nldas['time'].values[:]), axis = 0)\n",
    "\n",
    "# # get time mask from nldas data\n",
    "# time_obj = pd.to_datetime(time)\n",
    "# mask_t  = (time_obj >= plot_date_start_obj) & (time_obj <= plot_date_end_obj) \n",
    "# time_nldas = time_obj[mask_t]\n",
    "\n",
    "# nt_nldas = len(time_nldas)\n",
    "# mask_xy_3d_nldas = np.repeat(mask_xy[np.newaxis,:,:],nt_nldas,axis=0)\n",
    "\n",
    "# pcp = pcp[mask_xy_3d_nldas!=0]    \n",
    "# pcp = pcp.reshape((nt_nldas,-1))\n",
    "\n",
    "# # calculate DOY (day of year) mean IQR    \n",
    "# df_nlds = pd.DataFrame(pcp)    \n",
    "# time_month = [t.month for t in time_nldas]\n",
    "# time_day = [t.day for t in time_nldas]\n",
    "# df_nlds['month']=time_month\n",
    "# df_nlds['date']=time_day  \n",
    "# df_nlds2 = df_nlds.groupby(['month','date']).mean()\n",
    "\n",
    "# del pcp\n",
    "\n",
    "# #======================================================================================================\n",
    "# # read scenario regression results \n",
    "# print('Read regression uncertainty')\n",
    "# k=7-1\n",
    "# test_folder = test_folders[scenarios_ids[k]]\n",
    "\n",
    "# print(test_folder)\n",
    "# test_dir = os.path.join(result_dir, test_folder)\n",
    "# fig_title= test_folder\n",
    "\n",
    "# # read\n",
    "# nldas_regr_dir = os.path.join(root_dir,'test_uniform_perturb',test_folder,'gmet_regr')\n",
    "# output_namebase = os.path.join(nldas_regr_dir,'regress_ts')\n",
    "# time_regr, pcp_error, pcp_error_2 = read_nldas_regr(output_namebase, start_yr, end_yr)\n",
    "\n",
    "# # define plot mask for nldas regr\n",
    "# mask_regr_t = (time_regr>=plot_date_start_obj) & (time_regr<=plot_date_end_obj)\n",
    "# time_regr = time_regr[mask_regr_t]\n",
    "\n",
    "# nt_regr = len(time_regr)\n",
    "# mask_xy_3d_regr = np.repeat(mask_xy[np.newaxis,:,:],nt_regr,axis=0)\n",
    "\n",
    "# pcp_error = pcp_error[mask_xy_3d_regr!=0]    \n",
    "# pcp_error_2 = pcp_error_2[mask_xy_3d_regr!=0]    \n",
    "\n",
    "# # reshape\n",
    "# # reshpae (nt,ny,nx) -> (nt,ny*nx)\n",
    "# pcp_error = pcp_error.reshape((nt_regr,-1))\n",
    "# pcp_error_2 = pcp_error_2.reshape((nt_regr,-1))\n",
    "\n",
    "##======================================================================================================    \n",
    "# plot\n",
    "print('Plot')\n",
    "for k in range(2):\n",
    "    if k == 0:\n",
    "        data = pcp_error \n",
    "        output_filename = 'step27_plot_unctainty_DOY_pcp.png'\n",
    "        print('pcp')\n",
    "    else:\n",
    "        data = pcp_error_2\n",
    "        output_filename = 'step27_plot_unctainty_DOY_pcp_2.png'\n",
    "        print('pcp_2')\n",
    "\n",
    "    var_list = ['Precp (when NLDAS = 0)', 'Precp (when NLDAS ≠ 0)']\n",
    "    var_units = ['(mm/d)','(mm/d)']\n",
    "    \n",
    "    # plot each varaiable seperately\n",
    "    nrow = len(var_list) \n",
    "    ncol = 1           \n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(3.54,3.54*0.75))\n",
    "\n",
    "    c_iqr = 'b' #'tab:blue'\n",
    "    c_nldas = 'tab:red'\n",
    "\n",
    "    for i in range(nrow):\n",
    "        print(var_list[i])\n",
    "\n",
    "        # calculate DOY (day of year) mean IQR    \n",
    "        df = pd.DataFrame(data)    \n",
    "        time_month = [t.month for t in time_regr]\n",
    "        time_day = [t.day for t in time_regr]\n",
    "        df['month']=time_month\n",
    "        df['date']=time_day    \n",
    "        df2 = df.groupby(['month','date']).mean()\n",
    "\n",
    "        if i == 0:\n",
    "            df3 = df2[df_nlds2==0]\n",
    "        else:\n",
    "            df3 = df2[df_nlds2!=0]\n",
    "\n",
    "        # vmin and vmax\n",
    "        vmin = np.nanmin(df3)\n",
    "        vmax = np.nanmax(df3) #np.nanmax(data) #np.percentile(data,75)\n",
    "\n",
    "        unc_doy = np.nanmean(df3,axis=1) #[DOY,1]\n",
    "\n",
    "        # plot uncertainty\n",
    "        ax[i].plot(np.arange(1,1+len(unc_doy)),unc_doy, color=c_iqr, marker='s', \n",
    "                   linewidth=0.5, markersize=1, markeredgecolor='none', alpha=0.7)\n",
    "\n",
    "        # limit\n",
    "        ax[i].set_xlim(1,len(unc_doy))\n",
    "\n",
    "        # label\n",
    "        if i == nrow-1:\n",
    "            xlabel = 'Day of Year (DOY) '\n",
    "            ax[i].set_xlabel(xlabel, fontsize='xx-small')\n",
    "        ax[i].set_ylabel('Uncertainty', fontsize='xx-small') #+var_units[i]\n",
    "\n",
    "        # title\n",
    "        alpha = chr(ord('a') + i)\n",
    "        ax[i].set_title('('+alpha+') '+var_list[i], fontsize='xx-small', fontweight='semibold')\n",
    "\n",
    "        # tick\n",
    "        ax[i].tick_params(axis='both', direction='out',labelsize = 'xx-small',\n",
    "                          length=1, width=0.5, pad=1.5, labelcolor='k')\n",
    "\n",
    "        # change subplot border width\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax[i].spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    # save plot\n",
    "    fig.tight_layout(pad=0.1, h_pad=0.5) \n",
    "    fig.savefig(os.path.join(output_dir, output_filename), dpi=dpi_value,\n",
    "                bbox_inches = 'tight', pad_inches = 0.05)\n",
    "    plt.close(fig)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((366,), (366, 80439))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(unc_doy),np.shape(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_doy = np.nanmean(df3,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
