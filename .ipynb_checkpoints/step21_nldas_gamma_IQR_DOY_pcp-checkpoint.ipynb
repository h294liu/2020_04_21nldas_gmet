{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read gridinfo mask\n",
      "Read nldas data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_max' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_min' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_range' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_max' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_min' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/lib/python3.8/site-packages/xarray/conventions.py:487: SerializationWarning: variable 't_range' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 79831\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# This script is used to compare ensemble outputs with NLDAS data\n",
    "import numpy as np\n",
    "import os,scipy\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from scipy.stats import gamma\n",
    "import multiprocessing as mp\n",
    "\n",
    "def ppf(p,a,b):\n",
    "    \n",
    "    q = gamma.ppf(p, a, loc=0, scale=b)\n",
    "    return q\n",
    "\n",
    "def read_ens(out_forc_name_base, metric, start_yr, end_yr):\n",
    "    for yr in range(start_yr, end_yr+1):        \n",
    "        \n",
    "        file = os.path.join(out_forc_name_base + '.' + str(yr) + '.'+metric+'.nc')\n",
    "        f=xr.open_dataset(file)\n",
    "        time = f['time'][:]\n",
    "        pcp = f.variables['pcp'][:]\n",
    "        tmean = f.variables['t_mean'][:]\n",
    "        tmin = f.variables['t_min'][:]\n",
    "        tmax = f.variables['t_max'][:]\n",
    "        trange = f.variables['t_range'][:]\n",
    "        \n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            tmean_concat = tmean\n",
    "            tmin_concat = tmin\n",
    "            tmax_concat = tmax\n",
    "            trange_concat = trange\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0) # (time)\n",
    "            pcp_concat = np.concatenate((pcp_concat, pcp), axis=0) # (time,y,x)\n",
    "            tmean_concat = np.concatenate((tmean_concat, tmean), axis=0)\n",
    "            tmin_concat = np.concatenate((tmin_concat, tmin), axis=0)\n",
    "            tmax_concat = np.concatenate((tmax_concat, tmax), axis=0)\n",
    "            trange_concat = np.concatenate((trange_concat, trange), axis=0)\n",
    "            \n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "        \n",
    "    return time_concat, pcp_concat, tmean_concat, tmin_concat, tmax_concat, trange_concat\n",
    "\n",
    "#======================================================================================================\n",
    "# main script\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc_convert')\n",
    "start_yr = 2015\n",
    "end_yr = 2016\n",
    "\n",
    "gridinfo_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "\n",
    "time_format = '%Y-%m-%d'\n",
    "plot_date_start = '2015-01-01'\n",
    "plot_date_end = '2016-12-31'\n",
    "plot_date_start_obj = datetime.datetime.strptime(plot_date_start, time_format)\n",
    "plot_date_end_obj = datetime.datetime.strptime(plot_date_end, time_format)\n",
    "\n",
    "output_dir=os.path.join(root_dir, 'scripts/step21_nldas_gamma_IQR_DOY_pcp')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_file1 = 'ppf25_pcp.txt'\n",
    "output_file2 = 'ppf75_pcp.txt'\n",
    "output_file3 = 'IQR_pcp.txt'\n",
    "   \n",
    "#======================================================================================================\n",
    "print('Read gridinfo mask')\n",
    "# get xy mask from gridinfo.nc\n",
    "f_gridinfo = xr.open_dataset(gridinfo_file)\n",
    "mask_xy = f_gridinfo['mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "#data_mask = f_gridinfo['data_mask'].values[:] # (y, x). 1 is valid. 0 is invalid.\n",
    "\n",
    "#======================================================================================================\n",
    "# read historical nldas data\n",
    "print('Read nldas data')\n",
    "for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "    nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "    nldas_path = os.path.join(nldas_dir, nldas_file)\n",
    "    \n",
    "    f_nldas = xr.open_dataset(nldas_path)\n",
    "    if yr == start_yr:\n",
    "        pcp = f_nldas['pcp'].values[:] # (time, y, x). unit: mm/day\n",
    "        time = f_nldas['time'].values[:]\n",
    "    else:\n",
    "        pcp = np.concatenate((pcp, f_nldas['pcp'].values[:]), axis = 0)\n",
    "        time = np.concatenate((time, f_nldas['time'].values[:]), axis = 0)\n",
    "\n",
    "# get time mask from nldas data\n",
    "time_obj = pd.to_datetime(time)\n",
    "mask_t  = (time_obj >= plot_date_start_obj) & (time_obj <= plot_date_end_obj) \n",
    "time = time_obj[mask_t]\n",
    "\n",
    "nt_nldas = len(time)\n",
    "mask_xy_3d_nldas = np.repeat(mask_xy[np.newaxis,:,:],nt_nldas,axis=0)\n",
    "\n",
    "pcp = pcp[mask_xy_3d_nldas!=0]    \n",
    "pcp = pcp.reshape((nt_nldas,-1))\n",
    "\n",
    "# calculate DOY (day of year) mean IQR    \n",
    "df_nlds = pd.DataFrame(pcp)    \n",
    "time_month = [t.month for t in time]\n",
    "time_day = [t.day for t in time]\n",
    "df_nlds['month']=time_month\n",
    "df_nlds['date']=time_day  \n",
    "df_nlds2 = df_nlds.groupby(['month','date']).mean()\n",
    "\n",
    "del pcp\n",
    "\n",
    "##======================================================================================================    \n",
    "# calculate Gamma distribution IQR\n",
    "df_nldas3 = df_nlds2[df_nlds2!=0]\n",
    "nldas_arr = df_nldas3.to_numpy()\n",
    "mu = nldas_arr \n",
    "std = nldas_arr*0.25\n",
    "\n",
    "alpha = np.power(mu,2)/np.power(std,2)\n",
    "beta = np.power(std,2)/mu\n",
    "\n",
    "(ny,nx) = np.shape(nldas_arr)\n",
    "q25 = np.zeros((ny,nx))\n",
    "q75 = np.zeros((ny,nx))\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "\n",
    "# for i in range(ny):\n",
    "for i in range(2):\n",
    "    print('row ',i)\n",
    "    q25[i,:] = [pool.apply(ppf, args=(0.25, alpha[i,j], beta[i,j])) for j in range(nx)]\n",
    "    q75[i,:] = [pool.apply(ppf, args=(0.75, alpha[i,j], beta[i,j])) for j in range(nx)]\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()    \n",
    "\n",
    "# post-process\n",
    "q25_update = np.where(np.isnan(q25),-999,q25)\n",
    "q75_update = np.where(np.isnan(q75),-999,q75)\n",
    "iqr = q75-q25\n",
    "iqr_update = np.where(np.isnan(iqr),-999,iqr)\n",
    "\n",
    "# save\n",
    "np.savetxt(os.path.join(output_dir,output_file1),q25_update,delimiter=',',fmt='%f',header='# Row:DOY. Col:grids.')\n",
    "np.savetxt(os.path.join(output_dir,output_file2),q75_update,delimiter=',',fmt='%f',header='# Row:DOY. Col:grids.')\n",
    "np.savetxt(os.path.join(output_dir,output_file3),iqr_update,delimiter=',',fmt='%f',header='# Row:DOY. Col:grids.')\n",
    "\n",
    "print('Done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
