{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/xarray/core/merge.py:17: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read nldas data\n",
      "stndata_00810grids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/home/hongli/tools/miniconda/ENTER/lib/python3.7/site-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'   \n",
    "nldas_dir = os.path.join(root_dir,'data/nldas_daily_utc')\n",
    "stnlist_dir = os.path.join(root_dir, 'scripts/step1_sample_stnlist_uniform')\n",
    "stnlist_name_base = 'stnlist'\n",
    "\n",
    "time_format='%Y-%m-%d'\n",
    "start_yr = 2015\n",
    "end_yr = 2016\n",
    "\n",
    "time_format='%Y-%m-%d'\n",
    "extract_start_date = '2015-01-01'\n",
    "extract_end_date   = '2016-12-31'\n",
    "\n",
    "outfolder = 'scripts/step14_check_prepare_stndata_uniform'\n",
    "if not os.path.exists(os.path.join(root_dir, outfolder)):\n",
    "    os.makedirs(os.path.join(root_dir, outfolder))\n",
    "\n",
    "# ============================================================================================================\n",
    "# read historical nldas \n",
    "print('Read nldas data')\n",
    "for yr in range(start_yr, end_yr+1):\n",
    "    \n",
    "    nldas_file = 'NLDAS_'+str(yr)+'.nc'\n",
    "    nldas_path = os.path.join(nldas_dir, nldas_file)\n",
    "    \n",
    "    f_nldas = xr.open_dataset(nldas_path)\n",
    "    if yr == start_yr:\n",
    "        prcp_avg = f_nldas['prcp_avg'].values[:] # (time, lat, lon). unit: kg/m^2 = mm\n",
    "        tair_min = f_nldas['tair_min'].values[:] # (time, lat, lon). unit: K\n",
    "        tair_max = f_nldas['tair_max'].values[:]\n",
    "        time = pd.to_datetime(f_nldas['time'].values[:]).strftime(time_format)\n",
    "    else:\n",
    "        prcp_avg = np.concatenate((prcp_avg, f_nldas['prcp_avg'].values[:]), axis = 0)\n",
    "        tair_min = np.concatenate((tair_min, f_nldas['tair_min'].values[:]), axis = 0)\n",
    "        tair_max = np.concatenate((tair_max, f_nldas['tair_max'].values[:]), axis = 0)\n",
    "        time = np.concatenate((time, pd.to_datetime(f_nldas['time'].values[:]).strftime(time_format)), axis = 0)\n",
    "    f_nldas.close()\n",
    "    \n",
    "prcp_sum = np.multiply(prcp_avg, 24.0) #mm/hr to mm/day\n",
    "tair_min = np.subtract(tair_min, 273.15)\n",
    "tair_max = np.subtract(tair_max, 273.15)\n",
    "\n",
    "# nldas mask on the time dimension\n",
    "time_obj = np.asarray([datetime.datetime.strptime(t, time_format) for t in time])\n",
    "start_date_obj = datetime.datetime.strptime(extract_start_date, time_format)\n",
    "end_date_obj = datetime.datetime.strptime(extract_end_date, time_format)\n",
    "nldas_mask  = (time_obj >= start_date_obj) & (time_obj <= end_date_obj) \n",
    "t = time_obj[nldas_mask]\n",
    "\n",
    "# ============================================================================================================\n",
    "# plot station time series one-by-one\n",
    "stnlist_files = [f for f in os.listdir(stnlist_dir) if stnlist_name_base in f]\n",
    "stnlist_files = sorted(stnlist_files)\n",
    "\n",
    "# for stnlist_file in stnlist_files:\n",
    "for stnlist_file in stnlist_files[0:1]:\n",
    "    \n",
    "    # create sub-outfolder\n",
    "    sub_folder = 'stndata_'+(stnlist_file.split('.')[0].split('_')[1])\n",
    "    if not os.path.exists(os.path.join(root_dir, outfolder, sub_folder)):\n",
    "        os.makedirs(os.path.join(root_dir, outfolder, sub_folder)) \n",
    "    print(sub_folder)\n",
    "\n",
    "    # read selected stn list \n",
    "    stn_ids = np.loadtxt(os.path.join(stnlist_dir,stnlist_file), skiprows=2, usecols=[0], delimiter=',', dtype='str') # STA_ID[0], LAT[1], LON[2] ELEV[3], SLP_N[4], SLP_E[5], STA_NAME[6]\n",
    "    stnlist = np.loadtxt(os.path.join(stnlist_dir,stnlist_file), skiprows=2, usecols=[1,2,3,4,5], delimiter=',') \n",
    "    stn_num = len(stn_ids)\n",
    "    \n",
    "    #====================================================================================#\n",
    "    # plot each station\n",
    "    fig_file_summary = []\n",
    "    for i in range(stn_num):\n",
    "        stn_id = stn_ids[i]    \n",
    "        stn_lat_id = int(stn_id[3:3+3]) #start from zero\n",
    "        stn_lon_id = int(stn_id[9:9+3])\n",
    "       \n",
    "        # plot time series to avoid empty values\n",
    "        fig, ax1 = plt.subplots(constrained_layout=True)\n",
    "        fig.set_figwidth(3.5*2) #190mm\n",
    "        fig.set_figheight(3.5) #5.61 heigh/width=3/4\n",
    "        fig.suptitle(stn_id, fontsize='medium', fontweight='semibold', color='g')\n",
    "\n",
    "        color = 'tab:red'\n",
    "        ax1.set_xlabel('time')\n",
    "        ax1.set_ylabel('T (degC)', color=color)\n",
    "        lns1=ax1.plot(t, tair_min[nldas_mask,stn_lat_id, stn_lon_id], color='b', linewidth=1, label='tmin')\n",
    "        lns2=ax1.plot(t, tair_max[nldas_mask,stn_lat_id, stn_lon_id], color='r', linewidth=1, label='tmax')\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        color = 'k'\n",
    "        ax2.set_ylabel('P (mm/d)', color=color)  # we already handled the x-label with ax1\n",
    "        lns3=ax2.plot(t, prcp_sum[nldas_mask,stn_lat_id, stn_lon_id], color='k', linewidth=1, label='pcp')\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        # added these three lines\n",
    "        lns = lns1+lns2+lns3\n",
    "        labs = [l.get_label() for l in lns]\n",
    "        ax1.legend(lns, labs, loc='upper right', fontsize='small', framealpha=0.5)\n",
    "\n",
    "#         fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#         plt.show()\n",
    "\n",
    "        output_filename = stn_id+'.png'\n",
    "        fig.savefig(os.path.join(root_dir, outfolder, sub_folder, output_filename))\n",
    "        plt.close(fig)        \n",
    "\n",
    "        fig_file_summary.append(os.path.join(root_dir, outfolder, sub_folder, output_filename))\n",
    "    \n",
    "#     #====================================================================================#\n",
    "#     # save all station figures as one\n",
    "#     widths = []\n",
    "#     heights = []\n",
    "#     for fig_file in fig_file_summary:\n",
    "#         im = Image.open(fig_file)\n",
    "#         widths.append(im.width)\n",
    "#         heights.append(im.height)\n",
    "\n",
    "#     max_width = max(widths)\n",
    "#     total_height = sum(heights)\n",
    "#     new_im = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "#     x_offset = 0\n",
    "#     for fig_file in fig_file_summary:\n",
    "#         im = Image.open(fig_file)    \n",
    "#         new_im.paste(im, (0,x_offset))\n",
    "#         x_offset += im.size[1]\n",
    "#     new_im.save(os.path.join(root_dir, outfolder, sub_folder+'.png'))\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stnlist_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ENTER]",
   "language": "python",
   "name": "conda-env-ENTER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
