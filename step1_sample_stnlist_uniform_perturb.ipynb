{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot distribution\n",
      "810 Grids\n",
      "974 Grids\n",
      "1225 Grids\n",
      "1610 Grids\n",
      "2251 Grids\n",
      "3186 Grids\n",
      "4951 Grids\n",
      "8884 Grids\n",
      "18074 Grids\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "# import conda\n",
    "# conda_file_dir = conda.__file__\n",
    "# conda_dir = conda_file_dir.split('lib')[0]\n",
    "# proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "# os.environ[\"PROJ_LIB\"] = proj_lib\n",
    "# reference :http://jtdz-solenoids.com/stackoverflow_/questions/54201946/how-can-i-avoid-proj-lib-error-in-importing-basemap\n",
    "os.environ[\"PROJ_LIB\"] = '/glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/share/proj'\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from itertools import chain\n",
    "\n",
    "def plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx):\n",
    "\n",
    "    m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='cyl', ax=ax)   \n",
    "#     m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='tmerc', ax=ax,lat_0=lat_0,lon_0=lon_0)\n",
    "\n",
    "    m.drawstates(linewidth=0.25, linestyle='solid', color='grey')\n",
    "    m.drawcountries(linewidth=0.25, linestyle='solid', color='k')\n",
    "    m.drawcoastlines(linewidth=0.2, linestyle='solid', color='k')\n",
    "\n",
    "    # lat and lon with lables\n",
    "    m.drawparallels(np.arange(np.floor(llcrnrlat),np.ceil(urcrnrlat),10),labels=[True,False,False,False],\n",
    "                    dashes=[1,1], fontsize='xx-small', linewidth=0.2, color='grey') # Draw parallels (latitude lines)\n",
    "    m.drawmeridians(np.arange(np.floor(llcrnrlon),np.ceil(urcrnrlon),15),labels=[False,False,False,True],\n",
    "                    dashes=[1,1], fontsize='xx-small', linewidth=0.2, color='grey') # Draw meridians (longitude lines). Label [left, right, top, bottom]\n",
    "    \n",
    "#     # draw a shaded-relief image\n",
    "#     m.shadedrelief(scale=0.5)\n",
    "    \n",
    "#     # lats and longs are returned as a dictionary\n",
    "# #     lats = m.drawparallels(np.arange(llcrnrlat,urcrnrlat,dy),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "# #     lons = m.drawmeridians(np.arange(llcrnrlon,urcrnrlon,dx),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "#     lats = m.drawparallels(np.reshape(np.linspace(llcrnrlat,urcrnrlat,ny+1),(ny+1,)),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "#     lons = m.drawmeridians(np.reshape(np.linspace(llcrnrlon,urcrnrlon,nx+1),(nx+1,)),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "\n",
    "#     lat_lines = chain(*(tup[1][0] for tup in lats.items()))\n",
    "#     lon_lines = chain(*(tup[1][0] for tup in lons.items()))\n",
    "#     all_lines = chain(lat_lines, lon_lines)\n",
    "    \n",
    "#     # cycle through these lines and set the desired style\n",
    "#     for line in all_lines:\n",
    "#         line.set(linestyle='-', alpha=0.3, color='grey')\n",
    "\n",
    "    return m\n",
    "\n",
    "def plot_basemap2(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx):\n",
    "\n",
    "    m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,resolution='l',projection='cyl', ax=ax)   \n",
    "\n",
    "    m.drawstates(linewidth=0.25, linestyle='solid', color='grey')\n",
    "    m.drawcountries(linewidth=0.25, linestyle='solid', color='k')\n",
    "    m.drawcoastlines(linewidth=0.2, linestyle='solid', color='k')\n",
    "\n",
    "    # lat and lon with lables\n",
    "    m.drawparallels(np.arange(np.floor(llcrnrlat),np.ceil(urcrnrlat),10),labels=[True,False,False,False],\n",
    "                    dashes=[1,1], fontsize='small', linewidth=0.2, color='grey') # Draw parallels (latitude lines)\n",
    "    m.drawmeridians(np.arange(np.floor(llcrnrlon),np.ceil(urcrnrlon),15),labels=[False,False,False,True],\n",
    "                    dashes=[1,1], fontsize='small', linewidth=0.2, color='grey') # Draw meridians (longitude lines). Label [left, right, top, bottom]\n",
    "    \n",
    "#     # draw a shaded-relief image\n",
    "#     m.shadedrelief(scale=0.5)\n",
    "    \n",
    "    # lats and longs are returned as a dictionary\n",
    "#     lats = m.drawparallels(np.arange(llcrnrlat,urcrnrlat,dy),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "#     lons = m.drawmeridians(np.arange(llcrnrlon,urcrnrlon,dx),labels=[False,False,False,False],dashes=[0.5,0.5]) \n",
    "    lats = m.drawparallels(np.reshape(np.linspace(llcrnrlat,urcrnrlat,ny+1),(ny+1,)),labels=[False,False,False,False],dashes=[0.1,0.1],color='yellow') \n",
    "    lons = m.drawmeridians(np.reshape(np.linspace(llcrnrlon,urcrnrlon,nx+1),(nx+1,)),labels=[False,False,False,False],dashes=[0.1,0.1],color='yellow') \n",
    "\n",
    "    lat_lines = chain(*(tup[1][0] for tup in lats.items()))\n",
    "    lon_lines = chain(*(tup[1][0] for tup in lons.items()))\n",
    "    all_lines = chain(lat_lines, lon_lines)\n",
    "    \n",
    "    # cycle through these lines and set the desired style\n",
    "    for line in all_lines:\n",
    "        line.set(linestyle='-', alpha=0.3, color='grey')\n",
    "    return m\n",
    "# ===============================================================================\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet'\n",
    "grid_info_file = os.path.join(root_dir,'data/nldas_topo/conus_ens_grid_eighth.nc')\n",
    "dpi_value = 300\n",
    "\n",
    "# outfolder = 'scripts/step1_sample_stnlist_uniform_perturb'\n",
    "# if os.path.exists(os.path.join(root_dir, outfolder)):\n",
    "#     shutil.rmtree(os.path.join(root_dir, outfolder))\n",
    "# os.makedirs(os.path.join(root_dir, outfolder))\n",
    "# ofile_name_base = 'stnlist'\n",
    "\n",
    "# np.random.seed(seed=123456)\n",
    "\n",
    "# # ==========================================================================================\n",
    "# # read NLDAS grid info\n",
    "# f = xr.open_dataset(os.path.join(root_dir,grid_info_file))\n",
    "# mask = f['mask'].values[:] # 1 is valid. 0 is invalid. \n",
    "# latitude = f['latitude'].values[:] \n",
    "# longitude = f['longitude'].values[:] \n",
    "# elev = f['elev'].values[:] \n",
    "# gradient_n_s = f['gradient_n_s'].values[:] \n",
    "# gradient_w_e = f['gradient_w_e'].values[:] \n",
    "\n",
    "# (ny,nx)=np.shape(mask)\n",
    "# (y_ids,x_ids)=np.where(mask==1)\n",
    "# total_stn_num = len(y_ids)\n",
    "\n",
    "# # ==========================================================================================\n",
    "# # sampled grid interval\n",
    "# index_intervals=[2,3,4,5,6,7,8,9,10] #1/4, 1/9, 1/16, 1/25,...,1/100  \n",
    "\n",
    "# sample_num_previous = 0\n",
    "# for index_interval in index_intervals:    \n",
    "# # for index_interval in index_intervals[8:]:    \n",
    "    \n",
    "#     # uniform sample\n",
    "#     sample_indexes = np.where((y_ids%index_interval==0) & (x_ids%index_interval==0))[0]\n",
    "#     sample_num = len(sample_indexes)\n",
    "#     rnds=np.random.randint(low=0, high=8+1, size=np.shape(sample_indexes))\n",
    "#     record = []\n",
    "    \n",
    "#     # perturb in eight directions\n",
    "#     if sample_num!=sample_num_previous:\n",
    "#         print('index interval = '+str(index_interval)+', choice num = '+str(sample_num))\n",
    "\n",
    "#         for i in range(sample_num):\n",
    "#             choice_index = sample_indexes[i]\n",
    "#             rnd = rnds[i]\n",
    "#             y_id_origin = y_ids[choice_index]\n",
    "#             x_id_origin = x_ids[choice_index]\n",
    "                 \n",
    "#             if rnd in [1,2,8]:\n",
    "#                 y_id=y_id_origin+1    \n",
    "#             elif rnd in [4,5,6]:\n",
    "#                 y_id=y_id_origin-1\n",
    "#             else:\n",
    "#                 y_id=y_id_origin\n",
    "#             if y_id<0 or y_id>ny or mask[y_id,x_id_origin]!=1:\n",
    "#                 y_id=y_id_origin\n",
    "                           \n",
    "#             if rnd in [2,3,4]:\n",
    "#                 x_id=x_id_origin+1\n",
    "#             elif rnd in [6,7,8]:\n",
    "#                 x_id=x_id_origin-1  \n",
    "#             else:\n",
    "#                 x_id=x_id_origin\n",
    "#             if x_id<0 or x_id>nx or mask[y_id,x_id]!=1:\n",
    "#                 x_id=x_id_origin\n",
    "            \n",
    "#             if [y_id,x_id] not in record:\n",
    "#                 record.append([y_id,x_id])\n",
    "    \n",
    "#     # record the perturbed samples\n",
    "#     sample_num = len(record)        \n",
    "#     ofile = ofile_name_base +'_'+str('%05d' %(sample_num))+'grids'+ '_interval'+str(index_interval)+'.txt'\n",
    "#     f_out = open(os.path.join(root_dir, outfolder, ofile), 'w') \n",
    "#     f_out.write('NSITES\\t'+str(sample_num)+'\\n') # total number line\n",
    "#     f_out.write('STA_ID LAT LON ELEV SLP_N SLP_E STA_NAME\\n') # title line\n",
    "\n",
    "#     for i in range(sample_num):\n",
    "#         y_id = record[i][0]\n",
    "#         x_id = record[i][1]\n",
    "#         sta_id = 'Row'+str('%03d' %(y_id))+'Col'+str('%03d' %(x_id))\n",
    "#         lat_i=latitude[y_id,x_id]\n",
    "#         lon_i=longitude[y_id,x_id]\n",
    "#         ele_i=elev[y_id,x_id]\n",
    "#         gradient_n_s_i=gradient_n_s[y_id,x_id]\n",
    "#         gradient_w_e_i=gradient_w_e[y_id,x_id]\n",
    "#         stn_name = '\"'+sta_id+'\"'\n",
    "#         f_out.write('%s, %f, %f, %f, %f, %f, %s\\n' \\\n",
    "#                     % (sta_id, lat_i, lon_i, ele_i, gradient_n_s_i, gradient_w_e_i, stn_name)) \n",
    "\n",
    "#     f_out.close()\n",
    "#     sample_num_previous=sample_num        \n",
    "\n",
    "##==========================================================================================\n",
    "print('plot distribution')\n",
    "llcrnrlon=longitude[0,0]-1\n",
    "llcrnrlat=latitude[0,0]-1\n",
    "urcrnrlon=longitude[-1,-1]+1\n",
    "urcrnrlat=latitude[-1,-1]+1\n",
    "\n",
    "lat_0=0.5*(llcrnrlat+urcrnrlat)\n",
    "lon_0=0.5*(llcrnrlon+urcrnrlon)\n",
    "\n",
    "stnlist_files = [f for f in os.listdir(os.path.join(root_dir, outfolder)) if ofile_name_base in f]\n",
    "stnlist_files = sorted(stnlist_files)\n",
    "\n",
    "# plot\n",
    "ncol = 3\n",
    "nrow = int(np.ceil(len(stnlist_files)/ncol))\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(7.08,7.08*0.6))#, constrained_layout=True) #figsize=(7.08,7.08*0.6)\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "\n",
    "        k = i*ncol+j            \n",
    "        if k<len(stnlist_files):  \n",
    "\n",
    "            # read sampled stnlist.txt\n",
    "            stnlist_file = os.path.join(root_dir, outfolder, stnlist_files[k])\n",
    "            interval = int(stnlist_files[k].split('.')[0].split('_')[2].split('interval')[1])\n",
    "            data = np.loadtxt(stnlist_file, skiprows=2, usecols=[1,2],delimiter=',') #STA_ID[0], LAT[1], LON[2], ELEV[3], SLP_N[4], SLP_E[5], STA_NAME[6]\n",
    "            stn_num = len(data)\n",
    "            stn_lons = [float(data[i][1]) for i in range(stn_num)]\n",
    "            stn_lats = [float(data[i][0]) for i in range(stn_num)]\n",
    "            print(str(stn_num) +' Grids')\n",
    "\n",
    "            m = plot_basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax[i,j],lat_0,lon_0,ny,nx) # plot Basemap \n",
    "\n",
    "            x, y = m(stn_lons,stn_lats) # convert the lat/lon values to x/y projections.\n",
    "#             m.plot(x, y, 'bs', markersize=0.15) # plot sampeld grid points\n",
    "            m.scatter(x, y, s=0.5, c='b', marker='o', edgecolors='none')\n",
    "\n",
    "            # set title\n",
    "            ratio=str('1/')+str(interval**2)\n",
    "            perctl=round(stn_num/total_stn_num*100,1)\n",
    "#             title_str = '('+chr(ord('a') + k) +') ' + str(stn_num)  +' samples \\n(Proportion = '+str(perctl)+'%. Interval = '+str(interval)+')'\n",
    "            title_str = 'Strategy %d (interval = %d)\\nSamples = %d. Proportion = %.1f%%' %(k+1, interval, stn_num, perctl)\n",
    "            ax[i,j].set_title(title_str, fontsize='xx-small', fontweight='normal', pad=2) #fontweight='normal'\n",
    "\n",
    "        else: # blank axis\n",
    "            ax[i,j].axis('off')\n",
    "            \n",
    "        # change subplot border width\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax[i,j].spines[axis].set_linewidth(0.5)\n",
    "\n",
    "\n",
    "# save plot\n",
    "fig.tight_layout()\n",
    "ofile = 'sample_grids_dist.png'\n",
    "fig.savefig(os.path.join(root_dir, outfolder, ofile), dpi=dpi_value)\n",
    "plt.close(fig)    \n",
    "\n",
    "# # --- plot distribution with NLDAS grids ---\n",
    "# print('plot distribution with NLDAS grids')\n",
    "# llcrnrlon=longitude[0,0]-1\n",
    "# llcrnrlat=latitude[0,0]-1\n",
    "# urcrnrlon=longitude[-1,-1]+1\n",
    "# urcrnrlat=latitude[-1,-1]+1\n",
    "\n",
    "# lat_0=0.5*(llcrnrlat+urcrnrlat)\n",
    "# lon_0=0.5*(llcrnrlon+urcrnrlon)\n",
    "\n",
    "# stnlist_files = [f for f in os.listdir(os.path.join(root_dir, outfolder)) if ofile_name_base in f]\n",
    "# stnlist_files = sorted(stnlist_files)\n",
    "\n",
    "# # plot\n",
    "# ncol = 1 #3\n",
    "# nrow = 1 #int(np.ceil(len(stnlist_files)/ncol))\n",
    "\n",
    "# fig, ax = plt.subplots(nrow, ncol, figsize=(8,8*0.65))#, constrained_layout=True)\n",
    "\n",
    "# k = 0           \n",
    "# if k<len(stnlist_files):  \n",
    "\n",
    "#     # read sampled stnlist.txt\n",
    "#     stnlist_file = os.path.join(root_dir, outfolder, stnlist_files[k])\n",
    "#     interval = int(stnlist_files[k].split('.')[0].split('_')[2].split('interval')[1])\n",
    "#     data = np.loadtxt(stnlist_file, skiprows=2, usecols=[1,2],delimiter=',') #STA_ID[0], LAT[1], LON[2], ELEV[3], SLP_N[4], SLP_E[5], STA_NAME[6]\n",
    "#     stn_num = len(data)\n",
    "#     stn_lons = [float(data[i][1]) for i in range(stn_num)]\n",
    "#     stn_lats = [float(data[i][0]) for i in range(stn_num)]\n",
    "#     print(str(stn_num) +' Grids')\n",
    "\n",
    "#     m = plot_basemap2(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,ax,lat_0,lon_0,ny,nx) # plot Basemap \n",
    "\n",
    "#     x, y = m(stn_lons,stn_lats) # convert the lat/lon values to x/y projections.\n",
    "# #             m.plot(x, y, 'bs', markersize=0.15) # plot sampeld grid points\n",
    "#     m.scatter(x, y, s=0.5, c='b', marker='o', edgecolors='none')\n",
    "\n",
    "#     # set title\n",
    "#     ratio=str('1/')+str(interval**2)\n",
    "#     perctl=round(stn_num/total_stn_num*100,1)\n",
    "#     title_str = '('+chr(ord('a') + k) +') ' + str(stn_num)  +' samples \\n(Proportion = '+str(perctl)+'%. Interval = '+str(interval)+')'\n",
    "#     ax.set_title(title_str, fontsize='small', fontweight='semibold')\n",
    "\n",
    "# else: # blank axis\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # change subplot border width\n",
    "# for axis in ['top','bottom','left','right']:\n",
    "#     ax.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "# # save plot\n",
    "# fig.tight_layout()\n",
    "# ofile = 'sample_grids_dist_w_NLDAS_grids_small.png'\n",
    "# fig.savefig(os.path.join(root_dir, outfolder, ofile), dpi=dpi_value)\n",
    "# plt.close(fig)    \n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'conda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c420a3655322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconda_file_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconda_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconda_file_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproj_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconda_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'share'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'conda'"
     ]
    }
   ],
   "source": [
    "import conda\n",
    "\n",
    "conda_file_dir = conda.__file__\n",
    "conda_dir = conda_file_dir.split('lib')[0]\n",
    "proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "os.environ[\"PROJ_LIB\"] = proj_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 8, 0, 7, 4, 8, 4, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd=np.random.randint(low=0, high=8, size=np.shape(choice_index))\n",
    "rnd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
