{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# PART1. identify overlapping grid lat/lon and weight\n",
      "# PART2. identify y/x index \n",
      "# PART3. extract ensemble forcings\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "def read_snow17_sac_forcing(file):\n",
    "    # read txt\n",
    "    time = np.loadtxt(file, usecols=[0,1,2], dtype='str', skiprows=4)\n",
    "    data = np.loadtxt(file, skiprows=4) \n",
    "    data = data[:,4:10+1]\n",
    "    \n",
    "    # convert time\n",
    "    time_obj = []\n",
    "    for i in range(len(time)):\n",
    "        t_str = time[i,0]+' '+time[i,1]+' '+time[i,2]\n",
    "        time_obj.append(datetime.strptime(t_str,'%Y %m %d'))\n",
    "        \n",
    "    # create dataframe (time, data)\n",
    "    df = pd.DataFrame(data,columns=['Dayl(s)','PRCP(mm/day)','SRAD(W/m2)',\n",
    "                                        'SWE(mm)','Tmax(C)','Tmin(C)','Vp(Pa)'])\n",
    "    df['Date'] = time_obj\n",
    "    df = df.set_index('Date')   \n",
    "    return df\n",
    "\n",
    "source_code_dir = '/glade/u/home/hongli/github/2020_04_21nldas_gmet/snow17_sac'\n",
    "\n",
    "# target_polyid = '13310700'\n",
    "# weight_file = os.path.join(source_code_dir, 'region_17_lump_weights.nc')\n",
    "# forcing_tpl = os.path.join(source_code_dir, '13310700_lump_nldas_forcing_leap.txt')\n",
    "# # source (hydro-c1):/d2/anewman/region_weights/nldas/region_17_lump_weights.nc\n",
    "# # source (hydro-c1):/d5/anewman/basin_forcing_data/nldas/17/13310700_lump_nldas_forcing_leap.txt\n",
    "\n",
    "target_polyid = '09081600' \n",
    "weight_file = os.path.join(source_code_dir, 'region_14_lump_weights.nc')\n",
    "forcing_tpl = os.path.join(source_code_dir, '09081600_lump_nldas_forcing_leap.txt')\n",
    "# source: /d2/anewman/region_weights/nldas/region_14_lump_weights.nc\n",
    "# source (hydro-c1):/d5/anewman/basin_forcing_data/nldas/14/09081600_lump_nldas_forcing_leap.txt\n",
    "\n",
    "source_ens_dr = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet/test_uniform_perturb/18212grids/gmet_ens_bc'\n",
    "forcing_basename = 'ens_forc' #ens_forc.2000.086.nc\n",
    "start_time = '2005/10/01'\n",
    "end_time = '2006/09/30'\n",
    "time_fmt = '%Y/%m/%d'\n",
    "start_time_obj = datetime.strptime(start_time,time_fmt)\n",
    "end_time_obj = datetime.strptime(end_time,time_fmt)\n",
    "\n",
    "start_yr = start_time_obj.year\n",
    "end_yr = end_time_obj.year\n",
    "yr_num = end_yr-start_yr+1\n",
    "day_num = (end_time_obj-start_time_obj).days+1\n",
    "ens_num = 100\n",
    "\n",
    "root_dir = '/glade/u/home/hongli/scratch/2020_04_21nldas_gmet/test_uniform_perturb/18212grids/gmet_ens_snow17_sac'\n",
    "out_dir = os.path.join(root_dir, target_polyid)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "file_basename = target_polyid+'_lump_nldas_forcing_leap'\n",
    "\n",
    "# PART1. identify overlapping grid lat/lon and weight\n",
    "print('# PART1. identify overlapping grid lat/lon and weight')\n",
    "f=xr.open_dataset(weight_file)\n",
    "polyid = f.variables['polyid'].values[:]\n",
    "weight = f.variables['weight'].values[:]\n",
    "overlaps = f.variables['overlaps'].values[:]\n",
    "latitude = f.variables['latitude'].values[:]\n",
    "longitude = f.variables['longitude'].values[:]\n",
    "\n",
    "target_index = list(polyid).index(target_polyid)\n",
    "overlap_num = overlaps[target_index]\n",
    "\n",
    "overlap_lats = latitude[target_index, 0:overlap_num]\n",
    "overlap_lons = longitude[target_index, 0:overlap_num]\n",
    "overlap_weights = weight[target_index, 0:overlap_num]\n",
    "\n",
    "# PART2. identify y/x index for overlapping grid lat/lon and weight\n",
    "print('# PART2. identify y/x index ')\n",
    "forcing_file = os.path.join(source_ens_dr,('%s.%d.%003d.nc')%(forcing_basename,start_yr,1))\n",
    "f=xr.open_dataset(forcing_file)\n",
    "latitude = list(f.variables['latitude'].values[:,0])   #(y,x)=(224,464) -> (y)=(224)\n",
    "longitude = list(f.variables['longitude'].values[0,:]) #(y,x)=(224,464) -> (x)=(464)\n",
    "\n",
    "y_index = [latitude.index(round(lat,4)) for lat in overlap_lats]\n",
    "x_index = [longitude.index(round(lon,4)) for lon in overlap_lons]\n",
    "\n",
    "# PART3. extract ensemble forcings\n",
    "print('# PART3. extract ensemble forcings')\n",
    "for mb in range(ens_num):\n",
    "# for mb in range(2):\n",
    "    print(mb+1)\n",
    "    for yr in range(start_yr, end_yr+1):\n",
    "        forcing_file = os.path.join(source_ens_dr,('%s.%d.%003d.nc')%(forcing_basename,yr,mb+1))\n",
    "        f=xr.open_dataset(forcing_file)\n",
    "        time = f.variables['time'].values\n",
    "        pcp = f.variables['pcp'].values\n",
    "        t_min = f.variables['t_min'].values\n",
    "        t_max = f.variables['t_max'].values\n",
    "        \n",
    "        # concatenate for years\n",
    "        if yr == start_yr:\n",
    "            time_concat = time\n",
    "            pcp_concat = pcp\n",
    "            t_min_concat = t_min\n",
    "            t_max_concat = t_max\n",
    "        else:\n",
    "            time_concat = np.concatenate((time_concat,time), axis=0)\n",
    "            pcp_concat = np.concatenate((pcp_concat,pcp), axis=0)\n",
    "            t_min_concat = np.concatenate((t_min_concat,t_min), axis=0)\n",
    "            t_max_concat = np.concatenate((t_max_concat,t_max), axis=0)\n",
    "    \n",
    "    # extract overlapping grids (time,overlap_num)\n",
    "    overlap_pcp = pcp_concat[:,y_index,x_index]\n",
    "    overlap_t_min = t_min_concat[:,y_index,x_index]\n",
    "    overlap_t_max = t_max_concat[:,y_index,x_index]\n",
    "    \n",
    "    # extract useful time period (time_useful,overlap_num)\n",
    "    time_concat = pd.DatetimeIndex(time_concat)\n",
    "    mask = (time_concat>=start_time_obj) & (time_concat<=end_time_obj)\n",
    "    overlap_pcp = overlap_pcp[mask,:]\n",
    "    overlap_t_min = overlap_t_min[mask,:]\n",
    "    overlap_t_max = overlap_t_max[mask,:]\n",
    "    \n",
    "    # calcualte weighted sum (time_useful)\n",
    "    lump_pcp = np.matmul(overlap_pcp,overlap_weights)\n",
    "    lump_t_min = np.matmul(overlap_t_min,overlap_weights)\n",
    "    lump_t_max = np.matmul(overlap_t_max,overlap_weights)\n",
    "    \n",
    "    # update reference forcing date\n",
    "    df = read_snow17_sac_forcing(forcing_tpl)\n",
    "    df.at[start_time_obj:end_time_obj,'PRCP(mm/day)'] = lump_pcp\n",
    "    df.at[start_time_obj:end_time_obj,'Tmax(C)'] = lump_t_max    \n",
    "    df.at[start_time_obj:end_time_obj,'Tmin(C)'] = lump_t_min\n",
    "    \n",
    "    # write ensemble forcing txt\n",
    "    ofile = os.path.join(out_dir, ('%s_%003d.txt')%(file_basename,mb+1)) #'13310700_lump_nldas_forcing_leap.txt'\n",
    "    with open(forcing_tpl, 'r') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "        with open(ofile,'w') as f_out:\n",
    "            for iline, line in enumerate(lines):\n",
    "                if iline<=3:\n",
    "                    f_out.write(line)\n",
    "                elif iline>=4:\n",
    "                    splits=line.split()\n",
    "                    splits[5] = ('%.2f')%(df.iloc[iline-4,1])\n",
    "                    splits[-3] = ('%.2f')%(df.iloc[iline-4,-3])\n",
    "                    splits[-2] = ('%.2f')%(df.iloc[iline-4,-2])\n",
    "                    update_line='\\t'.join(splits)\n",
    "                    f_out.write(update_line)\n",
    "                    f_out.write('\\n')    \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12010000', '12056500', '14092750', '12145500', '14020000',\n",
       "       '12186000', '12381400', '13340000', '12383500', '14303200',\n",
       "       '12043000', '14138800', '14400000', '13011900', '12115500',\n",
       "       '14362250', '13331500', '12092000', '14158790', '12189500',\n",
       "       '13083000', '12141300', '14137000', '14166500', '14187000',\n",
       "       '14301000', '10396000', '13340600', '12025000', '14138900',\n",
       "       '13338500', '12041200', '12143600', '14185900', '12095000',\n",
       "       '12048000', '12147600', '14141500', '12374250', '13161500',\n",
       "       '12115000', '12013500', '12082500', '14306500', '12411000',\n",
       "       '12375900', '14306340', '12488500', '12020000', '12167000',\n",
       "       '12040500', '12388400', '12073500', '12054000', '13240000',\n",
       "       '14182500', '14158500', '13235000', '12025700', '12390700',\n",
       "       '13313000', '14096850', '14154500', '12451000', '12377150',\n",
       "       '14139800', '12114500', '13011500', '12414500', '12147500',\n",
       "       '14222500', '14138870', '12035000', '14316700', '12447390',\n",
       "       '13018300', '12117000', '14325000', '14216500', '12144000',\n",
       "       '13337000', '14305500', '14308990', '14185000', '13023000',\n",
       "       '12358500', '14309500', '14236200', '12175500', '12178100',\n",
       "       '13310700'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dayl(s)</th>\n",
       "      <th>PRCP(mm/day)</th>\n",
       "      <th>SRAD(W/m2)</th>\n",
       "      <th>SWE(mm)</th>\n",
       "      <th>Tmax(C)</th>\n",
       "      <th>Tmin(C)</th>\n",
       "      <th>Vp(Pa)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>31236.10</td>\n",
       "      <td>9.68</td>\n",
       "      <td>131.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>517.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>31308.86</td>\n",
       "      <td>1.31</td>\n",
       "      <td>188.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>402.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>31407.67</td>\n",
       "      <td>2.68</td>\n",
       "      <td>194.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>450.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>31449.60</td>\n",
       "      <td>5.02</td>\n",
       "      <td>144.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>453.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>31449.60</td>\n",
       "      <td>27.12</td>\n",
       "      <td>115.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>487.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>31104.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>146.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.40</td>\n",
       "      <td>-10.40</td>\n",
       "      <td>240.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>31104.00</td>\n",
       "      <td>12.71</td>\n",
       "      <td>164.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.86</td>\n",
       "      <td>-5.86</td>\n",
       "      <td>337.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>31104.00</td>\n",
       "      <td>2.17</td>\n",
       "      <td>176.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>288.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>31118.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>218.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.12</td>\n",
       "      <td>-14.12</td>\n",
       "      <td>166.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>31150.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>170.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.53</td>\n",
       "      <td>-13.53</td>\n",
       "      <td>110.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12784 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dayl(s)  PRCP(mm/day)  SRAD(W/m2)  SWE(mm)  Tmax(C)  Tmin(C)  \\\n",
       "Date                                                                        \n",
       "1980-01-01  31236.10          9.68      131.43      0.0    -1.03    -1.03   \n",
       "1980-01-02  31308.86          1.31      188.29      0.0    -3.96    -3.96   \n",
       "1980-01-03  31407.67          2.68      194.72      0.0    -2.30    -2.30   \n",
       "1980-01-04  31449.60          5.02      144.25      0.0    -2.80    -2.80   \n",
       "1980-01-05  31449.60         27.12      115.70      0.0    -1.29    -1.29   \n",
       "...              ...           ...         ...      ...      ...      ...   \n",
       "2014-12-27  31104.00          0.00      146.20      0.0   -10.40   -10.40   \n",
       "2014-12-28  31104.00         12.71      164.88      0.0    -5.86    -5.86   \n",
       "2014-12-29  31104.00          2.17      176.54      0.0    -8.05    -8.05   \n",
       "2014-12-30  31118.72          0.16      218.80      0.0   -14.12   -14.12   \n",
       "2014-12-31  31150.60          0.00      170.68      0.0   -13.53   -13.53   \n",
       "\n",
       "            Vp(Pa)  \n",
       "Date                \n",
       "1980-01-01  517.04  \n",
       "1980-01-02  402.22  \n",
       "1980-01-03  450.44  \n",
       "1980-01-04  453.40  \n",
       "1980-01-05  487.83  \n",
       "...            ...  \n",
       "2014-12-27  240.21  \n",
       "2014-12-28  337.70  \n",
       "2014-12-29  288.81  \n",
       "2014-12-30  166.80  \n",
       "2014-12-31  110.33  \n",
       "\n",
       "[12784 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dayl(s)</th>\n",
       "      <th>PRCP(mm/day)</th>\n",
       "      <th>SRAD(W/m2)</th>\n",
       "      <th>SWE(mm)</th>\n",
       "      <th>Tmax(C)</th>\n",
       "      <th>Tmin(C)</th>\n",
       "      <th>Vp(Pa)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Dayl(s), PRCP(mm/day), SRAD(W/m2), SWE(mm), Tmax(C), Tmin(C), Vp(Pa)]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[start_time_obj:end_time_obj] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
